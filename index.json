[{"authors":["admin"],"categories":null,"content":"I am a third-year PhD candidate in physics in the Bruder group within the \u0026ldquo;Quantum Computing and Quantum Technology\u0026rdquo; PhD school at the University of Basel. I have participated in the Google Summer of Code (GSoC) 2020 program with the project \u0026ldquo;High weak order stochastic differential equation solvers and their utility in neural stochastic differential equations\u0026rdquo; within the Julia Language organization. The project was supervised by Chris Rackauckas, Moritz Schauer, and Yingbo Ma. Currently, I am working on my GSoC 2021 project \u0026ldquo;Neural Hybrid Differential Equations and Adjoint Sensitivity Analysis\u0026rdquo; within the NumFocus organization. My GSoC 2021 mentors are Chris Rackauckas, Moritz Schauer, Yingbo Ma, and Mohamed Tarek. Since 2020, I am a member of the SciML open source software organization for scientific machine learning.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://frankschae.github.io/author/frank-schafer/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/frank-schafer/","section":"authors","summary":"I am a third-year PhD candidate in physics in the Bruder group within the \u0026ldquo;Quantum Computing and Quantum Technology\u0026rdquo; PhD school at the University of Basel. I have participated in the Google Summer of Code (GSoC) 2020 program with the project \u0026ldquo;High weak order stochastic differential equation solvers and their utility in neural stochastic differential equations\u0026rdquo; within the Julia Language organization.","tags":null,"title":"Frank Schäfer","type":"authors"},{"authors":[],"categories":[],"content":"Project summary In this project, we have implemented state-of-the-art sensitivity tools for chaotic dynamical systems, continuous adjoint sensitivity methods for hybrid differential equations, as well as a high level API for automatic differentiation.\nPossible fields of application for these tools range from model discovery with explicit dosing times in pharmacology, over accurate gradient estimates for chaotic fluid dynamics, to the control of open quantum systems. A more detailed summary is available on the GSoC page.\nBlog posts The following blog posts describe the work throughout the GSoC period in more detail:\n  Neural Hybrid Differential Equations  Shadowing Methods for Forward and Adjoint Sensitivity Analysis of Chaotic Systems  Sensitivity Analysis of Hybrid Differential Equations  AbstractDifferentiation.jl for AD-backend agnostic code  Docs Documentation with respect to the adjoint sensitivity tools will be available on the local sensitivity analysis and on the control of automatic differentiation choices pages.\nAchievements Below is a list of PRs in the various repositories in chronological order.\nDiffEqSensitivity.jl Merged:\n  Add additive noise downstream test for DiffEqFlux  DiscreteCallback fixes  Allow for changes of p in callbacks  Fix for using the correct uleft/pleft in continuous callback  Fix broadcasting error on steady state adjoint  Forward Least Squares Shadowing (LSS)  Adjoint-mode for the LSS method  concrete_solve dispatch for LSS methods  Non-Intrusive Least Square Shadowing (NILSS)  concrete_solve for NILSS  Remove allocation in NILSS  Handle additional callback case  State-dependent Continuous Callbacks for BacksolveAdjoint  Open:\n  QuadratureAdjoint() for ContinuousCallback  AbstractDifferentiation.jl Merged:\n  Fixes gradient, Jacobian, Hessian, and vjp tests  Open:\n  Add ForwardDiff and Zygote  OrdinaryDiffEq.jl Merged:\n  Fix discrete reverse mode for some standard controllers  SteadyStateDiffEq.jl Merged:\n  convert alg.tspan to type of prob.u0  DiffEqNoiseProcess.jl Merged:\n  Allow solvers to use Noise Grid with SVectors  StochasticDiffEq.jl Merged:\n  Remove Ihat2 matrix from weak solvers  DiffEqDocs.jl Merged:\n  Small typo on plot page  Add docs for shadowing methods  Future work Besides the implementation of more shadowing methods, such as\n  NILSAS,  FD-NILSS, or  Fast linear response,  we are planning to\n benchmark the new adjoints, refine the AbstractDifferentiation.jl package and use it within DiffEqSensitivity.jl, add more docs and examples.  If you have any further suggestions or comments, check out our slac/zulip channels #sciml-bridged and #diffeq-bridged or the Julia language discourse.\nAcknowledgement Many thanks to my mentors Chris Rackauckas, Moritz Schauer, Yingbo Ma, and Mohamed Tarek for their unique, continuous support. It was a great opportunity to be part of such an inspiring collaboration. I highly appreciate our quick and flexible meeting times. I would also like to thank Christoph Bruder, Julian Arnold, and Martin Koppenhöfer for helpful comments on my blog posts. Special thanks to Michael Poli and Stefano Massaroli for their suggestions on adjoints for hybrid differential equations. Finally, thanks to the very supportive julia community and to Google\u0026rsquo;s open source program for funding this experience!\n","date":1628883705,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628883705,"objectID":"295f158a34d7a2a8bb042950210377c3","permalink":"https://frankschae.github.io/post/gsoc-2021/","publishdate":"2021-08-13T21:41:45+02:00","relpermalink":"/post/gsoc-2021/","section":"post","summary":"Project summary In this project, we have implemented state-of-the-art sensitivity tools for chaotic dynamical systems, continuous adjoint sensitivity methods for hybrid differential equations, as well as a high level API for automatic differentiation.","tags":["GSoC 2021"],"title":"Neural Hybrid Differential Equations and Adjoint Sensitivity Analysis","type":"post"},{"authors":[],"categories":[],"content":" Differentiable programming (∂P), i.e., the ability to differentiate general computer program structures, has enabled the efficient combination of existing packages for scientific computation and machine learning1. The Julia2 language is well suited for ∂P, see also Chris' article3 for a detailed examination. There is already a plethora of examples where ∂P has provided massive performance and accuracy advantages over black-box approaches to machine learning. This is because black-box machine learning approaches are flexible but require a large amount of data. Incorporating previously acquired knowledge about the structure of a problem reduces the amount of data and allows the learning task to be simplified4, for example, by focusing on learning only the parts of the model that are actually missing4 5. In the context of quantum control, we have demonstrated the power of this framework for closed6 and open quantum systems7.\n∂P is (commonly) realized by automatic differentiation (AD), which is a family of techniques to efficiently and accurately differentiate numeric functions expressed as computer programs. Generally, besides forward- and reverse-mode AD, the two main branches of AD, a large variety of software implementations with different pros and cons exists. The goal is to make the best choice in every part of the program without requiring users to significantly customize their code. Having a common ground by ChainRules.jl empowers this idea of a Glue AD where backend developers just define ChainRules overloads. However, switching from one backend to another on the user side can still be tedious because the user has to look up the syntax of the new AD package.\n Mohamed Tarek has started to implement a high level API for differentiation that unifies the APIs of all the AD packages in the Julia ecosystem. Ultimately, the API of our new package, AbstractDifferentiation.jl, aims at enabling AD users to write AD backend-agnostic code. This will greatly facilitate the switching between different AD packages. Once the interface is completed and all tests are added, it is also planned that DiffEqSensitivity.jl within the SciML software suite adopts AbstractDifferentiation.jl as a better way of handling AD choices. In this part of my GSoC project, I\u0026rsquo;ve started to fix remaining errors of the initial PR.\nThe interested reader is encouraged to look at Mohamed\u0026rsquo;s first PR for a complete list of functions provided by AbstractDifferentiation.jl (and some great discussions about the package). In the rest of this blog post, I will focus on a concrete example to illustrate the main idea.\nOptimization of the Rosenbrock function The Rosenbrock function is defined by\n$$ g(x_1,x_2) = (a-x_1)^2 + b(x_2-x_1^2)^2. $$\nThe function $g$ has a global minimum at $(x_1^\\star, x_2^\\star)= (a, a^2)$ with $g(x_1^\\star, x_2^\\star)=0$. In the following, we fix $a = 1$ and $b = 100$. The global minimum is located inside a long, narrow, banana-shaped, flat valley, which makes the function a common test case for optimization algorithms.\nLet us now implement the Gauss–Newton algorithm to find the global minimum. The Gauss–Newton algorithm iteratively finds the value of the $N$ variables ${\\bf{x}}=(x_1,\\dots, x_N)$ that minimize the sum of squares of $M$ residuals $(f_1,\\dots, f_M)$\n$$ S({\\bf x}) = \\frac{1}{2} \\sum_{i=1}^M f_i({\\bf x})^2. $$\nStarting from an initial guess ${\\bf x_0}$ for the minimum, the method runs through the iterations\n$$ {\\bf x}^{k+1} = {\\bf x}^k - \\alpha_k \\left(J^T J \\right)^{-1} J^T f({\\bf x}^k), $$ where $J$ is the Jacobian matrix at ${\\bf{x}}^k$ and $\\alpha_k$ is the step length determined via a line search subroutine.\nThe following plot shows the Rosenbrock function in 3D as well as a 2D heatmap including the global minimum ${\\bf x^\\star}=(1,1)$ and our initial guess ${\\bf x_0}=(0,-0.1)$.\nusing Pkg path = @__DIR__ cd(path); Pkg.activate(\u0026quot;.\u0026quot;); Pkg.instantiate() ## AbstractDifferentiation is not released yet!! using AbstractDifferentiation using Test, LinearAlgebra using FiniteDifferences, ForwardDiff, Zygote using Enzyme, UnPack using Plots, LaTeXStrings # using Diffractor: ∂⃖¹ ## Diffractor needs \u0026gt;julia@1.6 ## Rosenbrock function # R: R^2 -\u0026gt; R: x -\u0026gt; (a-x₁)² + b(x₂-x₁²)² g(x,p) = (p[1]-x[1])^2 + p[2]*(x[2]-x[1]^2)^2 # visualization p = [1.0,100.0] x₀ = [0.0,-0.1] xopt = [1.0,1.0] do_plot = true if do_plot x₁, x₂ = -2.0:0.01:2.0, -0.6:0.01:3.5 z = Surface((x₁,x₂)-\u0026gt;g([x₁,x₂],p), x₁, x₂) pl1 = surface(x₁,x₂,z, linealpha = 0.3, c=cgrad(:thermal, scale = :exp), colorbar=true, labelfontsize=20,camera = (3,50), xlabel = L\u0026quot;x_1\u0026quot;, ylabel = L\u0026quot;x_2\u0026quot;) pl2 = heatmap(x₁,x₂,z, c=cgrad(:thermal, scale = :exp), labelfontsize=20, xlabel = L\u0026quot;x_1\u0026quot;, ylabel = L\u0026quot;x_2\u0026quot;) scatter!(pl2, [(x₀[1],x₀[2])], label=L\u0026quot;x_0\u0026quot;, legendfontsize=15, markershape = :circle, markersize = 10, markercolor = :green) scatter!(pl2, [(xopt[1],xopt[2])],label=L\u0026quot;x^\\star\u0026quot;, legendfontsize=15, markershape = :star, markersize = 10, markercolor = :red) pl = plot(pl1,pl2, layout=(2,1)) savefig(pl, \u0026quot;Rosenbrock.png\u0026quot;) end    To apply the Gauss-Newton algorithm to the Rosenbrock function $g$, we first cast $g$ into an appropriate form fulfilling $S({\\bf x})$, i.e., we use:\n$$ f:\\mathbb{R}^2\\rightarrow\\mathbb{R}^2: {\\bf x} \\mapsto \\begin{pmatrix} f_1({\\bf x}) \\\\\nf_2({\\bf x}) \\\\\n\\end{pmatrix} = \\begin{pmatrix} \\sqrt{2}(a-x_1) \\\\\n\\sqrt{2b}(x_2-x_1^2)\\\\\n\\end{pmatrix}, $$\ninstead of $g$. We can easily compute the Jacobian of $f$ manually\n$$ J = \\begin{pmatrix} -\\sqrt{2} \u0026amp; 0 \\\\\n-2x_1\\sqrt{2b} \u0026amp; \\sqrt{2b} \\\\\n\\end{pmatrix}. $$\nWe can then implement a (simple, non-optimized) version of the Gauss-Newton algorithm as follows.\n# bring Rosenbrock function into the form \u0026quot;sum of squares of functions\u0026quot; f1(x,p) = convert(eltype(x),sqrt(2))*(p[1]-x[1]) f2(x,p) = convert(eltype(x),sqrt(2*p[2]))*(x[2]-x[1]^2) f(x,p) = [f1(x,p),f2(x,p)] function f(res,x,p) # Enzyme works with inplace functions res[1] = f1(x,p) res[2] = f2(x,p) return nothing end ## manually pre-defined Jacobian function Jacobian(x,p) [-convert(eltype(x),sqrt(2)) 0 -2*x[1]*convert(eltype(x),sqrt(2*p[2])) convert(eltype(x),sqrt(2*p[2]))] end ## Gauss-Newton scheme function GaussNewton!(xs, x, p; maxiter=8, backend=nothing) for i=1:maxiter x = step(x, p, backend) @info i @show x push!(xs, x) end return xs, x end done(x,x2,p) = g(x2,p) \u0026lt; g(x,p) function step(x, p, backend::Nothing, α=1//1) x2 = deepcopy(x) while !done(x,x2,p) J = Jacobian(x,p) d = -inv(J'*J)*J'*f(x,p) copyto!(x2,x + α*d) α = α//2 end return x2 end  When we run the algorithm, we find the global minimum after about the 7th iteration.\nxs = [x₀] GaussNewton!(xs, x₀, p)  # output: [ Info: 1 ] x = [0.125, -0.08750000000000001] [ Info: 2 ] x = [0.234375, -0.047265625000000006] [ Info: 3 ] x = [0.4257812499999995, 0.06800537109374968] [ Info: 4 ] x = [0.5693359374999986, 0.21857223510742047] [ Info: 5 ] x = [0.784667968749996, 0.5165503501892037] [ Info: 6 ] x = [0.9999999999999961, 0.9536321163177449] [ Info: 7 ] x = [0.9999999999999989, 0.9999999999999999] [ Info: 8 ] x = [1.0, 1.0]  If computing the Jacobian by hand is too cumbersome (or not possible for other reasons), we can compute it using finite differences. Within the AbstractDifferentiation API, we can directly define, for instance, the Jacobian of FiniteDifferences.jl as a new primitive operation.\n## FiniteDifferences struct FDMBackend{A} \u0026lt;: AD.AbstractFiniteDifference alg::A end FDMBackend() = FDMBackend(central_fdm(5, 1)) const fdm_backend = FDMBackend() # Minimal interface AD.@primitive function jacobian(ab::FDMBackend, f, xs...) return FiniteDifferences.jacobian(ab.alg, f, xs...) end # AD Jacobian returns tuple # df_dx = AD.jacobian(fdm_backend, f(x,p), x₀, p)[1] # df_dp = AD.jacobian(fdm_backend, f(x,p), x₀, p)[2] @test AD.jacobian(fdm_backend, x-\u0026gt;f(x,p), x₀)[1] ≈ Jacobian(x₀, p) @test AD.jacobian(fdm_backend, f, x₀, p)[1] ≈ Jacobian(x₀, p)  After overloading the step function, we can run the Gauss-Newton algorithm as follows:\nfunction step(x, p, backend, α=1//1) x2 = deepcopy(x) while !done(x,x2,p) J = AD.jacobian(backend, f, x, p)[1] d = -inv(J'*J)*J'*f(x,p) copyto!(x2,x + α*d) α = α//2 end return x2 end xs = [x₀] GaussNewton!(xs, x₀, p, backend=fdm_backend)  If we want to use reverse-mode AD instead, for example via Zygote.jl, a natural choice for the primitive is to define the pullback function. AbstractDifferentiation then generates the associated code to compute the Jacobian for us.\n## Zygote struct ZygoteBackend \u0026lt;: AD.AbstractReverseMode end const zygote_backend = ZygoteBackend() AD.@primitive function pullback_function(ab::ZygoteBackend, f, xs...) return function (vs) # Supports only single output _, back = Zygote.pullback(f, xs...) if vs isa AbstractVector back(vs) else @assert length(vs) == 1 back(vs[1]) end end end ## @test minimum(AD.jacobian(fdm_backend, f, x₀, p) .≈ AD.jacobian(zygote_backend, f, x₀, p)) xs = [x₀] GaussNewton!(xs, x₀, p, backend=zygote_backend)  Typically, reverse-mode AD is only beneficial for functions $f:\\mathbb{R}^N\\rightarrow\\mathbb{R}^M$ where $M \\ll N$, thus it is also a good idea to compare the performance with respect to forward-mode AD ( ForwardDiff.jl)\n## ForwardDiff struct ForwardDiffBackend \u0026lt;: AD.AbstractForwardMode end const forwarddiff_backend = ForwardDiffBackend() AD.@primitive function pushforward_function(ab::ForwardDiffBackend, f, xs...) # jvp = f'(x)*v, i.e., differentiate f(x + h*v) wrt h at 0 return function (vs) if xs isa Tuple @assert length(xs) \u0026lt;= 2 if length(xs) == 1 (ForwardDiff.derivative(h-\u0026gt;f(xs[1]+h*vs[1]),0),) else ForwardDiff.derivative(h-\u0026gt;f(xs[1]+h*vs[1], xs[2]+h*vs[2]),0) end else ForwardDiff.derivative(h-\u0026gt;f(xs+h*vs),0) end end end ## @test minimum(AD.jacobian(fdm_backend, f, x₀, p) .≈ AD.jacobian(forwarddiff_backend, f, x₀, p)) xs = [x₀] GaussNewton!(xs, x₀, p, backend=forwarddiff_backend)  where we have used that the Jacobian-vector product $f'(x)v$, i.e., the primitives of forward-mode AD, can be computed by differentiating $f(x + hv)$ with respect to $h$ at 0.\nMany AD packages, such as Zygote, have troubles with mutating functions. Enzyme.jl is one of the exceptions. Additionally, it is very fast and has further improved the performance of the adjoints implemented within the DiffEqSensitivity package.\n## Enzyme struct EnzymeBackend{T1,T2,T3,T4} \u0026lt;: AD.AbstractReverseMode out::T1 λ::T2 ∂f_∂x::T3 ∂f_∂p::T4 end out = zero(x₀) λ = zero(x₀) ∂f_∂x = zero(x₀) ∂f_∂p = zero(p) const enzyme_backend = EnzymeBackend(out,λ,∂f_∂x,∂f_∂p) AD.@primitive function pullback_function(ab::EnzymeBackend, f, xs...) return function (vs) # enzyme works only with inplace functions if !(vs isa AbstractVector) @assert length(vs) == 1 # Supports only single output vs = vs[1] end if xs isa Tuple @assert length(xs) == 2 # hard-coded for use case with two inputs x₀ = xs[1] p = xs[2] end @unpack out, λ, ∂f_∂x, ∂f_∂p = ab # cached in the struct, could also be created in here ∂f_∂x .*= false ∂f_∂p .*= false out .*= false copyto!(λ, vs) autodiff(Duplicated(out, λ), Duplicated(x₀, ∂f_∂x), Duplicated(p, ∂f_∂p)) do _out,_x, _p f(_out,_x,_p) end return (∂f_∂x,∂f_∂p) end end AD.isinplace(ab::EnzymeBackend) = true AD.primalvalue(ab::EnzymeBackend, nothing, f, xs) = (f(ab.out,xs...);return ab.out) ## @test minimum(AD.jacobian(fdm_backend, f, x₀, p) .≈ AD.jacobian(enzyme_backend, f, x₀, p)) xs = [x₀] GaussNewton!(xs, x₀, p, backend=enzyme_backend)  Note that we have declared the Enzyme backend as inplace (which is important for internal control flow) and specified a primalvalue function returning the primal value of the forward pass.\nSome current glitches First, the push forward of a tuple of vectors, e.g., $(v_1, v_2)$, for a function with several input arguments is currently ambiguous. While AD.jacobian primitives and AD.pullback_function primitives interpret the push forward of our $f$ function as\n$$ \\left(\\frac{\\partial f(x_0,p)}{\\partial x} v_1 , \\frac{\\partial f(x_0,p)}{\\partial p} v_2 \\right), $$\nAD.pushforward_function primitives compute\n$$ \\frac{\\partial f(x_0,p)}{\\partial x} v_1 + \\frac{\\partial f(x_0,p)}{\\partial p} v_2. $$\n# pushforward_function wrt to multiple vectors is currently ambiguous vs = (randn(2), randn(2)) res1 = AD.pushforward_function(fdm_backend, f, x₀, p)(vs) res2 = AD.pushforward_function(forwarddiff_backend, f, x₀, p)(vs) @test res2 ≈ res1[1] + res1[2]  Thus, we currently solve this issue by augmenting the input in the case of AD.pushforward_function primitives.\nres2a = AD.pushforward_function(forwarddiff_backend, f, x₀, p)((vs[1], zero(vs[2]))) res2b = AD.pushforward_function(forwarddiff_backend, f, x₀, p)((zero(vs[1]), vs[2])) @test res2a ≈ res1[1] @test res2b ≈ res1[2]  The plural \u0026ldquo;primitives\u0026rdquo; is used here because we may have different pushforward_function primitives for different backends. For instance, we can define an additional pushforward_function primitive for FiniteDifferences by:\nstruct FDMBackend2{A} \u0026lt;: AD.AbstractFiniteDifference alg::A end FDMBackend2() = FDMBackend2(central_fdm(5, 1)) const fdm_backend2 = FDMBackend2() AD.@primitive function pushforward_function(ab::FDMBackend2, f, xs...) return function (vs) FDM.jvp(ab.alg, f, tuple.(xs, vs)...) end end  Second, to avoid misunderstandings for the output of a Hessian of a function with several input arguments, we allow only single input arguments to the Hessian function.\n# Hessian only defined with respect to single input variable @test_throws AssertionError H1 = AD.hessian(forwarddiff_backend, g, x₀, p) H1 = AD.hessian(forwarddiff_backend, x-\u0026gt;g(x,p), x₀) H2 = AD.hessian(forwarddiff_backend, p-\u0026gt;g(x₀,p), p)  Third, computing the Hessian requires to nest AD/backend calls. This can lead to failure if one tries to use Zygote over Zygote. To solve this problem, we have implemented a HigherOrderBackend that takes a tuple containing multiple backends (because, for example, using ForwardDiff over Zygote is perfectly fine).\n# Hessian might fail if AD system calls must not be nested (e.g. Zygote over Zygote) backends = AD.HigherOrderBackend((forwarddiff_backend,zygote_backend)) H3 = AD.hessian(backends, x-\u0026gt;g(x,p), x₀)  Outlook There are many other use cases, e.g.,\n  Sensitivity analysis of differential equations requires vector-Jacobian products for adjoint methods and Jacobian-vector products for tangent methods. The Newton–Raphson method for rootfinding requires the gradient in the case of scalar function $f:\\mathbb{R}\\rightarrow\\mathbb{R}$ and the Jacobian in case of $N$ (nonlinear) equations, i.e., finding the zeros of $f:\\mathbb{R}^N\\rightarrow\\mathbb{R}^N$. The Newton method in optimization requires the computation of the Hessian.  AbstractDifferentiation.jl is by no means complete yet. We are still in the very early stages, but we hope to make significant progress in the coming weeks. Some of the next steps are:\n fixing remaining bugs, e.g., with respect to the computation of the Hessian and adding AD/Finite Differentiation packages such as Diffractor.  If you have any questions or comments, please don’t hesitate to contact me!\n  Mike Innes, Alan Edelman, et al., arXiv preprint arXiv:1907.07587 (2019). \u0026#x21a9;\u0026#xfe0e;\n Jeff Bezanson, Stefan Karpinski, et al., arXiv preprint arXiv:1209.5145 (2012). \u0026#x21a9;\u0026#xfe0e;\n Chris Rackauckas, The Winnower 8, DOI: 10.15200/winn.156631.13064 (2019). \u0026#x21a9;\u0026#xfe0e;\n Chris Rackauckas, Yingbo Ma, et al., arXiv preprint arXiv:2001.04385 (2020). \u0026#x21a9;\u0026#xfe0e;\n Raj Dandekar, Chris Rackauckas, et al., Patterns 1, 100145 (2020). \u0026#x21a9;\u0026#xfe0e;\n Frank Schäfer, Michal Kloc, et al., Mach. Learn.: Sci. Technol. 1, 035009 (2020). \u0026#x21a9;\u0026#xfe0e;\n Frank Schäfer, Pavel Sekatski, et al., Mach. Learn.: Sci. Technol. 2, 035004 (2021). \u0026#x21a9;\u0026#xfe0e;\n   ","date":1627812197,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627812197,"objectID":"d9ff4a599f5556fadd3c7cc978b481a3","permalink":"https://frankschae.github.io/post/abstract_differentiation/","publishdate":"2021-08-01T12:03:17+02:00","relpermalink":"/post/abstract_differentiation/","section":"post","summary":"Differentiable programming (∂P), i.e., the ability to differentiate general computer program structures, has enabled the efficient combination of existing packages for scientific computation and machine learning1. The Julia2 language is well suited for ∂P, see also Chris' article3 for a detailed examination.","tags":["GSoC 2021","julia","Automatic Differentiation","AbstractDifferentiation.jl"],"title":"AbstractDifferentiation.jl for AD-backend agnostic code ","type":"post"},{"authors":["Frank Schäfer and Moritz Schauer"],"categories":[],"content":"In this post, we discuss sensitivity analysis of hybrid differential equations1 and highlight differences between explicit2 and implicit discontinuities3 4. As a paradigmatic example, we consider a bouncing ball described by the ODE\n$$ \\begin{aligned} \\text{d}z(t) \u0026amp;= v(t) \\text{d}t, \\\\\n\\text{d}v(t) \u0026amp;= -g \\text{d}t \\end{aligned}\n$$\nwith initial condition\n$$ \\begin{aligned} z(t=0) \u0026amp;= z_0 = 5, \\\\\nv(t=0) \u0026amp;= v_0 = -0.1. \\end{aligned}\n$$\nThe initial condition contains the initial height $z_0$ and initial velocity $v_0$ of the ball. We have two important parameters in this system. First, there is the gravitational constant $g=10$ modeling the acceleration of the ball due to an approximately constant gravitational field. Second, we include a dissipation factor $\\gamma=0.8$ ( coefficient of restitution) that accounts for a non-perfect elastic bounce on the ground.\nWhen ignoring the bounce, we can straightforwardly integrate the ODE analytically\n$$ \\begin{aligned} z(t) \u0026amp;= z_0 + v_0 t - \\frac{g}{2} t^2, \\\\\nv(t) \u0026amp;= v_0 - g t \\end{aligned}\n$$\nor numerically using the OrdinaryDiffEq package from the SciML ecosystem.\nusing ForwardDiff, Zygote, OrdinaryDiffEq, DiffEqSensitivity using Plots, LaTeXStrings ## ### simulate forward function f(du,u,p,t) du[1] = u[2] du[2] = -p[1] end z0 = 5.0 v0 = -0.1 t0 = 0.0 tend = 1.9 g = 10 γ = 0.8 u0 = [z0,v0] tspan = (t0,tend) p = [g, γ] prob = ODEProblem(f,u0,tspan,p) # plot forward trajectory sol = solve(prob,Tsit5(),saveat=0.1) pl = plot(sol, label = [\u0026quot;z(t)\u0026quot; \u0026quot;v(t)\u0026quot;], labelfontsize=20, legendfontsize=20, lw = 2, xlabel = \u0026quot;t\u0026quot;, legend=:bottomleft) hline!(pl, [0.0], label=false, color=\u0026quot;black\u0026quot;) savefig(pl,\u0026quot;BB_forward_no_bounce.png\u0026quot;)    Forward simulation with events At around $t^\\star \\approx 1$, the ball hits the ground $z^\\star(t^\\star) = 0$, and is inelastically reflected while dissipating a fraction of its energy. This can be modeled by re-initializing the ODE with new initial conditions\n$$ \\begin{aligned}\nz_+\u0026amp;= \\lim_{t \\rightarrow {t^\\star}^+} z(t) = \\lim_{t \\rightarrow {t^\\star}^-} z(t) = z_- ,\\\\\nv_+\u0026amp;= \\lim_{t \\rightarrow {t^\\star}^+} v(t) = -\\gamma \\lim_{t \\rightarrow {t^\\star}^-} v(t) = -\\gamma v_- \\end{aligned}\n$$\non the right-hand side of the event. Given our analytical solution for the state as a function of time, we can easily compute the event time $t^\\star$ as\n$$ t^\\star = \\frac{v_0 + \\sqrt{v_0^2 + 2 g z_0}}{g}. $$\nExplicit events We can define the bounce of the ball as an explicit event by inserting the values of the initial condition and the parameters into $t^\\star$. We obtain\n$$ t^\\star = 0.99005. $$\nThe full trajectory $z_{\\rm exp}(t)$ is determined by\n$$ z_{\\rm exp}(t) = \\begin{cases} z^{(1)}_{\\rm exp}(t) \u0026amp;=z_0 + v_0 t - \\frac{g}{2} t^2 \u0026amp;, \\forall t \\leq t^\\star, \\\\\nz^{(2)}_{\\rm exp}(t) \u0026amp;=-0.4901 g - 0.5 g (-0.99005 + t)^2 +\\\\\n\u0026amp;+0.99005 v_0 + z_0 - (-0.99005 + t) (-0.99005 g + v_0)\\gamma \u0026amp;, \\forall t \u0026gt; t^\\star, \\end{cases} $$\nwhere we used:\n$$ \\begin{aligned}\nz_{-, \\rm exp}\u0026amp;= z_0 + 0.99005 v_0 -0.4901 g,\\\\\nv_{-, \\rm exp}\u0026amp;= (v_0 - 0.99005 g) . \\end{aligned}\n$$\nand\n$$ \\begin{aligned}\nz_{+, \\rm exp}\u0026amp;= z_0 + 0.99005 v_0 -0.4901 g, \\\\\nv_{+, \\rm exp}\u0026amp;= -(v_0 - 0.99005 g) \\gamma . \\end{aligned}\n$$\nNumerically, we use a DiscreteCallback in this case to simulate the system\n# DiscreteCallback (explicit event) tstar = (v0 + sqrt(v0^2+2*z0*g))/g condition1(u,t,integrator) = (t == tstar) affect!(integrator) = integrator.u[2] = -integrator.p[2]*integrator.u[2] cb1 = DiscreteCallback(condition1,affect!,save_positions=(true,true)) sol1 = solve(prob,Tsit5(),callback=cb1, saveat=0.1, tstops=[tstar])  Evidently, by choosing an explicit definition of the event, the impact time is fixed. The reflection event is triggered at $t^\\star = 0.99005$, a time where under different initial configurations the ball perhaps hasn’t reached the ground.\nImplicit events The physically more meaningful description of a bouncing ball is therefore given by an implicit description of the event in form of a condition (event function)\n$$ g(z,v,p,t) = z(t), $$\nwhere an event occurs if $g(z^\\star,v^\\star,p,t^\\star) = 0$. Note that we have already used this condition to define our impact time $t^\\star$ of the explicit event.\nAs in the previous case, we can analytically compute the full trajectory of the ball. At the event time, we have\n\\begin{aligned}\nz_{-, \\rm imp}\u0026amp;= 0, \\\\\nv_{-, \\rm imp}\u0026amp;= - \\sqrt{v_0^2 + 2 g z_0} \\end{aligned}\nfor the left and\n\\begin{aligned}\nz_{+, \\rm imp}\u0026amp;= 0 \\\\\nv_{+, \\rm imp}\u0026amp;= \\gamma \\sqrt{v_0^2 + 2 g z_0}. \\end{aligned}\nfor the right limit. Thus, the full trajectory $z_{\\rm imp}(t)$ is given by\n$$ z_{\\rm imp}(t) = \\begin{cases} z^{(1)}_{\\rm imp}(t) \u0026amp;=z_0 + v_0 t - \\frac{g}{2} t^2 \u0026amp;, \\forall t \\leq t^\\star ,\\\\\nz^{(2)}_{\\rm imp}(t) \u0026amp;= -\\frac{(-g t + v_0 + \\sqrt{v_0^2 + 2 g z_0})}{2 g} \\times, \\\\\n\u0026amp;\\times (-g t + v_0 + \\sqrt{v_0^2 + 2 g z_0} (1 + 2 \\gamma)) \u0026amp;, \\forall t \u0026gt; t^\\star. \\end{cases} $$\nNumerically, we use a ContinuousCallback in this case.\n# ContinuousCallback (implicit event) condition2(u,t,integrator) = u[1] # Event when condition(u,t,integrator) == 0 cb2 = ContinuousCallback(condition2,affect!,save_positions=(true,true)) sol2 = solve(prob,Tsit5(),callback=cb2,saveat=0.1)  We can verify that both callbacks lead to the same forward time evolution (for fixed initial conditions and parameters).\n# plot forward trajectory pl1 = plot(sol1, label = [\u0026quot;z(t)\u0026quot; \u0026quot;v(t)\u0026quot;], title=\u0026quot;explicit event\u0026quot;, labelfontsize=20, legendfontsize=20, lw = 2, xlabel = \u0026quot;t\u0026quot;, legend=:bottomright) pl2 = plot(sol2, label = [\u0026quot;z(t)\u0026quot; \u0026quot;v(t)\u0026quot;], title=\u0026quot;implicit event\u0026quot;, labelfontsize=20, legendfontsize=20, lw = 2, xlabel = \u0026quot;t\u0026quot;, legend=:bottomright) hline!(pl1, [0.0], label=false, color=\u0026quot;black\u0026quot;) hline!(pl2, [0.0], label=false, color=\u0026quot;black\u0026quot;) pl = plot(pl1,pl2) savefig(pl,\u0026quot;BB_forward.png\u0026quot;)    In addition, the implicitly defined impact time via the ContinuousCallback also shifts the impact time when changing the initial conditions or the parameters. In other words, the event time $t^\\star=t^\\star(p,z_0,v_0,t_0)$ is a function of the parameters and initial conditions, and is implicitly defined by the event condition.\nSuppose we let the ball drop from a somewhat higher position now. Does an increase in height at $t=0$ give an increase or decrease in height at the end time $t_\\text{end}=1.9$? This is something we can answer with sensitivity analysis. For example if we increase the height by (a fraction of) one unit then\n$$ \\frac{\\text{d} z_{\\rm imp}(t_\\text{end})}{\\text{d} z_0} = \\frac{\\text{d} z_{\\rm imp}^{(2)}(t_\\text{end})}{\\text{d} z_0} = 0.84, $$\nmeaning the height at $t_\\text{end}$ is also by a corresponding fraction of 0.84 units higher.\nWe can verify this visually:\n# animate forward trajectory sol3 = solve(remake(prob,u0=[u0[1]+0.5,u0[2]]),Tsit5(),callback=cb2,saveat=0.01) plt2 = plot(sol2, label = false, labelfontsize=20, legendfontsize=20, lw = 1, xlabel = \u0026quot;t\u0026quot;, legend=:bottomright, color=\u0026quot;black\u0026quot;, xlims=(t0,tend)) hline!(plt2, [0.0], label=false, color=\u0026quot;black\u0026quot;) plot!(plt2, sol3, tspan=(t0,tend), color=[1 2], label = [\u0026quot;z(t)\u0026quot; \u0026quot;v(t)\u0026quot;], labelfontsize=20, legendfontsize=20, lw = 2, xlabel = \u0026quot;t\u0026quot;, legend=:bottomright, denseplot=true, xlims=(t0,tend), ylims=(-11,9)) # scatter!(plt2, [t2,t2], sol3(t2), color=[1, 2], label=false) list_plots = [] for t in sol3.t tstart = 0.0 plt1 = plot(sol2, label = false, labelfontsize=20, legendfontsize=20, lw = 1, xlabel = \u0026quot;t\u0026quot;, legend=:bottomright, color=\u0026quot;black\u0026quot;) hline!(plt1, [0.0], label=false, color=\u0026quot;black\u0026quot;) plot!(plt1, sol3, tspan=(t0,t), color=[1 2], label = [\u0026quot;z(t)\u0026quot; \u0026quot;v(t)\u0026quot;], labelfontsize=20, legendfontsize=20, lw = 2, xlabel = \u0026quot;t\u0026quot;, legend=:bottomright, denseplot=true, xlims=(t0,tend), ylims=(-11,9)) scatter!(plt1,[t,t], sol3(t), color=[1, 2], label=false) plt = plot(plt1,plt2) push!(list_plots, plt) end plot(list_plots[100]) anim = animate(list_plots,every=1)    The original curve is shown in black in the figure above.\nSensitivity analysis with events More generally, we are often interested in computing the change of a loss function with respect to changes of the parameters or initial condition. Suppose that you have a mean square error loss function\n$$ L(z,y) = \\sum_i(z(t_i) - y_i)^2 $$\nwith respect to target values $y_i$ at time points $t_i$ incident before, after, or at the event time. Let $\\alpha$ denote any of the inputs $(z_0,v_0,g,\\gamma)$. The sensitivity with respect to $\\alpha$ is then given by the chain rule:\n$$ \\frac{\\text{d}L}{\\text{d} \\alpha} = 2\\sum_i (z(t_i) - y_i) \\frac{\\text{d}z(t_i)}{\\text{d} \\alpha}. $$\nFor the bouncing ball, we can easily compute the sensitivity $\\frac{\\text{d}L}{\\text{d} \\alpha}$ by inserting our results for $z_{\\rm imp}(t_i)$. Using the explicit event $z_{\\rm exp}(t_i)$ instead of the implicit event $z_{\\rm imp}(t_i)$, a different value for the sensitivity is obtained and not the one we are looking for.\nHowever, in most systems, we won\u0026rsquo;t be able to solve analytically a differential equation\n$$ \\text{d}x(t) = f(x,p,t) \\text{d}t $$\nwith initial condition $x_0=x(t_0)$. Instead, we have to numerically solve for the trajectory $x(t)$. Regarding the computation of the sensitivities, we may then choose one of the available algorithms for the given differential equation. Currently, BacksolveAdjoint(), InterpolatingAdjoint(), QuadratureAdjoint(), ReverseDiffAdjoint(), TrackerAdjoint(), and ForwardDiffAdjoint() are compatible with events in ordinary differential equations. We write the loss function in the following as a function of time, state, and parameters\n$$ \\begin{aligned} L = L(t,x,p). \\end{aligned} $$\nLet us focus on the BacksolveAdjoint() algorithm, which computes the sensitivities\n$$ \\begin{aligned} \\frac{\\text{d}L}{\\text{d}x(t_{0})} \u0026amp;= \\lambda(t_{0}),\\\\\n\\frac{\\text{d}L}{\\text{d}p} \u0026amp;= \\lambda_{p}(t_{0}), \\end{aligned} $$\nwith respect to the initial state and the parameters, by solving an ODE for $\\lambda(t)$ in reverse time from $t_N$ to $t_0$\n$$ \\begin{aligned} \\frac{\\text{d}\\lambda(t)}{\\text{d}t} \u0026amp;= -\\lambda(t)^\\dagger \\frac{\\text{d} f(\\rightarrow x(t), p, t)}{\\text{d} x(t)} - \\frac{\\text{d} L(t, \\rightarrow x(t), p)}{\\text{d} x(t)}^\\dagger \\delta(t-t_i), \\\\\n\\frac{\\text{d}\\lambda_{p}(t)}{\\text{d}t} \u0026amp;= -\\lambda(t)^\\dagger \\frac{\\text{d} f(x(t), \\rightarrow p, t)}{\\text{d} p}, \\end{aligned} $$\nwith initial conditions:\n$$ \\begin{aligned} \\lambda(t_{N})\u0026amp;= 0, \\\\\n\\lambda_{p}(t_{N}) \u0026amp;= 0. \\end{aligned} $$\nThe arrows ($\\rightarrow$) indicate the variable with respect to which we differentiate. Note that computing the vector-Jacobian products (vjp) in the adjoint ODE requires the value of $x(t)$ along its trajectory. In BacksolveAdjoint(), we recompute $x(t)$\u0026ndash;together with the adjoint variables\u0026ndash;backwards in time starting with its final value $x(t_N)$. A derivation of the ODE adjoint is given in Chris' MIT 18.337 lecture notes.\nExplicit events To make BacksolveAdjoint() compatible with explicit events2, we have to store the event times $t^\\star_j$ as well as the state $x({t_j^\\star}^-)$ and parameters $p=p({t_j^\\star}^-)$ (if they are changed) at the left limit of $t^\\star_j$. We then solve the adjoint ODE backwards in time between the events. As soon as we reach an event from the right limit ${t_j^\\star}^+$, we update the augmented state according to\n$$ \\begin{aligned} \\lambda({t_j^\\star}^-) \u0026amp;= \\lambda({t_j^\\star}^+)^\\dagger \\frac{\\text{d} a(\\rightarrow x({t_j^\\star}^-), p({t_j^\\star}^-), {t_j^\\star}^-)}{\\text{d} x({t_j^\\star}^-)} \\\\\n\\lambda_p({t_j^\\star}^-) \u0026amp;= \\lambda_p({t_j^\\star}^+) - \\lambda({t_j^\\star}^+)^\\dagger \\frac{\\text{d} a(x({t_j^\\star}^-), \\rightarrow p({t_j^\\star}^-), {t_j^\\star}^-)}{\\text{d} p({t_j^\\star}^-)} \\end{aligned} $$\nwhere $a$ is the affect function applied at the discontinuity. That is, to lift the adjoint from the right to the left limit, we compute a vjp with the adjoint $\\lambda({t_j^\\star}^+)$ at the right limit and the Jacobian of the affect function evaluated on the left limit.\nIn particular, we apply a loss function callback before and after this update if the state was saved in the forward evolution and entered directly into the loss function.\nImplicit events Special case: event as termination condition Define $u(t) = (t, x(t))$. Let us first re-derive the case, where the implicit event terminates the ODE and where we have a loss function acting on $t^\\star_1$, $x(t^\\star_1)$, and $p$, as considered by Ricky T. Q. Chen, Brandon Amos, and Maximilian Nickel in their ICLR 2021 paper4. We are interested in\n$$ \\frac{\\text{d}L(u(t^\\star_1(\\rightarrow p), \\rightarrow p), \\rightarrow p)}{\\text{d}p} = \\frac{\\text{d}L(t^\\star_1({\\color{black}\\rightarrow} p), \\text{solve}(t_0, x_0, t^\\star_1({\\color{black}\\rightarrow}p), \\rightarrow p),\\rightarrow p)}{\\text{d}p}, $$\nwhich indicates that changing $p$ changes both $t^\\star_1$ as well as $x^\\star_1$ in $t^\\star_1$. Therefore, the sensitivity of the event time with respect to parameters $\\frac{\\text{d}t^\\star}{\\text{d}p}$ or initial conditions $\\frac{\\text{d}t^\\star}{\\text{d}z_0}$, $\\frac{\\text{d}t^\\star}{\\text{d}v_0}$ must be taken into account.\nIn a first step, we need to compute the sensitivity of $t^\\star_1(p)$ with respect to $p$ and $x_0$ based on the event condition $F(t, p) = g(u(t, p)) = 0$. We can apply the implicit function theorem which yields:\n$$ \\begin{aligned} \\frac{\\text{d}t^\\star_1(p)}{\\text{d}p} \u0026amp;= - \\left(\\frac{\\text{d}g(\\rightarrow t^\\star_1, \\text{solve}(t_0, x_0, \\rightarrow t^\\star_1, p))}{\\text{d}t^\\star_1}\\right)^{-1} \\frac{\\text{d}g(t^\\star_1, \\text{solve}(t_0, x_0, t^\\star_1, \\rightarrow p))}{\\text{d}p} .\\\\\n\\end{aligned} $$\nThe total derivative5 inside the bracket is defined as: $$ \\begin{aligned} \\frac{\\text{d}g}{\\text{d}t^\\star_1} \\stackrel{\\text{def}}{=} \\frac{\\text{d}g(\\rightarrow t^\\star_1, \\text{solve}(t_0, x_0, \\rightarrow t^\\star_1, p))}{\\text{d}t^\\star_1} \u0026amp;= \\frac{\\text{d}g(\\rightarrow t^\\star_1, \\text{solve}(t_0, x_0, t^\\star_1, p))}{\\text{d}t^\\star_1} + \\frac{\\text{d}g(t^\\star_1, \\text{solve}(t_0, x_0, \\rightarrow t^\\star_1, p))}{\\text{d}t^\\star_1}\\\\\n\\end{aligned} $$\nSince\n$$ \\frac{\\text{d}(\\text{solve}(t_0, x_0, \\rightarrow t^\\star_1, p))}{\\text{d}t^\\star_1} = f(x^\\star, p^\\star, t^\\star_1) $$\nby definition of the ODE, we can write\n$$ \\begin{aligned} \\frac{\\text{d}g(t^\\star_1, \\text{solve}(t_0, x_0, \\rightarrow t^\\star_1, p))}{\\text{d}t^\\star_1} = \\frac{\\text{d}g(t^\\star_1, \\text{solve}(t_0, x_0, \\rightarrow t^\\star_1, p))}{\\text{d} u^\\star(t^\\star_1)} f(x^\\star, p^\\star, t^\\star_1). \\end{aligned} $$\nFurthermore, we have $$ \\begin{aligned} \\frac{\\text{d}g(t^\\star_1, \\text{solve}(t_0, x_0, t^\\star_1, \\rightarrow p))}{\\text{d}p} = \\frac{\\text{d}g(t^\\star_1, \\text{solve}(t_0, x_0, t^\\star_1,\\rightarrow p))}{\\text{d} u^\\star(t^\\star_1)}^\\dagger \\frac{\\text{d}\\text{ solve}(t_0, x_0, t^\\star_1,\\rightarrow p))}{\\text{d}p} \\end{aligned} $$ for the second term of $\\frac{\\text{d}t^\\star_1(p)}{\\text{d}p}$. We define\n$$ \\frac{\\text{d}g}{\\text{d}u^\\star_1} \\stackrel{\\text{def}}{=} \\frac{\\text{d}g(t^\\star_1, \\text{solve}(t_0, x_0, t^\\star_1,\\rightarrow p))}{\\text{d} u^\\star(t^\\star_1)} $$\nWe can now write the gradient as:\n$$ \\begin{aligned} \\frac{\\text{d}L(t^\\star_1({\\color{black}\\rightarrow} p), \\text{solve}(t_0, x_0, t^\\star_1({\\color{black}\\rightarrow}p), \\rightarrow p),\\rightarrow p)}{\\text{d}p} \u0026amp;= \\frac{\\text{d}L(t^\\star_1(p), \\text{solve}(t_0, x_0, t^\\star_1(p), p), \\rightarrow p)}{\\text{d}p} \\\\\n+\u0026amp; \\frac{\\text{d}L(t^\\star_1(p), \\text{solve}(t_0, x_0, t^\\star_1(p), \\rightarrow p), p)}{\\text{d}p} \\\\\n+\u0026amp; \\frac{\\text{d}L(\\rightarrow t^\\star_1(p), \\text{solve}(t_0, x_0, \\rightarrow t^\\star_1(p), p), p)}{\\text{d}t^\\star_1} \\frac{\\text{d} t^\\star_1(p)}{\\text{d}p}, \\end{aligned} $$\nwhich, after insertion of our results above, can be casted into the form:\n$$ \\begin{aligned} \\frac{\\text{d}L(t^\\star_1({\\color{black}\\rightarrow} p), \\text{solve}(t_0, x_0, t^\\star_1({\\color{black}\\rightarrow}p), \\rightarrow p),\\rightarrow p)}{\\text{d}p} \u0026amp;= v^\\dagger \\frac{\\text{d}\\text{ solve}(t_0, x_0, t^\\star_1(p), \\rightarrow p)}{\\text{d}p} \\\\\n\u0026amp;+ \\frac{\\text{d}L(t^\\star_1(p), \\text{solve}(t_0, x_0, t^\\star_1(p), p), \\rightarrow p)}{\\text{d}p}, \\end{aligned} $$\nwith\n$$ \\begin{aligned} v \u0026amp;= \\xi \\left(-\\frac{\\text{d}g}{\\text{d}t^\\star_1}\\right)^{-1} \\frac{\\text{d}g}{\\text{d}u^\\star_1} + \\frac{\\text{d}L(t^\\star_1(p), \\text{solve}(t_0, x_0, t^\\star_1(p), p), p)}{\\text{d} u^\\star(t^\\star_1)}, \\end{aligned} $$\nwhere we introduced the scalar pre-factor\n$$ \\begin{aligned} \\xi = \\left( \\frac{\\text{d}L(\\rightarrow t^\\star_1(p), \\text{solve}(t_0, x_0, t^\\star_1(p), p), p)}{\\text{d}t^\\star_1} + \\frac{\\text{d}L(t^\\star_1(p), \\text{solve}(t_0, x_0, t^\\star_1(p), p), p)}{\\text{d} u^\\star(t^\\star_1)}^\\dagger f(x^\\star, p^\\star, t^\\star_1)\\right). \\end{aligned} $$\nThis means that if we terminate the ODE integration by an implicit event, we compute the sensitivities as follows (for simplicity we drop terms due to an explicit dependence of the loss function on the parameters or time):\n use an ODE solver to solve forward until the event is triggered $$ u_i = \\text{solve}(t_0, x_0, t^\\star_1(p), p). $$ $u_i(t_i)=(t_i,x_i)$ are the stored values which enter the loss function. compute the loss function gradient with respect to the state at $t^\\star_1$. $$ \\lambda_-^\\text{0} = \\frac{\\text{d}L(t^\\star_1(p), \\rightarrow \\text{solve}(t_0, x_0, t^\\star_1(p), p), p)}{\\text{d} u^\\star(t^\\star_1)}. $$ (instead of using the BacksolveAdjoint() algorithm with $\\lambda_-^\\text{0}$ directly,) use the corrected version containing the dependence on the event time. For this, compute $\\frac{\\text{d}g}{\\text{d}t^\\star_1}, \\frac{\\text{d}g}{\\text{d}u^\\star_1}$, and $f(x^\\star, p, t^\\star_1)$. Then, the corrected version of the adjoint is given by  $$ \\lambda_- = - \\left( {\\lambda_-^\\text{0}}^\\dagger f(x^\\star, p^\\star, t^\\star_1) \\right)\\left(\\frac{\\text{d}g}{\\text{d}t^\\star_1}\\right)^{-1} \\frac{\\text{d}g}{\\text{d}u^\\star_1} + \\lambda_-^\\text{0}. $$\n$\\lambda_-$ can then be used as initial condition to $\\text{backsolve_adjoint}(\\lambda_-, t^\\star_1, x(t^\\star_1), t_0)$ which backpropagates the adjoint $\\lambda_-$ from $t^\\star_1$ to $t_0$.\nIf there is an additional affect function $a$ associated with the event, i.e. a right limit, we must additionally compute\n$$ \\begin{aligned} \\lambda_+^\\text{0} = \\frac{\\text{d}L(t^\\star_1(p), \\rightarrow a\\left(\\text{solve}(t_0, x_0, t^\\star_1(p), p)\\right), p)}{\\text{d} u^\\star(t^\\star_1))}. \\end{aligned} $$\nCompute the vjp as in the case of a \u0026lsquo;DiscreteCallback\u0026rsquo;\n$$ \\lambda_-^\\text{0} = {\\lambda_+^\\text{0}}^\\dagger \\frac{\\text{d} a(\\rightarrow x({t_j^\\star}^-), p({t_j^\\star}^-), {t_j^\\star}^-)}{\\text{d} x({t_j^\\star}^-)} $$\nand correct it as above\n$$ \\begin{aligned} \\lambda_- = - \\left( {\\lambda_-^\\text{0}}^\\dagger f(x({t_1^\\star}^-), p({t_1^\\star}^-), t^\\star_1) \\right)\\left(\\frac{\\text{d}g}{\\text{d}{t_1^\\star}^-}\\right)^{-1} \\frac{\\text{d}g}{\\text{d}{u^\\star_1}^-} + \\lambda_-^\\text{0}. \\end{aligned} $$\nIf both limits contribute to the loss function, the contributions are added.\nGeneralization: several events As pointed out by Chen et al. as well as by Timo C. Wunderlich and Christian Pehle3, one can chain together the events and differentiate through the entire time evolution on a time interval $(t_0, t_{\\text{end}})$. That is, we are generally allowed to segment the time evolution over an interval $[t_0, t]$ into one from $[t_0, s]$ and a subsequent one from $[s, t]$:\n$$ \\text{solve}(t_0, x_0, t, p) = \\text{solve}(s, \\text{solve}(t_0, x_0, s, p), t-s, p), $$\nsuch that also loss function contributions are chained. Therefore, we have the following modification:\n  Segment the trajectory at the event times. Use $\\text{backsolve_adjoint}(\\lambda_{0}, t_\\text{end}, x(t_\\text{end}), t^\\star_N)$ to backprogagate the loss function gradient from the final state until the right limit of the last event location.\n  In addition to the steps above, subtract a correction:\n  $$ \\lambda_\\text{c} = - \\left( {\\lambda_+}^\\dagger f(x({t_N^\\star}^+), p({t_N^\\star}^+), t^\\star_N) \\right)\\left(\\frac{\\text{d}g}{\\text{d}{t_N^\\star}^-}\\right)^{-1} \\frac{\\text{d}g}{\\text{d}{u^\\star_N}^-}, $$\nwhere $\\lambda_+$ is the right-hand limit of the adjoint state before the loss gradient ($\\lambda_+^\\text{0}$ above) was added. Iterate over the remaining $N-1$ events.\nOutlook We are still refining the adjoints in case of implicit discontinuities (ContinuousCallbacks). For further information, the interested reader is encouraged to track the associated issues #383 and #374, and PR #445 in the DiffEqSensitivity.jl package.\nIf you have any questions or comments, please don’t hesitate to contact me!\n  Michael Poli, Stefano Massaroli, et al., arXiv preprint arXiv:2106.04165 (2021). \u0026#x21a9;\u0026#xfe0e;\n Junteng Jia, Austin R. Benson, arXiv preprint arXiv:1905.10403 (2019). \u0026#x21a9;\u0026#xfe0e;\n Timo C. Wunderlich and Christian Pehle, Sci. Rep. 11, 12829 (2021). \u0026#x21a9;\u0026#xfe0e;\n Ricky T. Q. Chen, Brandon Amos, Maximilian Nickel, arXiv preprint arXiv:2011.03902 (2020). \u0026#x21a9;\u0026#xfe0e;\n For a function $f$ of more than one variable $y = f(t, x_1(t),x_2(t),\\dots,x_N(t))$, the total derivative with respect to the independent variable $t$ is given by the sum of all partial derivatives $$ \\begin{aligned} \\frac{\\text{d}y}{\\text{d}t} \u0026amp;= \\frac{\\text{d}f(\\rightarrow t, x_1(\\rightarrow t),x_2(\\rightarrow t),\\dots,x_N(\\rightarrow t))}{\\text{d}t} \\\\\n\u0026amp;= \\frac{\\text{d}f(\\rightarrow t, x_1(t),x_2(t),\\dots,x_N(t))}{\\text{d}t} + \\frac{\\text{d}f(t, x_1(\\rightarrow t),x_2(t),\\dots,x_N(t))}{\\text{d}t}\\\\\n\u0026amp;+ \\frac{\\text{d}f(t, x_1(t),x_2(\\rightarrow t),\\dots,x_N(t))}{\\text{d}t} + \\dots + \\frac{\\text{d}f(t, x_1(t),x_2(t),\\dots,x_N(\\rightarrow t))}{\\text{d}t}. \\end{aligned} $$ \u0026#x21a9;\u0026#xfe0e;\n   ","date":1626434644,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1626434644,"objectID":"a60e1fb7808c483d902fff1d56e2a3a3","permalink":"https://frankschae.github.io/post/bouncing_ball/","publishdate":"2021-07-16T13:24:04+02:00","relpermalink":"/post/bouncing_ball/","section":"post","summary":"In this post, we discuss sensitivity analysis of hybrid differential equations1 and highlight differences between explicit2 and implicit discontinuities3 4. As a paradigmatic example, we consider a bouncing ball described by the ODE","tags":["GSoC 2021","Hybrid differential equations","Adjoint sensitivity methods","Event handling"],"title":"Sensitivity Analysis of Hybrid Differential Equations","type":"post"},{"authors":[],"categories":[],"content":"In this post, we dig into sensitivity analysis of chaotic systems. Chaotic systems are dynamical, deterministic systems that are extremely sensitive to small changes in the initial state or the system parameters. Specifically, the dependence of a chaotic system on its initial conditions is well known as the \u0026ldquo;butterfly effect\u0026rdquo;. Chaotic models are encountered in various fields ranging from simple examples such as the double pendulum to highly complicated fluid or climate models.\nSensitivity analysis methods have proven to be very powerful for solving inverse problems such as parameter estimation or optimal control1 2 3. However, conventional sensitivity analysis methods may fail in chaotic systems due to the ill-conditioning of the initial value problem. Sophisticated methods, such as least squares shadowing4 (LSS) or non-intrusive least squares shadowing5 (NILSS) have been developed in the last decade. Essentially, these methods transform the initial value problem to a well conditioned optimization problem \u0026ndash; the least squares shadowing problem. In this second part of my GSoC project, I implemented the LSS and the NILSS method within the DiffEqSensitivity.jl package.\nThe objective for LSS and NILSS is a long-time average quantity. More precisely, we define the instantaneous objective by $g(u,p)$, where $u$ is the state and $p$ is the parameter of the differential equation. Then, the objective is obtained by averaging $g$ over an infinitely long trajectory:\n$$ \\langle g \\rangle_∞ = \\lim_{T \\rightarrow ∞} \\langle g \\rangle_T, $$ where $$ \\langle g \\rangle_T = \\frac{1}{T} \\int_0^T g(u,s) \\text{d}t. $$ Under the assumption of ergodicity, $\\langle g \\rangle_∞$ only depends on $p$.\nThe Lorenz system One of the most important chaotic models is the Lorenz system which is a simplified model for atmospheric convection. The Lorenz system has three states $x$, $y$, and $z$, as well as three parameters $\\rho$, $\\sigma$, and $\\beta$. Its time evolution is given by the ODE:\n$$ \\begin{pmatrix} \\text{d}x \\\\\n\\text{d}y \\\\\n\\text{d}z \\\\\n\\end{pmatrix} = \\begin{pmatrix} \\sigma (y-x)\\\\\nx(\\rho-z) - y\\\\\nx y - \\beta z \\\\\n\\end{pmatrix}\\text{d}t $$\nFor simplicity, let us fix $\\sigma=10$ and $\\beta=8/3$ and focus only on the sensitivity with respect to $\\rho$. The classic Lorenz attractor is obtained when using $\\rho=28$:\nusing Random; Random.seed!(1234) using OrdinaryDiffEq using Statistics using QuadGK, ForwardDiff, Calculus using DiffEqSensitivity using SparseArrays, LinearAlgebra # simulate 1 trajectory of the Lorenz system forward function lorenz!(du,u,p,t) du[1] = 10*(u[2]-u[1]) du[2] = u[1]*(p[1]-u[3]) - u[2] du[3] = u[1]*u[2] - (8//3)*u[3] end p = [28.0] tspan_init = (0.0,30.0) tspan_attractor = (30.0,50.0) u0 = rand(3) prob_init = ODEProblem(lorenz!,u0,tspan_init,p) sol_init = solve(prob_init,Tsit5()) prob_attractor = ODEProblem(lorenz!,sol_init[end],tspan_attractor,p) sol_attractor = solve(prob_attractor,Vern9(),abstol=1e-14,reltol=1e-14) using Plots, LaTeXStrings pl1 = plot(sol_init,vars=(1,2,3), legend=true, label = \u0026quot;initial\u0026quot;, labelfontsize=20, lw = 2, xlabel = L\u0026quot;x\u0026quot;, ylabel = L\u0026quot;y\u0026quot;, zlabel = L\u0026quot;z\u0026quot;, xlims=(-25,30),ylims=(-30,30),zlims=(5,49) ) plot!(pl1, sol_attractor,vars=(1,2,3), label=\u0026quot;attractor\u0026quot;,xlims=(-25,30),ylims=(-30,30),zlims=(5,49) ) savefig(pl1, \u0026quot;Lorenz_forward.png\u0026quot;)    Here, we separated the trajectory in two parts: We plot the initial transient dynamics starting from random initial conditions towards the attractor in blue and the subsequent time evolution lying entirely on the attractor in orange.\nFollowing Refs.4 and 5, we choose\n$$ \\langle z \\rangle_∞ = \\lim_{T \\rightarrow ∞} \\frac{1}{T} \\int_0^T z \\text{d}t $$\nas the objective, where we only use the trajectory that lies completely on the attractor (i.e., the orange trajectory in the plot on top). Let us first study the objective as a function of $\\rho$.\nfunction compute_objective(sol) quadgk(t-\u0026gt; sol(t)[end]/(tspan_attractor[2]-tspan_attractor[1]) ,tspan_attractor[1],tspan_attractor[2], atol=1e-14, rtol=1e-10)[1] end pl2 = plot(sol_attractor.t, getindex.(sol_attractor.u,3), ylabel=L\u0026quot;z(t)\u0026quot;, xlabel=L\u0026quot;t\u0026quot;, label=false, labelfontsize=20,lw = 2) mean_z = [mean(getindex.(sol_attractor.u,3))] int_z = compute_objective(sol_attractor) hline!(pl2, [int_z], label=L\u0026quot;\\langle z\\rangle\u0026quot;, lw = 2) savefig(pl2, \u0026quot;zsingle.png\u0026quot;) # for each value of the parameter, solve 20 times the initial value problem # wrap the procedure inside a function depending on p function Lorenz_solve(p) u0 = rand(3) prob_init = ODEProblem(lorenz!,u0,tspan_init,p) sol_init = solve(prob_init,Tsit5()) prob_attractor = ODEProblem(lorenz!,sol_init[end],tspan_attractor,p) sol_attractor = solve(prob_attractor,Vern9(),abstol=1e-14,reltol=1e-14) sol_attractor, prob_attractor end Niter = 10 ps = collect(0.0:1.0:50.0) probs = [] sols = [] zmean = [] zstd = [] for ρ in ps @show ρ ztmp = [] for i=1:Niter sol, prob = Lorenz_solve([ρ]) zbar = compute_objective(sol) push!(sols, sol) push!(probs, prob) push!(ztmp, zbar) end push!(zmean,mean(ztmp)) push!(zstd,std(ztmp)) end pl3 = plot(ps,zmean, ribbon = zstd, ylabel=L\u0026quot;\\langle z\\rangle\u0026quot;, xlabel=L\u0026quot;\\rho\u0026quot;, legend=false, labelfontsize=20, lw = 2, xlims=(0,50),ylims=(0,50)) savefig(pl3, \u0026quot;zvsrho.png\u0026quot;) pl4 = plot(pl2,pl3, margin=3Plots.mm, layout = (1, 2), size=(600,300)) savefig(pl4, \u0026quot;z.png\u0026quot;)  We obtain:\n  That is, we find a slope of approximately one (almost everywhere except at the kink $\\rho\\approx 23$), and, therefore, we expect a sensitivity of\n$$ \\frac{\\text{d}\\langle z \\rangle_∞}{\\text{d} \\rho} \\approx 1. $$\nConventional forward-mode sensitivity analysis and finite-differencing For non-chaotic systems, we would just use the standard discrete or continuous forward sensitivity methods or even finite-differencing. If we try to compute the sensitivity for the Lorenz system:\nfunction G(p, prob=prob_attractor) tmp_prob = remake(prob,p=p) tmp_sol = solve(tmp_prob,Vern9(),abstol=1e-14,reltol=1e-14) res = compute_objective(tmp_sol) @info res res end sense_forward = ForwardDiff.gradient(G,p) sense_calculus = Calculus.gradient(G,p)  we find diverging values:\n$$ \\begin{aligned} \u0026amp; \\frac{\\text{d}\\langle z \\rangle_\\infty}{\\text{d} \\rho} \\Bigg\\rvert_{\\rho=28} \\approx -49899 {\\text{ (ForwardDiff)}} \\\\\n\u0026amp;\\frac{\\text{d}\\langle z \\rangle_\\infty}{\\text{d} \\rho} \\Bigg\\rvert_{\\rho=28} \\approx 472 {\\text{ (Calculus)}} \\end{aligned} $$\nAs pointed out in the NILSS paper, this is because the limit of $T\\rightarrow ∞$ for a fixed initial state does not commute with the differentiation:\n$$ \\frac{\\text{d}}{\\text{d} \\rho} \\langle z \\rangle_∞ \\neq \\lim_{T \\rightarrow ∞} \\frac{\\partial}{\\partial \\rho} \\langle z \\rangle_T $$\nSimilarly, using uncertainty quantification one realizes that due to finite numerical precision and the associated unavoidable errors that are amplified exponentially, one cannot follow the true solution of a chaotic system for long times. We can visualize this by solving the Lorenz system twice with exactly the same parameters and initial condition but with different floating point number precision. In the following animation, we see an $O(1)$ difference between both trajectories after a few Lyapunov lengths:\nprob_attractor1 = ODEProblem(lorenz!,sol_init[end],(0.0, 50.0),p) prob_attractor2 = ODEProblem(lorenz!,convert.(Float32, sol_init[end]),(0f0, 50f0),convert.(Float32,p)) sol1 = solve(prob_attractor1,Tsit5(),abstol=1e-6,reltol=1e-6, saveat=0.01) sol2 = solve(prob_attractor2,Tsit5(),abstol=1f-6,reltol=1f-6, saveat=0.01f0) list_plots = [] t1 = 0.0 for i in 1:500 t2 = i*0.1 plt1 = plot(sol1, vars=(1,2,3), tspan=(t1,t2), denseplot=true, legend=true, label = \u0026quot;Float64\u0026quot;, labelfontsize=20, lw = 2, xlabel = L\u0026quot;x\u0026quot;, ylabel = L\u0026quot;y\u0026quot;, zlabel = L\u0026quot;z\u0026quot;, xlims=(-20,25),ylims=(-28,25),zlims=(5,48)) plot!(plt1, sol2,vars=(1,2,3), tspan=(t1,t2), denseplot=true, label=\u0026quot;Float32\u0026quot;, xlims=(-20,25),ylims=(-28,25),zlims=(5,48)) push!(list_plots, plt1) end anim = animate(list_plots,every=1) pl1 = plot(sol1,vars=(1,2,3), legend=true, label = \u0026quot;Float64\u0026quot;, labelfontsize=20, lw = 2, xlabel = L\u0026quot;x\u0026quot;, ylabel = L\u0026quot;y\u0026quot;, zlabel = L\u0026quot;z\u0026quot;, xlims=(-20,25),ylims=(-28,25),zlims=(5,48) ) plot!(pl1, sol2,vars=(1,2,3), label=\u0026quot;Float32\u0026quot;, xlims=(-20,25),ylims=(-28,25),zlims=(5,48) ) savefig(pl1, \u0026quot;Lorenz_Floats.png\u0026quot;)    Without animation:\n  Luckily, the shadowing lemma states:\n Although a numerically computed chaotic trajectory diverges exponentially from the true trajectory with the same initial coordinates, there exists an errorless trajectory with a slightly different initial condition that stays near (\u0026ldquo;shadows\u0026rdquo;) the numerically computed one.\n Shadowing methods The central idea of the shadowing methods is to distill the long-time effect (which actually shifts the attractor) due to a variation of the system parameters (upwards in the $z$-direction with increasing $\\rho$ for the Lorenz system) from the transient effect, i.e., the butterfly effect that looks like exponentially diverging trajectories due to variations of the initial conditions. That implies that we aim at finding two trajectories, one with $p$ and one with $p+\\delta p$, which do not diverge exponentially from each other (which exist thanks to the shadowing lemma). In this case, their difference will only contain the long-time effect. More details can be found in Refs. 4 and 5, including a visualization of both effects in Fig. 1 of Ref. 5.\nLSS and NILSS for the Lorenz system Switching to LSS or NILSS within the SciML ecosystem is straightforward by either defining the associated LSS (ForwardLSSProblem or AdjointLSSProblem) or NILSS problem (NILSSProblem) type manually:\n# objective g(u,p,t) = u[end] #### # LSS #### lss_problem = ForwardLSSProblem(sol_attractor, ForwardLSS(alpha=DiffEqSensitivity.CosWindowing()), g) @show shadow_forward(lss_problem) # 1.0095888187322035 lss_problem = ForwardLSSProblem(sol_attractor, ForwardLSS(alpha=DiffEqSensitivity.Cos2Windowing()), g) @show shadow_forward(lss_problem) # 1.0343951385924328 lss_problem = ForwardLSSProblem(sol_attractor, ForwardLSS(alpha=10.0), g) @show shadow_forward(lss_problem) # 1.0284286902740765 adjointlss_problem = AdjointLSSProblem(sol_attractor, AdjointLSS(alpha=10.0), g) @show shadow_adjoint(adjointlss_problem) # 1.028428690274077  or by setting the sensealg= kwarg in solve():\n# select via sensealg in solve using Zygote function GLSS(p; sensealg=ForwardLSS(), dt=0.01, g=nothing) _prob = remake(prob_attractor,p=p) _sol = solve(_prob,Vern9(),abstol=1e-14,reltol=1e-14,saveat=dt,sensealg=sensealg, g=g) sum(getindex.(_sol.u,3)) end dp1 = Zygote.gradient((p)-\u0026gt;GLSS(p),p) # 0.9694728321500617  Note that we have implemented three different options for forward shadowing with LSS():\n CosWindowing() (default) Cos2Windowing() time dilation with a factor of $\\alpha$.  Additionally, an adjoint implementation AdjointLSS() is available that is particularly recommended for a large number of system parameters. Based on the values computed above, we can easily check that AdjointLSS(alpha=10.0) agrees perfectly with ForwardLSS(alpha=10.0). In all cases considered, we find the expected sensitivity value of $\\approx 1$.\nHowever, the use of LSS() is (typically) much more expensive than the use of NILSS(), because LSS() needs to solve a large linear system. This linear system scales with the number of independent variables in the differential equation times the number of time steps and, thus, it can become very large. The computational and memory costs of NILSS() scale with the number of positive (unstable) Lyapunov exponents, since it constrains the optimization problem in the LSS method to its unstable subspace. In many cases, this number is much smaller than the number of independent variables, hence making NILSS() more efficient.\nIn the NILSS() algorithm, the user can control the number of steps per segment as well as the number of segments.\n#### # NILSS #### # make sure trajectory is fully on the attractor Random.seed!(1234) tspan_init = (0.0,100.0) tspan_attractor = (100.0,120.0) u0 = rand(3) prob_init = ODEProblem(lorenz!,u0,tspan_init,p) sol_init = solve(prob_init,Tsit5()) prob_attractor = ODEProblem(lorenz!,sol_init[end],tspan_attractor,p) nseg = 100 # number of segments on time interval nstep = 2001 # number of steps on each segment nilss_prob = NILSSProblem(prob_attractor, NILSS(nseg, nstep), g) @show DiffEqSensitivity.shadow_forward(nilss_prob,Tsit5()) # 0.9966924374966089  If the number of segments is chosen too small, a warning is thrown:\nnseg = 20 # number of segments on time interval nstep = 2001 # number of steps on each segment nilss_prob = NILSSProblem(prob_attractor, NILSS(nseg, nstep), g) @show DiffEqSensitivity.shadow_forward(nilss_prob,Tsit5()) # 1.0416028730638789 # Warning: Detected a large value of ξ at the beginning of a segment. # └ @ DiffEqSensitivity ~/.julia/dev/DiffEqSensitivity/src/nilss.jl:474  In the future, we might add an option for the automate control of these variables following the proposal in the NILSS paper5.\nOutlook With respect to the shadowing methods for chaotic systems, we are planning to implement further methods, such as\n NILSAS6 FD-NILSS7  in the upcoming weeks. For further information and a collection of other methods, the interested reader is invited to track the corresponding issue in the DiffEqSensitivity.jl package.\nIf you have any questions or comments, please don’t hesitate to contact me!\n  Frank Schäfer, Michal Kloc, et al., Mach. Learn.: Sci. Technol. 1, 035009 (2020). \u0026#x21a9;\u0026#xfe0e;\n Frank Schäfer, Pavel Sekatski, et al., Mach. Learn.: Sci. Technol. 2, 035004 (2021). \u0026#x21a9;\u0026#xfe0e;\n Chris Rackauckas, Yingbo Ma, et al., arXiv preprint arXiv:2001.04385 (2020). \u0026#x21a9;\u0026#xfe0e;\n Qiqi Wang, Rui Hu, et al. J. Comput. Phys 26, 210-224 (2014) \u0026#x21a9;\u0026#xfe0e;\n Angxiu Ni and Qiqi Wang. J. Comput. Phys 347, 56-77 (2017). \u0026#x21a9;\u0026#xfe0e;\n Angxiu Ni and Chaitanya Talnikar, J. Comput. Phys 395, 690-709, (2019) \u0026#x21a9;\u0026#xfe0e;\n Angxiu Ni, Qiqi Wang et al., J. Comput. Phys 394, 615-631 (2019) \u0026#x21a9;\u0026#xfe0e;\n   ","date":1625216902,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625216902,"objectID":"263091e46f2c8aead98407a523d8a2fe","permalink":"https://frankschae.github.io/post/shadowing/","publishdate":"2021-07-02T11:08:22+02:00","relpermalink":"/post/shadowing/","section":"post","summary":"In this post, we dig into sensitivity analysis of chaotic systems. Chaotic systems are dynamical, deterministic systems that are extremely sensitive to small changes in the initial state or the system parameters.","tags":["GSoC 2021","julia","Adjoint sensitivity methods","Forward sensitivity methods","Shadowing","Chaotic systems"],"title":"Shadowing Methods for Forward and Adjoint Sensitivity Analysis of Chaotic Systems","type":"post"},{"authors":[],"categories":[],"content":"I am delighted that I have been awarded my second GSoC stipend this year. I look forward to carrying out the ambitious project scope with my mentors Chris Rackauckas, Moritz Schauer, Yingbo Ma, and Mohamed Tarek. This year\u0026rsquo;s project is embedded within the NumFocus/ SciML organization and comprises adjoint sensitivity methods for discontinuities, shadowing methods for chaotic dynamics, symbolically generated adjoint methods, and further AD tooling within the Julia Language.\nThis first post aims to illustrate our new (adjoint) sensitivity analysis tools with respect to event handling in (ordinary) differential equations (DEs).\nHybrid Differential Equations DEs with additional explicit or implicit discontinuities are called hybrid DEs. Within the SciML software suite, such discontinuities may be incorporated into DE models by callbacks. Evidently, the incorporation of discontinuities allows a user to specify changes (events) in the system, i.e., changes of the state or the parameters of the DE, which cannot be modeled by a plain ordinary DE. While explicit events can be described by DiscreteCallbacks, implicit events have to be specified by ContinuousCallbacks. That is, explicit events possess explicit event times, while implicit events are triggered when a continuous function evaluates to 0. Thus, implicit events require some sort of rootfinding procedure.\nSome relevant examples for hybrid DEs with discrete or continuous callbacks are:\n quantum optics experiments, where photon-counting measurements lead to jumps in the quantum state that occur with a variable rate, see for instance Appendix A in Ref.1 (ContinuousCallback). a bouncing ball2 (ContinuousCallback). classical point process models, such as a Poisson process3. digital controllers4, where a continuous system dynamics is controlled by a discrete-time controller (DiscreteCallback). pharmacokinetic models5, where explicit dosing times change the drug concentration in the blood (DiscreteCallback). The simplest possible example being the one-compartment model. kicked oscillator dynamics, e.g., a harmonic oscillator that gets a kick at some time points (DiscreteCallback).  The associated sensitivity methods that allow us to differentiate through the respective hybrid DE systems have been recently introduced in Refs. 2 and 3.\nKicked harmonic oscillator Let us consider the simple physical model of a damped harmonic oscillator, described by an ODE of the form\n$$ \\ddot{x}(t) + a\\cdot\\dot{x}(t) + b \\cdot x(t) = 0 , $$\nwhere $a=0.1$ and $b=1$ with initial conditions\n$$ \\begin{aligned} x(t=0) \u0026amp;= 1 \\\\\nv(t=0) \u0026amp;= \\dot{x}(t=0) = 0. \\end{aligned}\n$$\nThis second-order ODE can be reduced to two first-order ODEs, such that we can straightforwardly simulate the resulting ODE with the DifferentialEquations.jl package. (Instead of doing this reduction manually, we could also use ModelingToolkit.jl to transform the ODE in an automatic manner. Alternatively, for second-order ODEs, there is also a SecondOrderODEProblem implemented.) The Julia code reads:\nusing DiffEqFlux, DifferentialEquations, Flux, Optim, Plots, DiffEqSensitivity using Zygote using Random u0 = Float32[1.; 0.] tspan = (0.0f0,50.0f0) dtsave = 0.5f0 t = tspan[1]:dtsave:tspan[2] function oscillator!(du,u,p,t) du[1] = u[2] du[2] = - u[1] - 1//10*u[2] return nothing end prob_data = ODEProblem(oscillator!,u0,tspan) # ODE without kicks pl = plot(solve(prob_data,Tsit5(),saveat=t), label=[\u0026quot;x(t)\u0026quot; \u0026quot;v(t)\u0026quot;])    We now include a kick to the velocity of the oscillator at regular time steps. Here, we choose both the time difference between the kicks and the increase in velocity as 1.\nkicktimes = tspan[1]:1:tspan[2] function kick!(integrator) integrator.u[end] += one(eltype(integrator.u)) end cb_ = PresetTimeCallback(kicktimes,kick!,save_positions=(false,false)) sol_data = solve(prob_data,Tsit5(),callback=cb_,saveat=t) t_data = sol_data.t ode_data = Array(sol_data) # visualize data pl1 = plot(t_data,ode_data[1,:],label=\u0026quot;data x(t)\u0026quot;) plot!(pl1,t_data,ode_data[2,:],label=\u0026quot;data v(t)\u0026quot;) pl2 = plot(t_data[1:20],ode_data[1,1:20],label=\u0026quot;data x(t)\u0026quot;) plot!(pl2,t_data[1:20],ode_data[2,1:20],label=\u0026quot;data v(t)\u0026quot;) pl = plot(pl2, pl1, layout=(1,2), xlabel=\u0026quot;t\u0026quot;)     The left-hand side shows a zoom for short times to better resolve the kicks. Note that by setting save_positions=(true,true), the kicks would be saved before and after the event such that the kicks would appear completely vertically in the plot. The data on the right-hand will be used as training data below. In the spirit of universal differential equations6, we now aim at learning (potentially) missing parts of the model from these data traces.\nHigh domain knowledge For simplicity, we assume that we have almost perfect knowledge about our system. That is, we assume to know the basic structure of the ODE, including its parameters $a$ and $b$, and that the affect! function of the event only acts on the velocity. We then encode the affect as an additional component to the ODE. The task is thus to learn the dynamics of the third component of integrator.u. If we further set the initial value of that component to 1, then the neural network only has to learn that du[3] is 0. In other words, the output of the neural network must be 0 for all states u.\nRandom.seed!(123) nn1 = FastChain(FastDense(2, 64, tanh),FastDense(64, 1)) p_nn1 = initial_params(nn1) function f1!(du,u,p,t) du[1] = u[2] du[2] = - u[1] - 1//10*u[2] du[3] = nn1(u[1:2], p)[1] return nothing end affect!(integrator) = integrator.u[2] += integrator.u[3] cb = PresetTimeCallback(kicktimes,affect!,save_positions=(false,false)) z0 = Float32[u0;one(u0[1])] prob1 = ODEProblem(f1!,z0,tspan,p_nn1)  We can easily compare the time evolution of the neural hybrid DE with respect to the data:\n# to visualize the predictions of the trained neural network below function visualize(prob,p) _prob = remake(prob,p=p) ode_pred = Array(solve(_prob,Tsit5(),callback=cb, saveat=dtsave))[1:2,:] pl1 = plot(t_data,ode_pred[1,:],label=\u0026quot;x(t)\u0026quot;) scatter!(pl1,t_data[1:5:end],ode_data[1,1:5:end],label=\u0026quot;data x(t)\u0026quot;) pl2 = plot(t_data,ode_pred[2,:],label=\u0026quot;v(t)\u0026quot;) scatter!(pl2,t_data[1:5:end],ode_data[2,1:5:end],label=\u0026quot;data v(t)\u0026quot;) pl = plot(pl1, pl2, layout=(1,2), xlabel=\u0026quot;t\u0026quot;) return pl, sum(abs2,ode_data .- ode_pred) end pl = plot(solve(prob1,Tsit5(),saveat=t, callback=cb ),label=[\u0026quot;x(t)\u0026quot; \u0026quot;v(t)\u0026quot; \u0026quot;u3(t)\u0026quot;])    which (of course) doesn\u0026rsquo;t match the data due to the random initialization of the neural network parameters before training. The neural network can be trained, i.e., its parameters can be optimized, by minimizing a mean-squared error loss function:\n### loss function function loss(p; prob=prob1, sensealg = ReverseDiffAdjoint()) _prob = remake(prob,p=p) pred = Array(solve(_prob,Tsit5(),callback=cb, saveat=dtsave,sensealg=sensealg))[1:2,:] sum(abs2,ode_data .- pred) end loss(p_nn1)  The recently implemented tools are deeply hidden within the DiffEqSensitivity.jl package. However, while the user could previously only choose discrete sensitivities such as ReverseDiffAdjoint() or ForwardDiffAdjoint() that rely on direct differentiation through the solver operations to get accurate gradients, one can now also select continuous adjoint sensitivity methods such as BacksolveAdjoint(), InterpolatingAdjoint(), and QuadratureAdjoint() as the sensealg for hybrid DEs. Each choice has its own characteristics in terms of stability, scaling with parameters, and memory consumption, see, e.g., Chris' talk at the SciML symposium at SIAM CSE.\n################################### # training loop # optimize the parameters for a few epochs with ADAM function train(prob, p_nn; sensealg=BacksolveAdjoint()) opt = ADAM(0.0003f0) list_plots = [] losses = [] for epoch in 1:200 println(\u0026quot;epoch: $epoch / 200\u0026quot;) _dy, back = Zygote.pullback(p -\u0026gt; loss(p, prob=prob, sensealg=sensealg), p_nn) gs = @time back(one(_dy))[1] push!(losses, _dy) if epoch % 10 == 0 # plot every xth epoch pl, test_loss = visualize(prob, p_nn) println(\u0026quot;Loss (epoch: $epoch): $test_loss\u0026quot;) display(pl) push!(list_plots, pl) end Flux.Optimise.update!(opt, p_nn, gs) println(\u0026quot;\u0026quot;) end return losses, list_plots end # plot training loss losses, list_plots = train(prob1, p_nn1) pl1 = plot(losses, lw = 1.5, xlabel = \u0026quot;epoch\u0026quot;, ylabel=\u0026quot;loss\u0026quot;, legend=false) pl2 = list_plots[end] pl3 = plot(solve(prob1,p=p_nn1,Tsit5(),saveat=t, callback=cb ), label=[\u0026quot;x(t)\u0026quot; \u0026quot;v(t)\u0026quot; \u0026quot;u3(t)\u0026quot;]) pl = plot(pl2,pl3)    We see the expected constant value of u[3], indicating a kick to the velocity of +=1, at the kicking times over the full time interval.\nReducing the domain knowledge If less physical information is included in the model design, the training becomes more difficult, e.g., due to local minima. Possible modification for the kicked oscillator could be\n changing the initial condition of the third component of u, using another affect function affect!(integrator) = integrator.u[2] = integrator.u[3], dropping the knowledge that only u[2] gets a kick by using a neural network with 2 outputs (+ a fourth component in the ODE):  affect2!(integrator) = integrator.u[1:2] = integrator.u[3:4] function f2!(du,u,p,t) du[1] = u[2] du[2] = - u[1] - 1//10*u[2] du[3:4] .= nn2(u[1:2], nn_weights) return nothing end   fitting the parameters $a$ and $b$ simultaneously:  function f3!(du,u,p,t) a = p[end-1] b = p[end] nn_weights = p[1:end-2] du[1] = u[2] du[2] = -b*u[1] - a*u[2] du[3:4] .= nn2(u[1:2], nn_weights) return nothing end   inferring the entire underlying dynamics using a neural network with 4 outputs:  function f4!(du,u,p,t) Ω = nn3(u[1:2], p) du[1] = Ω[1] du[2] = Ω[2] du[3:4] .= Ω[3:4] return nothing end   etc.  Outlook With respect to the adjoint sensitivity methods for hybrid DEs, we are planning to\n refine the adjoints in case of implicit discontinuities (ContinuousCallbacks) and support direct usage through the jump problem interface  in the upcoming weeks. For further information, the interested reader is encouraged to look at the open issues in the DiffEqSensitivity.jl package.\nIf you have any questions or comments, please don’t hesitate to contact me!\n  Frank Schäfer, Pavel Sekatski, et al., Mach. Learn.: Sci. Technol. 2, 035004 (2021) \u0026#x21a9;\u0026#xfe0e;\n Ricky T. Q. Chen, Brandon Amos, Maximilian Nickel, arXiv preprint arXiv:2011.03902 (2020). \u0026#x21a9;\u0026#xfe0e;\n Junteng Jia, Austin R. Benson, arXiv preprint arXiv:1905.10403 (2019). \u0026#x21a9;\u0026#xfe0e;\n Michael Poli, Stefano Massaroli, et al., arXiv preprint arXiv:2106.04165 (2021). \u0026#x21a9;\u0026#xfe0e;\n Chris Rackauckas, Yingbo Ma, et al., \u0026ldquo;Accelerated predictive healthcare analytics with pumas, a high performance pharmaceutical modeling and simulation platform.\u0026rdquo; (2020). \u0026#x21a9;\u0026#xfe0e;\n Chris Rackauckas, Yingbo Ma, et al., arXiv preprint arXiv:2001.04385 (2020). \u0026#x21a9;\u0026#xfe0e;\n   ","date":1623847817,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623847817,"objectID":"c5c641840c6146609c2e90c018c85a3f","permalink":"https://frankschae.github.io/post/hybridde/","publishdate":"2021-06-16T14:50:17+02:00","relpermalink":"/post/hybridde/","section":"post","summary":"I am delighted that I have been awarded my second GSoC stipend this year. I look forward to carrying out the ambitious project scope with my mentors Chris Rackauckas, Moritz Schauer, Yingbo Ma, and Mohamed Tarek.","tags":["GSoC 2021","julia","Hybrid differential equations","Adjoint sensitivity methods","Event handling"],"title":"Neural Hybrid Differential Equations","type":"post"},{"authors":[],"categories":[],"content":"","date":1615332097,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615332097,"objectID":"6b8484ee245fb6a73711cfc61c673627","permalink":"https://frankschae.github.io/software/sciml/","publishdate":"2021-03-10T00:21:37+01:00","relpermalink":"/software/sciml/","section":"software","summary":"Contributions to the SciML ecosystem in Julia, especially the DiffEqSensitivity.jl package for sensitivity analysis utilities, the StochasticDiffEq.jl package for stochastic differential equations solvers, and the DiffEqNoiseProcess package for tools to develop noise processes for differential equations.","tags":[],"title":"SciML Scientific Machine Learning Software","type":"software"},{"authors":[],"categories":[],"content":"","date":1615332037,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615332037,"objectID":"7d136c46f74da06acca4c2ac00a7b219","permalink":"https://frankschae.github.io/software/mitosisstochasticdiffeq/","publishdate":"2021-03-10T00:20:37+01:00","relpermalink":"/software/mitosisstochasticdiffeq/","section":"software","summary":"Implementation of the backward filter and the forward change of measure of the Automatic Backward Filtering Forward Guiding paradigm. Joint work with [Moritz Schauer](https://github.com/mschauer).","tags":[],"title":"MitosisStochasticDiffEq","type":"software"},{"authors":["FS in collaboration with Pavel Sekatski","Martin Koppenhöfer","Niels Lörch","Christoph Bruder","and Michal Kloc"],"categories":[],"content":"Conceptually, it is straightforward to determine the time evolution of a quantum system for a fixed initial state given its (time-dependent) Hamiltonian or Lindbladian. Depending on the physical context, the dynamics is described by an ordinary or stochastic differential equation. In quantum state control, which is of paramount importance for quantum computation, we aim at solving the inverse problem. That is, starting from a distribution of initial states, we seek protocols that allow us to reach a desired target state by optimization of free parameters of the differential equation (control drives) in a certain time interval. To solve this control problem, we implement the system dynamics as part of a fully differentiable program and use a loss function that quantifies the distance from the target state. Specifically, we employ a neural network that maps an observation of the state of the qubit to a control drive defined via the differential equation for each time interval. To implement efficient training, we backpropagate the gradient information from the loss function through the SDE solver using adjoint sensitivity methods. Such a procedure should ultimately combine powerful tools from machine learning and scientific computation.\n","date":1615332029,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615332029,"objectID":"0dda26cfe2920348a8f4a2cf6ef7ac1d","permalink":"https://frankschae.github.io/project/dp_for_control/","publishdate":"2021-03-10T00:20:29+01:00","relpermalink":"/project/dp_for_control/","section":"project","summary":"Quantum control based on parametrized controllers trained with gradient information computed by (adjoint) sensitivity methods.","tags":["SciML","differentiable programming","NODE","NSDE","adjoint sensitivity methods","automatic differentiation","quantum control"],"title":"Control of (Stochastic) Quantum Dynamics with Differentiable Programming","type":"project"},{"authors":["FS in collaboration with Julian Arnold","Eliska Greplova","Agnes Valenti","Martin Zonda","Axel Lode","Gregor Boschung","Sebastian Huber","and Niels Lörch"],"categories":[],"content":"Fully automated classification methods that yield direct physical insights into phase diagrams are of current interest. We demonstrate the identification of phase boundaries using an unsupervised machine learning method based on the vector-field divergence of the output of a predictive model, as well as using a data-driven scheme which relies on the difference between mean input features. As examples, we consider the anisotropic Ising model, the Kuramoto-Hopf model, Ising gauge theory, the toric code, and the spinless Falicov-Kimball model.\n","date":1615330603,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615330603,"objectID":"96c9e3dc2a1485e968cc89f130ac8af0","permalink":"https://frankschae.github.io/project/ml_for_pt/","publishdate":"2021-03-09T23:56:43+01:00","relpermalink":"/project/ml_for_pt/","section":"project","summary":"Data-driven methods based on sample instances of the state of a physical system as a function of the system's parameters.","tags":["Machine learning","neural networks","unsupervised learning"],"title":"Machine Learning for Phase Transitions","type":"project"},{"authors":["FS in collaboration with Laurent de Forges de Parny","Miguel Bastarrachea","Axel Lode","and Andreas Buchleitner"],"categories":[],"content":"We examine the spectral structure and many-body dynamics of two and three repulsively interacting bosons trapped in a one-dimensional double-well, for variable barrier height, inter-particle interaction strength, and initial conditions. By exact diagonalization of the many-particle Hamiltonian, we specifically explore the dynamical behavior of the particles launched either at the single-particle ground state or saddle-point energy, in a time-independent potential. We complement these results by a characterization of the cross-over from diabatic to quasi-adiabatic evolution under finite-time switching of the potential barrier, via the associated time evolution of a single particle’s von Neumann entropy. This is achieved with the help of the multiconfigurational time-dependent Hartree method for indistinguishable particles (MCTDH-X)—which also allows us to extrapolate our results for increasing particle numbers.\n","date":1615282751,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615282751,"objectID":"4b16c3ed4d0b9e975df9b36f75807256","permalink":"https://frankschae.github.io/project/mbdynamics/","publishdate":"2021-03-09T10:39:11+01:00","relpermalink":"/project/mbdynamics/","section":"project","summary":"Study of the spectral structure and the resulting dynamics of a few bosons under consideration of different initial conditions.","tags":["Many-body physics","exact diagonalization","Bose-Hubbard model","MCTDH-X"],"title":"Spectral Structure and Many-Body Dynamics of Ultracold Bosons in a Double Well ","type":"project"},{"authors":[],"categories":[],"content":"Project summary In this project, we have implemented new promising tools within the SciML organization which are relevant for tasks such as optimal control or parameter estimation for stochastic differential equations. The high weak order solvers will allow for massive performance advantages for fitting expectations of equations. Instead of automatic differentiation (AD) through the operations of an SDE solver, which scales poorly in memory, one can now use efficient stochastic adjoint sensitivity methods.\nBlog posts The following posts describe the work during the entire period in more detail:\n  GSoC 2020: High weak order SDE solvers and their utility in neural SDEs  High weak order SDE solvers  Docs The documentation of the solvers is available here. Docs with respect to the adjoint sensitivity tools will be available here.\nAchievements Please find below a list of the PRs carried out during GSoC in the different repositories in chronological order within the SciML ecosystem.\nStochasticDiffEq.jl Merged:\n  Inplace version of DRI1 scheme  RI1 method  tstop fixes for reverse time propagation  Fixes for EulerHeun scheme  Speed up the tests for the DRI1 and RI1 schemes  RI3, RI5, RI6, RDI2WM, RDI3WM, and RDI4WM schemes  RDI1WM scheme  Adaptive version of the stochastic Runge-Kutta schemes by embedding  RS1 and RS2 schemes  PL1WM scheme  NON scheme  Citations for weak methods  Stochastic improved and modified Euler methods  COM scheme  Computationally more efficient NON variant (NON2)  Open:\n  Static array tests  Levy area for non-commutative noise processes  DiffEqSensitivity.jl Merged:\n  Adjoint sensitivities for steady states  Concrete_solve dispatch for steady state problem  BacksolveAdjoint for SDEs  GPU savety for SDE BacksolveAdjoint  Tests for concrete solve with respect to SDEs  Alternative differentiation choices (vjps) for noise Jacobian  Fixes and tests for inplace formulation of BacksolveAdjoint  Efficient SDE BacksolveAdjoint for scalar noise  Generalization of the SDE Adjoint for non-diagonal noise processes and diagonal noise processes with mixing terms  InterpolatingAdjoint for SDEs  Citations for backsolve, steadystate and interpolation adjoint  Allow for more general noise processes: replace NoiseGrid by NoiseWrapper  Checkpointing fix for BacksolveAdjoint in case of ODEs and SDEs  Cheaper non-diagonal noise tests  Open:\n  Support adjoints for SDEs written in the Ito sense  DiffEqNoiseProcess.jl Merged:\n  Multi-dimensional Brownian motion tests  Bug fix for inplace form of NoiseGrid  Reversible NoiseWrapper  Relax the size constraints of the available noise processes  Generalization of the real-valued white noise process function  Fix of an extraction issue with NoiseGrid  Allow NoiseWrapper to start at user-specified time points for interpolating parts of a trajectory  Extraction and endpoint fixes on NoiseWrapper  Reversal of SDEs written in the Ito sense  DiffEqGPU.jl Merged:\n  Memory efficient reduction function for ensemble problems  ModelingToolkit.jl Merged:\n  modelingtoolkitize for SDESystem with conversion function between Ito and Stratonovich sense  DiffEqDevTools.jl Merged:\n  NoiseWrapper alternative for analyticless convergence tests of SDE solvers  test_convergence() dispatch for ensemble simulations  Work precision set for ensemble problems  DiffEqBase.jl Merged:\n  Fix concrete_solve tests  Future work There is still a lot that we\u0026rsquo;d like to do, e.g.,\n Writing up more docs and examples Implementing drift-implicit weak stochastic Runge-Kutta solvers Finishing the SDE adjoints for the Ito sense Implementing a virtual Brownian tree to store the noise processes in O(1) memory Setting up an OptimalControl library that allows for easy usage of the new tools within a symbolic interface Benchmarking of the new solvers and adjoints  Contributions, suggestions \u0026amp; comments are always welcome! You might like to join our slac channels #diffeq-bridged and #neuralsde to get in touch.\nAcknowledgement I would like to thank my mentors Chris Rackauckas, Moritz Schauer, and Yingbo Ma for their amazing support during this project. It was a great opportunity to work in such an inspiring collaboration and I highly appreciate their detailed feedback. I would also like to thank Christoph Bruder, Niels Lörch, Martin Koppenhöfer, and Michal Kloc for helpful comments on my blog posts. Many thanks to the very supportive julia community and to Google\u0026rsquo;s open source program for funding this experience!\n","date":1598475589,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598475589,"objectID":"c74c1755693bb9cf28d7bf9019cfb1ee","permalink":"https://frankschae.github.io/post/gsoc-2020/","publishdate":"2020-08-26T22:59:49+02:00","relpermalink":"/post/gsoc-2020/","section":"post","summary":"Project summary In this project, we have implemented new promising tools within the SciML organization which are relevant for tasks such as optimal control or parameter estimation for stochastic differential equations.","tags":["GSoC 2020"],"title":"High weak order solvers and adjoint sensitivity analysis for stochastic differential equations","type":"post"},{"authors":[],"categories":[],"content":"This post summarizes our new high weak order methods for the SciML ecosystem, as implemented within the Google Summer of Code 2020 project.\nAfter an introductory part highlighting the differences between the strong and the weak approximation for stochastic differential equations, we look into the convergence and performance properties of a few representative new methods in case of a non-commutative noise process. Based on the stochastic version of the Brusselator equations, we demonstrate how adaptive step-size control for the weak solvers can result in a better approximation of the system dynamics. Finally, we discuss how to run simulations on GPU hardware.\nThroughout this post, we shall use the vector notation $X(t)$ to denote the solution of the d-dimensional Ito SDE system\n$$ dX(t) = a(t,X(t)) dt + b(t,X(t)) dW $$\nwith an m-dimensional driving Wiener process W(t) in the time span $\\mathbb{I}=[t_0, T]$, where $a: \\mathbb{I}\\times\\mathbb{R}^d \\rightarrow \\mathbb{R}^d$ and $b: \\mathbb{I}\\times \\mathbb{R}^{d} \\rightarrow \\mathbb{R}^{d \\times m}$ are continuous functions which fulfill a global Lipschitz condition.1 For simplicity, we write $X(t)$ for both time-discrete approximations and continuous-time random variables in the following.\nStrong convergence Suppose that we encounter the following problem: Given noisy observations $Z(t)$ (e.g., originating from measurement noise), what is the best estimate $\\hat{X}(t)$ of a stochastic system $X(t)$ satisfying the form above. Intuitively, we aim at filtering away the noise from the observations in an optimal way. Such tasks are well known as filtering problems.\nTo solve a filtering problem, we need a solver whose sample paths $Y(t)$ are close to the ones of the stochastic process $X(t)$, i.e., the solver should allow us to reconstruct correctly the numerical solution of each single trajectory of an SDE.\nIntroducing the absolute error at the final time $T$ as $$ \\rm{E}(|X(T) -Y(T)|) \\leq \\sqrt{\\rm{E}(|X(T)-Y(T)|^2)}, $$ we define convergence in the strong sense with order $p$ of a time discrete approximation $Y(T)$ with step size $h$ to the solution $X(T)$ of a SDE at time $T$ if there exists a constant $C$ (independent of $h$) and a constant $\\delta \u0026gt; 0$ such that $$ \\rm{E}(|X(T) -Y(T)|) \\leq C \\cdot h^p, $$ for each $h \\in [0, \\delta]$.\nThe StochasticDiffEq package contains various state-of-the-art solvers for the strong approximation of SDEs. In most cases, the strong solvers are however restricted to special noise forms. For example, the very powerful stability-optimized, adaptive strong order 3/2 stochastic Runge-Kutta method (SOSRI) can only handle diagonal and scalar noise Ito SDEs, i.e., noise processes where b has only entries on its diagonal or $m=1$. The main difficulty for the construction of strong methods with an order \u0026gt; 1/2 arises from the need of an accurate estimation of multiple stochastic integrals. While the iterated stochastic integrals can be expressed in terms of dW in the case of scalar, diagonal, and commutative noise processes, an approximation based on a Fourier expansion of a Brownian bridge must be employed in the case of non-commutative noise processes.2 Currently, we are also implementing those iterated integrals in the StochasticDiffEq library.\nWeak convergence Instead of an accurate pathwise approximation of a stochastic process, we only require an estimation for the expected value of the solution in many situations. In these cases, methods for the weak approximation are sufficient and \u0026ndash; due to the less restrictive formulation of the objective \u0026ndash; those solvers are computationally cheaper than their strong counterparts. For example, weak solvers are very efficient for simulations in quantum optics, if only mean values of many trajectories are required, e.g., when the expectation values of variables such as position and momentum operators are computed in the phase space framework (Wigner functions, positive P-functions, etc.) of quantum mechanics. Our new contributions are particularly appealing for many-body simulations, which are the computationally most demanding problems in quantum mechanics.\nWe define convergence in the weak sense with order $p$ of a time-discrete approximation $Y(T)$ with step size $h$ to the solution $X(T)$ of a SDE at time $T$ if there exists a constant $C$ (independent of $h$) and a constant $\\delta \u0026gt; 0$ such that $$ |\\rm{E}(g(X(T))) -\\rm{E}(g(Y(T)))| \\leq C \\cdot h^p, $$ $~$\nfor any polynomial $g$ for each $h \\in [0, \\delta]$.\nWe demonstrate below that high weak order solvers are specifically appealing, as they allow for using much larger time steps while attaining the same error in the mean, as compared with SDE solvers possessing a smaller weak-order convergence.\nNew high weak order methods A list of all new weak solvers is available in the SciML documentation. Note that we also implemented methods designed for the Stratonovich sense. For the subsequent examples regarding Ito SDEs, we use only a subset of the plethora of second-order weak solvers. We employ the DRI1()3, RD1WM()4, and RD2WM()4 methods due to Debrabant \u0026amp; Rößler and Platen\u0026rsquo;s PL1WM()1 method. We compare those methods to the strong Euler-Maruyama EM()1 and the simplified Euler-Maruyama SimplifiedEM()1 schemes. The latter is the simplest weak solver, where the Gaussian increments of the strong Euler-Maruyama scheme are replaced by two-point distributed random variables with similar moment properties.\nRößler\u0026rsquo;s SRK schemes are particularly designed to scale well with the number of Wiener processes m, since only 2m-1 random variables have to be drawn and since the number of function evaluations for the drift and the diffusion terms is independent of m. PL1WM() in contrast needs to simulate m(m+1)/2 random variables but a smaller number of order conditions needs to be fulfilled.\nConvergence tests As in the first blog post, let us consider the multi-dimensional SDE with non-commuting noise3:\n$$ \\scriptstyle d \\begin{pmatrix} X_1 \\\\ X_2 \\end{pmatrix} = \\begin{pmatrix} -\\frac{273}{512} \u0026amp; \\phantom{X_2}0 \\\\ -\\frac{1}{160} \\phantom{X_2} \u0026amp; -\\frac{785}{512}+\\frac{\\sqrt{2}}{8} \\end{pmatrix} \\begin{pmatrix} X_1 \\\\ X_2 \\end{pmatrix} dt + \\begin{pmatrix} \\frac{1}{4} X_1 \u0026amp; \\frac{1}{16} X_1 \\\\ \\frac{1-2\\sqrt{2}}{4} X_2 \u0026amp; \\frac{1}{10}X_1 +\\frac{1}{16} X_2 \\end{pmatrix} d \\begin{pmatrix} W_1 \\\\ W_2 \\end{pmatrix} $$\nwith initial value $$ ~$$\n$$ X(t=0)= \\begin{pmatrix} 1 \\\\ 1\\end{pmatrix},$$\nwhere the expected value of the solution can be computed analytically\n$$ \\rm{E}\\left[ f(X(t)) \\right] = \\exp(-t),$$\nfor the function $f(x)=(x_1)^2$, which we use to test the weak convergence order of the algorithms in the following.\nTo compute the expected value numerically, we sample an ensemble of numtraj = 1e6 trajectories for different step sizes dt.\nusing StochasticDiffEq using Test using Random using Plots using DiffEqDevTools function prob_func(prob, i, repeat) remake(prob,seed=seeds[i]) end u₀ = [1.0,1.0] function f1!(du,u,p,t) @inbounds begin du[1] = -273//512*u[1] du[2] = -1//160*u[1]-(-785//512+sqrt(2)/8)*u[2] end return nothing end function g1!(du,u,p,t) @inbounds begin du[1,1] = 1//4*u[1] du[1,2] = 1//16*u[1] du[2,1] = (1-2*sqrt(2))/4*u[1] du[2,2] = 1//10*u[1]+1//16*u[2] end return nothing end dts = 1 .//2 .^(3: -1:0) tspan = (0.0,3.0) h2(z) = z^2 # but apply it only to u[1] prob = SDEProblem(f1!,g1!,u₀,tspan,noise_rate_prototype=zeros(2,2)) numtraj = Int(1e6) seed = 100 Random.seed!(seed) seeds = rand(UInt, numtraj) ensemble_prob = EnsembleProblem(prob; output_func = (sol,i) -\u0026gt; (h2(sol[end][1]),false), prob_func = prob_func ) sim = test_convergence(dts,ensemble_prob,DRI1(), save_everystep=false,trajectories=numtraj,save_start=false,adaptive=false, weak_timeseries_errors=false,weak_dense_errors=false, expected_value=exp(-3.0) )  The object sim defined in the last line contains all relevant quantities to test the weak convergence with respect to the final time point for the DRI1() scheme. Repeating this call to the test_convergence() function for the other aforementioned solvers, we obtain the convergence plot:\n  Note that the SimplifiedEM and the EM scheme fall on top of each other. DRI1() achieves the smallest errors for a fixed dt in this study.\nWork-Precision Diagrams Ultimately, we are not only interested in the general convergence slope of an algorithm but also in its speed. We\u0026rsquo;d like to select the fastest method depending on the permitted tolerance. This is commonly studied using work-precision diagram. Thanks to new routines, a user can generate a work-precision diagram by the following code\nreltols = 1.0 ./ 4.0 .^ (1:4) abstols = reltols#[0.0 for i in eachindex(reltols)] setups = [ Dict(:alg=\u0026gt;DRI1(),:dts=\u0026gt;dts,:adaptive=\u0026gt;false), Dict(:alg=\u0026gt;PL1WM(),:dts=\u0026gt;dts,:adaptive=\u0026gt;false), Dict(:alg=\u0026gt;EM(),:dts=\u0026gt;dts,:adaptive=\u0026gt;false), Dict(:alg=\u0026gt;SimplifiedEM(),:dts=\u0026gt;dts,:adaptive=\u0026gt;false), Dict(:alg=\u0026gt;RDI2WM(),:dts=\u0026gt;dts,:adaptive=\u0026gt;false), Dict(:alg=\u0026gt;RDI1WM(),:dts=\u0026gt;dts,:adaptive=\u0026gt;false) ] test_dt = 1//10000 appxsol_setup = Dict(:alg=\u0026gt;EM(), :dt=\u0026gt;test_dt) wp = @time WorkPrecisionSet(ensemble_prob, abstols,reltols,setups,test_dt; maxiters = 1e7,verbose=false, save_everystep=false,save_start=false, appxsol_setup = appxsol_setup, expected_value=exp(-3.0), trajectories=numtraj, error_estimate=:weak_final) plt = plot(wp;legend=:bottomleft)    Therefore, DRI1 has the best performance in this non-commutative noise case if the error is supposed to stay below 1e-3. For larger permitted errors, the SimplifiedEM scheme might be a good choice. However, the first order methods are outclassed when high precision is more of a concern. We plan to perform more in-depth benchmarks in the near future what will be reported on the SciML news. Stay tuned!\nAdaptive step-size control Already in 2004, Rößler proposed an adaptive discretization algorithm for the weak approximation of SDEs.4 The idea is to employ an embedded SRK scheme: Using the same function evaluations but distinct Butcher tableaus, one constructs two stochastic Runge-Kutta methods with different convergence order, such that the local error can be estimated with only small additional computational overhead. Based on the error estimate, new step sizes are proposed.\nTo use adaptive step-size control, it is sufficient to set adaptive=true (default setting). Optionally, one may also pass absolute and relative tolerances.\nThe following julia code simulates the stochastic version of the Brusselator equations with intitial condition\n$$ X(t=0)= \\begin{pmatrix} 0.1 \\\\ 0\\end{pmatrix},$$\non a time span $\\mathbb{I}=[0, 100]$ for adaptive (sol) and fixed step sizes (sol_na):\nusing StochasticDiffEq, DiffEqNoiseProcess, Random using Plots using DiffEqGPU function prob_func(prob, i, repeat) Random.seed!(seeds[i]) W = WienerProcess(0.0,0.0,0.0) remake(prob,noise=W) end function brusselator_f!(du,u,p,t) @inbounds begin du[1] = (p[1]-1)*u[1]+p[1]*u[1]^2+(u[1]+1)^2*u[2] du[2] = -p[1]*u[1]-p[1]*u[1]^2-(u[1]+1)^2*u[2] end nothing end function scalar_noise!(du,u,p,t) @inbounds begin du[1] = p[2]*u[1]*(1+u[1]) du[2] = -p[2]*u[1]*(1+u[1]) end nothing end # fix seeds seed = 100 Random.seed!(seed) numtraj= 100 seeds = rand(UInt, numtraj) W = WienerProcess(0.0,0.0,0.0) u0 = [-0.1f0,0.0f0] tspan = (0.0f0,100.0f0) p = [1.9f0,0.1f0] prob = SDEProblem(brusselator_f!,scalar_noise!,u0,tspan,p,noise=W) ensembleprob = EnsembleProblem(prob, prob_func = prob_func) sol = @time solve(ensembleprob,DRI1(),dt=0.1,EnsembleCPUArray(),trajectories=numtraj) sol_na = @time solve(ensembleprob,DRI1(),dt=0.8,adaptive=false,EnsembleCPUArray(),trajectories=numtraj) summ = EnsembleSummary(sol,0.0f0:0.5f0:100f0) pl = plot(summ,fillalpha=0.5,xlabel = \u0026quot;time t\u0026quot;, yaxis=\u0026quot;X(t)\u0026quot;, label= [\u0026quot;x₁(t)\u0026quot; \u0026quot;x₂(t)\u0026quot;], legend=true)  The time evolution of both dependent variables ($x_1(t)$ and $x_2(t)$) displays damped oscillations.\n  We can confirm Rößler\u0026rsquo;s observation4 that the adaptive scheme describes the time evolution of the SDE more accurately, as oscillations are damped out stronger for the fixed step size method, thus approaching the origin too rapidly.\nusing DifferentialEquations.EnsembleAnalysis meansol = timeseries_steps_mean(sol) meansol_na = timeseries_point_mean(sol_na,meansol.t) dts = [] tmp1 = tspan[1] for tmp2 in meansol.t global tmp1 push!(dts,tmp2-tmp1) tmp1 = tmp2 end # list_plots = [] for i in 1:length(meansol.u) l = @layout [a b] plt1 = plot(meansol[1, 1:i],meansol[2, 1:i], ylim = (-0.18, 0.18), xlim = (-0.13, 0.13), xlabel = \u0026quot;x₁(t)\u0026quot;, yaxis= \u0026quot;x₂(t)\u0026quot;, label=\u0026quot;adaptive\u0026quot;, lw=2, linecolor=1 ) plot!(meansol_na[1, 1:i],meansol_na[2, 1:i], ylim = (-0.18, 0.18), xlim = (-0.13, 0.13), xlabel = \u0026quot;x₁(t)\u0026quot;, yaxis= \u0026quot;x₂(t)\u0026quot;, label=\u0026quot;fixed step size\u0026quot;, lw=2, linecolor=2 ) pl2 = scatter(dts[1:i], xlabel = \u0026quot;step\u0026quot;, yaxis= \u0026quot;dtᵢ\u0026quot;, xlim = (0, length(meansol.u)), ylim = (0.0, 2.3), legend=false) plt = plot(plt1, pl2, layout = l) push!(list_plots, plt) end anim = animate(list_plots,lw=2,every=1)    GPU usage All necessary tools to accelerate the simulation of (stochastic) differential equations on GPUs within the SciML ecosystem are collected in the DiffEqGPU package.\nCurrently, bounds checking and return values are not allowed, i.e., functions must be written in the form:\nfunction f!(du,u,p,t) @inbounds begin du[1] = .. end nothing end  Except from those limitations, a user can specifiy ensemblealg=EnsembleGPUArray() to parallelize SDE solves across the GPU, see, e.g., the GPU tests for StochasticDiffEq for some examples. Note that for some high weak order solvers GPU usage is not recommended as scalar indexing is used.\nIf you have any questions or comments, please don’t hesitate to contact me!\n  Peter E. Kloeden and Eckhard Platen, Numerical solution of stochastic differential equations. 23, Springer Science \u0026amp; Business Media (2013). \u0026#x21a9;\u0026#xfe0e;\n Peter E. Kloeden, Eckhard Platen, and Ian W. Wright, Stochastic analysis and applications 10 431-441 (1992). \u0026#x21a9;\u0026#xfe0e;\n Kristian Debrabant, Andreas Rößler, Applied Numerical Mathematics 59, 582–594 (2009). \u0026#x21a9;\u0026#xfe0e;\n Kristian Debrabant, Andreas Rößler, Mathematics and Computers in Simulation 77, 408-420 (2008) \u0026#x21a9;\u0026#xfe0e;\n   ","date":1597668395,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597777200,"objectID":"43477ca9b2445f4eddd037d09515db97","permalink":"https://frankschae.github.io/post/high-weak/","publishdate":"2020-08-17T14:46:35+02:00","relpermalink":"/post/high-weak/","section":"post","summary":"This post summarizes our new high weak order methods for the SciML ecosystem, as implemented within the Google Summer of Code 2020 project.\nAfter an introductory part highlighting the differences between the strong and the weak approximation for stochastic differential equations, we look into the convergence and performance properties of a few representative new methods in case of a non-commutative noise process.","tags":["GSoC 2020","julia","High weak order solver","SRK methods"],"title":"High weak order SDE solvers","type":"post"},{"authors":[],"categories":[],"content":"First and foremost, I would like to thank my mentors Chris Rackauckas, Moritz Schauer, and Yingbo Ma for their willingness to supervise me in this Google Summer of Code project. Although we are still at the very beginning of the project, we already had plenty of very inspiring discussion. I will spend the following months implementing both new high weak order solvers as well as adjoint sensitivity methods for stochastic differential equations (SDEs). The project is embedded within the SciML organization which, among others, unifies the latest toolsets from scientific machine learning and differential equation solver software. Ultimately, the planned contributions will allow researchers to simulate (or even control) stochastic dynamics. Also inverse problems, where SDE models are fit to data, fall into the scope. Therefore, relevant applications are found in many fields ranging from the simulation of (bio-)chemical processes over financial modeling to quantum mechanics.\nThis post is supposed to summarize what we have implemented in this first period and what we are going to do next. Future posts are going to dig into the individual subjects in more details.\nHigh Weak Order Solvers Currently, the StochasticDiffEq package contains state-of-the-art solvers for the strong approximation of SDEs, i.e., solvers that allow one to reconstruct correctly the numerical solution of an SDE in a pathwise sense. In general, an accurate estimation of multiple stochastic integrals is then required to produce a strong method of order greater than 1/2.\nHowever in many situations, we are only aiming for computing an estimation for the expected value of the solution. In such situations, methods for the weak approximation are sufficient. The less restrictive formulation of the objective for weak methods has the advantage that they are computationally cheaper than strong methods. High weak order solvers are particularly appealing, as they allow for using much larger time steps while attaining the same error in the mean, as compared with SDE solvers having a smaller weak order convergence. As an example, when Monte Carlo methods are used for SDE models, it is indeed often sufficient to be able to accurately sample random trajectories of the SDE, and it is not important to accurately approximate a particular trajectory. The former is exactly what a solver with high weak order provides.\nSecond order Runge-Kutta methods for Ito SDEs In the beginning of the community bonding period I finished the implementations of the DRI1()1 and RI1()2 methods. Both are representing second order Runge-Kutta schemes and were introduced by Rößler. Interestingly, these methods are designed to scale well with the number of Wiener processes m. Specifically, only 2m-1 random variables have to be drawn (in contrast to m(m+1)/2 from previous methods). Additionally, the number of function evaluations for the drift and the diffusion terms is independent of m.\nAs an example, we can check the second order convergence property on a multi-dimensional SDE with non-commuting noise1:\n$$ \\scriptstyle d \\begin{pmatrix} X_1 \\\\ X_2 \\end{pmatrix} = \\begin{pmatrix} -\\frac{273}{512} \u0026amp; \\phantom{X_2}0 \\\\ -\\frac{1}{160} \\phantom{X_2} \u0026amp; -\\frac{785}{512}+\\frac{\\sqrt{2}}{8} \\end{pmatrix} \\begin{pmatrix} X_1 \\\\ X_2 \\end{pmatrix} dt + \\begin{pmatrix} \\frac{1}{4} X_1 \u0026amp; \\frac{1}{16} X_1 \\\\ \\frac{1-2\\sqrt{2}}{4} X_2 \u0026amp; \\frac{1}{10}X_1 +\\frac{1}{16} X_2 \\end{pmatrix} d \\begin{pmatrix} W_1 \\\\ W_2 \\end{pmatrix} $$\nwith initial value $$ X(t=0)= \\begin{pmatrix} 1 \\\\ 1\\end{pmatrix}.$$\nFor the function $f(x)=(x_1)^2$, we can analytically compute the expected value of the solution\n$$ \\rm{E}\\left[ f(X(t)) \\right] = \\exp(-t),$$\nwhich we use to test the weak convergence order of the algorithms in the following.\nTo compute the expected value numerically, we sample an ensemble of numtraj = 1e7 trajectories for different step sizes dt. The code for a single dt reads:\nusing StochasticDiffEq numtraj = 1e7 u₀ = [1.0,1.0] function f!(du,u,p,t) du[1] = -273//512*u[1] du[2] = -1//160*u[1]-(-785//512+sqrt(2)/8)*u[2] end function g!(du,u,p,t) du[1,1] = 1//4*u[1] du[1,2] = 1//16*u[1] du[2,1] = (1-2*sqrt(2))/4*u[1] du[2,2] = 1//10*u[1]+1//16*u[2] end dt = 1//8 tspan = (0.0,10.0) prob = SDEProblem(f!,g!,u₀,tspan,noise_rate_prototype=zeros(2,2)) h(z) = z^2 ensemble_prob = EnsembleProblem(prob; output_func = (sol,i) -\u0026gt; (h(sol[end][1]),false) ) sol = solve(ensemble_prob, DRI1(); dt=dt, save_start=false, save_everystep=false, weak_timeseries_errors=false, weak_dense_errors=false, trajectories=numtraj)  We then compute the error of the numerically obtained expected value of the ensemble simulation with respect to the analytical result:\nLinearAlgebra.norm(Statistics.mean(sol.u)-exp(-tspan[2]))  Repeating this procedure for some more values of dt, the log-log plot of the error as a function of dt displays nicely the second order convergence (slope $\\approx 2.2$).\n  In the next couple of weeks, my focus will be on\n adding other high weak order solvers, implementing adaptive time stepping.  More of our near-term goals are collected in this issue.\nAdjoint Sensitivity Methods for SDEs In parameter estimation/inverse problems, one is interested to know the optimal choice of parameters p such that a model f(p), e.g., a differential equation, optimally fits some data, y. The shooting method approaches this task by introducing some sort of loss function $L$. A common choice is the mean squared error\n$$ L = |f(p)-y|^2. $$\nAn optimizer is then used to update the parameters $p$ such that $L$ is minimized. For this fit, local optimizers use the gradient $\\frac{dL}{dp}$ to minimize the loss function and ultimately solve the inverse problem. One possibility to obtain the gradient information for (stochastic) differential equations is to use automatic differentiation (AD). While forward mode AD is memory efficient, it scales poorly in time with increasing number of parameters. On the contrary, reverse-mode AD, i.e., a direct backpropagation through the solver, has a huge memory footprint.\nAlternatively to the \u0026ldquo;direct\u0026rdquo; AD approaches, the adjoint sensitivity method can be used3. The adjoint sensitivity method is well known to compute gradients of solutions to ordinary differential equations (ODEs) with respect to the parameters and initial states entering the ODE. The method was recently generalized to SDEs4. Importantly, this new approach has different complexities in terms of memory consumption or computation time as compared with forward- or reverse-mode AD (NP vs N+P where N is the number of state variables and P is the number of parameters).\nIt turns out that the aforementioned gradients in the stochastic adjoint sensitivity method are given by solving an SDE with an augmented state backwards in time launched at the end state of the forward evolution. In other words, we first compute the forward time evolution of the model from the start time $t_0$ to the end time $t_1$. Subsequently, we reverse the SDE and run a second time evolution from $t_1$ to $t_0$. Please note that the authors in Ref. 4 are implementing a slightly modfified version where the time evolution of the augmented state runs from $-t_1$ to $-t_0$. We however are indeed using the former variant as it allows us to reuse/generalize many functions that were implemented in the DiffEqSensitivity package for ODE adjoints earlier.\nReverse SDE time evolution The reversion of an SDE is more difficult than the reversion of an ODE. However, for SDEs written in the Stratonovich sense, it turns out that reversion can be achieved by negative signs in front of the drift and diffusion terms. As one needs to follow the same trajectory backward, the noise sampled in the forward pass must be reconstructed. In general, we would like to use adaptive time-stepping solvers which require some form of interpolation for the noise values. After some fixes for the available noise processes, we are now able to reverse a stochastic time evolution either by using NoiseGrid which linearly interpolates between values of the noise on a given grid or by using a very general NoiseWrapper which interpolates in a distributionally-exact manner based on Brownian bridges.\nAs an example, the code below computes first the forward evolution of an SDE\n$$ dX = \\alpha X dt + \\beta X dW$$\nwith $\\alpha=1.01$, $\\beta=0.87$, $x(0)=1/2$, in the time span ($t_{0}=0$, $t_{1}=1)$. This forward evolution is shown in blue in the animation below. Subsequently, also the reverse time evolution (red) launched at time $t_{1}=1$ with initial value $x(t=1)$, propagated in negative time direction until $t_{0}=0$, is computed. We see that both trajectories match very well.\nusing StochasticDiffEq, DiffEqNoiseProcess α=1.01 β=0.87 dt = 1e-3 tspan = (0.0,1.0) u₀=1/2 tarray = collect(tspan[1]:dt:tspan[2]) f!(du,u,p,t) = du .= α*u g!(du,u,p,t) = du .= β*u prob = SDEProblem(f!,g!,[u₀],tspan) sol =solve(prob,EulerHeun(),dt=dt,save_noise=true, adaptive=false) _sol = deepcopy(sol) # to make sure the plot is correct W1 = NoiseGrid(reverse!(_sol.t),reverse!(_sol.W.W)) prob1 = SDEProblem(f!,g!,sol[end],reverse(tspan),noise=W1) sol1 = solve(prob1,EulerHeun(),dt=dt)    Gradients of diagonal SDEs I have already started to implement the stochastic adjoint sensitivity method for SDEs possessing diagonal noise. Currently, only out-of-place SDE functions are supported but I am optimistic that soon also the inplace formulation works.\nLet us consider again the linear SDE with multiplicative noise from above (with the same parameters). This SDE represents one of the few exact solvable cases. In the Stratonovich sense, the solution is given as\n$$ X(t) = X(0) \\exp(\\alpha t + \\beta W(t)).$$\nWe might be interested in optimizing the parameters $\\alpha$ and $\\beta$ to minimize a certain loss function acting on the solution $X(t)$. For such an optimization task, a useful search direction is indicated by the gradient of the loss function with respect to the parameters. The latter however requires the differentiation through the SDE solver \u0026ndash; if no analytical solution of the SDE is available.\nAs an example, let us consider a mean squared error loss\n$$ L(X(t)) = \\sum_i |X(t_i)|^2, $$\nacting on the solution $X(t)$ for some fixed time points $t_i$. Then, the analytical forms for the gradients here read\n$$ \\begin{aligned} \\frac{d L}{d \\alpha} \u0026amp;= 2 \\sum_i t_i |X(t_i)|^2 \\\\\n\\frac{d L}{d \\beta} \u0026amp;= 2 \\sum_i W(t_i) |X(t_i)|^2 \\end{aligned} $$\nfor $\\alpha$ and $\\beta$, respectively. We can confirm that this agrees with the gradients as obtained by the stochastic adjoint sensitivity method\nusing Test, LinearAlgebra using DiffEqSensitivity, StochasticDiffEq using Random seed = 100 Random.seed!(seed) u₀ = [0.5] tstart = 0.0 tend = 0.1 dt = 0.005 trange = (tstart, tend) t = tstart:dt:tend tarray = collect(t) function g(u,p,t) sum(u.^2.0) end function dg!(out,u,p,t,i) (out.=-2.0*u) end p2 = [1.01,0.87] f(u,p,t) = p[1]*u σ(u,p,t) = p[2]*u Random.seed!(seed) prob = SDEProblem(f,σ,u₀,trange,p2) sol = solve(prob,RKMil(interpretation=:Stratonovich),dt=tend/1e7,adaptive=false,save_noise=true) res_u0, res_p = adjoint_sensitivities(sol,EulerHeun(),dg!,t,dt=tend/1e7,sensealg=BacksolveAdjoint()) noise = vec((@. sol.W(tarray))) Wextracted = [W[1][1] for W in noise] resp1 = 2*sum(@. tarray*u₀^2*exp(2*(p2[1])*tarray+2*p2[2]*Wextracted)) resp2 = 2*sum(@. Wextracted*u₀^2*exp(2*(p2[1])*tarray+2*p2[2]*Wextracted)) resp = [resp1, resp2] @test isapprox(res_p', resp, rtol = 1e-6) # True  With respect to the adjoint sensitivity methods, we are planning to\n finish the current backsolve adjoint version, allow for computing the gradients of non-commuting SDEs, implement also an interpolation adjoint version, benchmark it with respect to AD approaches  in the upcoming weeks. For more information, the interested reader might take a look at the open issues in the DiffEqSensitivity package.\nIf you have any questions or comments, please don’t hesitate to contact me!\n  Kristian Debrabant, Andreas Rößler, Applied Numerical Mathematics 59, 582–594 (2009). \u0026#x21a9;\u0026#xfe0e;\n Andreas Rößler, Journal on Numerical Analysis 47, 1713–1738 (2009). \u0026#x21a9;\u0026#xfe0e;\n Steven G. Johnson, \u0026ldquo;Notes on Adjoint Methods for 18.335.\u0026rdquo; Introduction to Numerical Methods (2012). \u0026#x21a9;\u0026#xfe0e;\n Xuechen Li, Ting-Kam Leonard Wong, Ricky T. Q. Chen, David Duvenaud, arXiv preprint arXiv:2001.01328 (2020). \u0026#x21a9;\u0026#xfe0e;\n   ","date":1590844233,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590844233,"objectID":"b18c7f652abe8e3ab1ef5f8324b079fc","permalink":"https://frankschae.github.io/post/gsoc2020-high-weak-order-solvers-sde-adjoints/","publishdate":"2020-05-30T15:10:33+02:00","relpermalink":"/post/gsoc2020-high-weak-order-solvers-sde-adjoints/","section":"post","summary":"First and foremost, I would like to thank my mentors Chris Rackauckas, Moritz Schauer, and Yingbo Ma for their willingness to supervise me in this Google Summer of Code project. Although we are still at the very beginning of the project, we already had plenty of very inspiring discussion.","tags":["GSoC 2020","julia","High weak order solver","SRK methods","Adjoint sensitivity methods"],"title":"GSoC 2020: High weak order SDE solvers and their utility in neural SDEs","type":"post"},{"authors":[],"categories":[],"content":"","date":1589109744,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589109744,"objectID":"79e44c0f8a0e36807f6c8ada19854586","permalink":"https://frankschae.github.io/publication/njp/","publishdate":"2020-05-10T13:22:24+02:00","relpermalink":"/publication/njp/","section":"publication","summary":"Machine-learning driven models have proven to be powerful tools for the identification of phases of matter. In particular, unsupervised methods hold the promise to help discover new phases of matter without the need for any prior theoretical knowledge. While for phases characterized by a broken symmetry, the use of unsupervised methods has proven to be successful, topological phases without a local order parameter seem to be much harder to identify without supervision. Here, we use an unsupervised approach to identify boundaries of the topological phases. We train artificial neural nets to relate configurational data or measurement outcomes to quantities like temperature or tuning parameters in the Hamiltonian. The accuracy of these predictive models can then serve as an indicator for phase transitions. We successfully illustrate this approach on both the classical Ising gauge theory as well as on the quantum ground state of a generalized toric code.","tags":[],"title":"E. Greplova, A. Valenti, G. Boschung, F. Schäfer, N. Lörch, and S. Huber, New J. Phys. 22, 045003 (2020)","type":"publication"},{"authors":[],"categories":[],"content":"","date":1589109737,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589109737,"objectID":"ce947d9c8d777c18560c094394319a35","permalink":"https://frankschae.github.io/publication/entropy/","publishdate":"2020-05-10T13:22:17+02:00","relpermalink":"/publication/entropy/","section":"publication","summary":"We examine the spectral structure and many-body dynamics of two and three repulsively interacting bosons trapped in a one-dimensional double-well, for variable barrier height, inter-particle interaction strength, and initial conditions. By exact diagonalization of the many-particle Hamiltonian, we specifically explore the dynamical behavior of the particles launched either at the single-particle ground state or saddle-point energy, in a time-independent potential. We complement these results by a characterization of the cross-over from diabatic to quasi-adiabatic evolution under finite-time switching of the potential barrier, via the associated time evolution of a single particle’s von Neumann entropy. This is achieved with the help of the multiconfigurational time-dependent Hartree method for indistinguishable particles (MCTDH-X)—which also allows us to extrapolate our results for increasing particle numbers.","tags":["Bosonic systems","Exact Diagonalization","MCTDH-X"],"title":"F. Schäfer, M. A. Bastarrachea-Magnani, A. U. J. Lode, L. de Forges de Parny, and A. Buchleitner, Entropy 22, 382 (2020)","type":"publication"},{"authors":[],"categories":[],"content":"","date":1589109731,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589109731,"objectID":"919eb72cd3c1e9e9150d95b768cf58a8","permalink":"https://frankschae.github.io/publication/jphysb/","publishdate":"2020-05-10T13:22:11+02:00","relpermalink":"/publication/jphysb/","section":"publication","summary":"We investigate multiple scattering of scalar waves by an ensemble of N resonant point scatterers in three dimensions. For up to N = 21 scatterers, we numerically optimize the positions of the individual scatterers, to maximize the total scattering cross section for an incoming plane wave, on the one hand, and to minimize the decay rate associated to a long-lived scattering resonance, on the other. In both cases, the optimum is achieved by configurations where all scatterers are placed on a line parallel to the direction of the incoming plane wave. The associated maximal scattering cross section increases quadratically with the number of scatterers for large N, whereas the minimal decay rate—which is realized by configurations that are not the same as those that maximize the scattering cross section—decreases exponentially as a function of N. Finally, we also analyze the stability of our optimized configurations with respect to small random displacements of the scatterers. These results demonstrate that optimized configurations of scatterers bear a considerable potential for applications such as quantum memories or mirrors consisting of only a few atoms.","tags":["multiple scattering","numerical optimization"],"title":"F. Schäfer, F. Eckert and T. Wellens, J. Phys. B 50, 235502 (2017)","type":"publication"},{"authors":[],"categories":[],"content":"","date":1589109296,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589109296,"objectID":"d90fc2504c29d3f2758c889682fc049f","permalink":"https://frankschae.github.io/publication/pre99/","publishdate":"2020-05-10T13:14:56+02:00","relpermalink":"/publication/pre99/","section":"publication","summary":"We introduce an alternative method to identify phase boundaries in physical systems. It is based on training a predictive model such as a neural network to infer a physical system's parameters from its state. The deviation of the inferred parameters from the underlying correct parameters will be most susceptible and diverge maximally in the vicinity of phase boundaries. Therefore, peaks in the vector field divergence of the model's predictions are used as indication of phase transitions. Our method is applicable for phase diagrams of arbitrary parameter dimension and without prior information about the phases. Application to both the two-dimensional Ising model and the dissipative Kuramoto-Hopf model show promising results.","tags":["Machine Learning","Phase Transitions"],"title":"F. Schäfer and N. Lörch, Phys. Rev. E 99, 062107 (2019)","type":"publication"},{"authors":["FS in collaboration with Felix Eckert and Thomas Wellens"],"categories":[],"content":"We investigate multiple scattering of scalar waves by an ensemble of N resonant point scatterers in three dimensions. For up to N = 21 scatterers, we numerically optimize the positions of the individual scatterers, to maximize the total scattering cross section for an incoming plane wave, on the one hand, and to minimize the decay rate associated to a long-lived scattering resonance, on the other. In both cases, the optimum is achieved by configurations where all scatterers are placed on a line parallel to the direction of the incoming plane wave. The associated maximal scattering cross section increases quadratically with the number of scatterers for large N, whereas the minimal decay rate—which is realized by configurations that are not the same as those that maximize the scattering cross section—decreases exponentially as a function of N. Finally, we also analyze the stability of our optimized configurations with respect to small random displacements of the scatterers. These results demonstrate that optimized configurations of scatterers bear a considerable potential for applications such as quantum memories or mirrors consisting of only a few atoms.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"00a3646bc080207c242cecd1daa16abd","permalink":"https://frankschae.github.io/project/scattering/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/scattering/","section":"project","summary":"Numerical optimization of the positions of point scatterers to maximize the total scattering cross section for an incoming plane wave.","tags":["multiple scattering theory"],"title":"Cooperative Scattering of Scalar Waves by Optimized Configurations of Point Scatterers","type":"project"}]

    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"I am a researcher at Axiomatic AI where we develop verifiable AI technologies to accelerate progress in science and engineering. Previously, I was a postdoc in the Julia Lab located in the Computer Science and Artificial Intelligence Laboratory (CSAIL) at the Massachusetts Institute of Technology (MIT). I completed my PhD in physics in the Bruder group within the “Quantum Computing and Quantum Technology” PhD school at the University of Basel. During my PhD, I participated in the Google Summer of Code (GSoC) 2020 and 2021 programs with the projects “High weak order stochastic differential equation solvers and their utility in neural stochastic differential equations” within the Julia Language organization and “Neural Hybrid Differential Equations and Adjoint Sensitivity Analysis” within the NumFocus organization, supervised by Chris Rackauckas, Moritz Schauer, Mohamed Tarek, and Yingbo Ma. Since 2020, I am a member of the SciML open source software organization for scientific machine learning.\n","date":1554595200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1554595200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a researcher at Axiomatic AI where we develop verifiable AI technologies to accelerate progress in science and engineering. Previously, I was a postdoc in the Julia Lab located in the Computer Science and Artificial Intelligence Laboratory (CSAIL) at the Massachusetts Institute of Technology (MIT).","tags":null,"title":"Frank Schäfer","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Hugo Blox Builder’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://frankschae.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Hugo Blox Builder's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["FS in collaboration with Gaurav Arya","Moritz Schauer","Ruben Seyer","Alex Lew","Mathieu Huot","Kartik Chandra","Vikash Mansinghka","Jonathan Ragan-Kelley","Chris Rackauckas"],"categories":[],"content":"Automatic differentiation (AD) has become ubiquitous throughout scientific computing and deep learning. However, AD systems have been restricted to the subset of programs that have a continuous dependence on parameters. Programs that have discrete stochastic behaviors governed by distribution parameters, such as flipping a coin with probability p of being heads, pose a challenge to these systems. In this work we develop a new AD methodology for programs with discrete randomness. We demonstrate how this method gives an unbiased and low-variance estimator.\n","date":1705333764,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1705333764,"objectID":"fd4013b59c325e7176a3ea5f9c2d78c3","permalink":"https://frankschae.github.io/project/stochasticad/","publishdate":"2024-01-15T10:49:24-05:00","relpermalink":"/project/stochasticad/","section":"project","summary":"We develop and implement AD algorithms for handling programs that can contain discrete randomness.","tags":[],"title":"Automatic Differentiation of Programs with Discrete Randomness","type":"project"},{"authors":["FS in collaboration with Flemming Holtorf","Julian Arnold","Chris Rackauckas","and Alan Edelman"],"categories":[],"content":"Control of devices at the quantum level holds enormous potential for current and future applications in the field of quantum information science. However, due to the nonlinear and stochastic nature of quantum systems under continuous observation, analytical solutions to all but the simplest quantum control problems remain unknown. In this project, we present a convex optimization framework to compute informative bounds on the best attainable control performance. Since our approach provides an under-approximator for the value function, we can use it directly to construct near-optimal heuristic controllers as demonstrated for a qubit subjected to homodyne detection and photon counting.\n","date":1682803609,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682803609,"objectID":"d1e077164ce2a89141c07c546777d1ea","permalink":"https://frankschae.github.io/project/controlbounds/","publishdate":"2023-04-29T17:26:49-04:00","relpermalink":"/project/controlbounds/","section":"project","summary":"We compute bounds for the best attainable control performance that may serve as certificates of fundamental limitations or performance targets.","tags":["quantum control","convex optimization","stochastic optimal control","sum-of-squares"],"title":"Performance Bounds for Quantum Control","type":"project"},{"authors":[],"categories":[],"content":"","date":1673824837,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673824837,"objectID":"91750f0e293b4386e71240dea8d36441","permalink":"https://frankschae.github.io/software/stochasticad/","publishdate":"2023-01-16T00:20:37+01:00","relpermalink":"/software/stochasticad/","section":"software","summary":"StochasticAD is an experimental, research package for automatic differentiation (AD) of stochastic programs. It implements AD algorithms for handling programs that can contain discrete randomness. Joint work with: [Gaurav Arya](https://github.com/gaurav-arya), [Moritz Schauer](https://github.com/mschauer), and [Chris Rackauckas](https://github.com/ChrisRackauckas).","tags":[],"title":"StochasticAD.jl: Automatic Differentiation of Programs with Discrete Randomness","type":"software"},{"authors":[],"categories":[],"content":"","date":1638487237,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638487237,"objectID":"dd74b30c2376d17e758c3568ec2a62ad","permalink":"https://frankschae.github.io/software/abstractdifferentiation/","publishdate":"2021-12-03T00:20:37+01:00","relpermalink":"/software/abstractdifferentiation/","section":"software","summary":"Automatized generation of an extensive, unified, user-facing API for any AD package. Enables easy switching and composing between AD implementations. Joint work with [Mohamed Tarek](https://github.com/mohamed82008) and [other contributors](https://github.com/JuliaDiff/AbstractDifferentiation.jl/graphs/contributors).","tags":[],"title":"AbstractDifferentiation.jl: Backend-Agnostic Differentiable Programming in Julia","type":"software"},{"authors":[],"categories":[],"content":"Project summary In this project, we have implemented state-of-the-art sensitivity tools for chaotic dynamical systems, continuous adjoint sensitivity methods for hybrid differential equations, as well as a high level API for automatic differentiation.\nPossible fields of application for these tools range from model discovery with explicit dosing times in pharmacology, over accurate gradient estimates for chaotic fluid dynamics, to the control of open quantum systems. A more detailed summary is available on the GSoC page.\nBlog posts The following blog posts describe the work throughout the GSoC period in more detail:\nNeural Hybrid Differential Equations Shadowing Methods for Forward and Adjoint Sensitivity Analysis of Chaotic Systems Sensitivity Analysis of Hybrid Differential Equations AbstractDifferentiation.jl for AD-backend agnostic code Docs Documentation with respect to the adjoint sensitivity tools will be available on the local sensitivity analysis and on the control of automatic differentiation choices pages.\nAchievements Below is a list of PRs in the various repositories in chronological order.\nDiffEqSensitivity.jl Merged:\nAdd additive noise downstream test for DiffEqFlux DiscreteCallback fixes Allow for changes of p in callbacks Fix for using the correct uleft/pleft in continuous callback Fix broadcasting error on steady state adjoint Forward Least Squares Shadowing (LSS) Adjoint-mode for the LSS method concrete_solve dispatch for LSS methods Non-Intrusive Least Square Shadowing (NILSS) concrete_solve for NILSS Remove allocation in NILSS Handle additional callback case State-dependent Continuous Callbacks for BacksolveAdjoint QuadratureAdjoint() for ContinuousCallback More tests for Neural ODEs with callbacks for different sensitivity algorithms Support for PeriodicCallbacks in continuous adjoint methods AbstractDifferentiation.jl Merged:\nFixes gradient, Jacobian, Hessian, and vjp tests Open:\nAdd ForwardDiff and Zygote OrdinaryDiffEq.jl Merged:\nFix discrete reverse mode for some standard controllers DiffEqCallbacks.jl Merged:\nIntroduce a PeriodicCallbackAffect struct SteadyStateDiffEq.jl Merged:\nConvert alg.tspan to type of prob.u0 ChainRules.jl Merged:\nDo not differentiate through the construction of BitArray Use splatting in BitArray DiffEqNoiseProcess.jl Merged:\nAllow solvers to use Noise Grid with SVectors StochasticDiffEq.jl Merged:\nRemove Ihat2 matrix from weak solvers DiffEqDocs.jl Merged:\nSmall typo on plot page Add docs for shadowing methods Future work Besides the implementation of more shadowing methods, such as\nNILSAS, FD-NILSS, or Fast linear response, we are planning to\nbenchmark the new adjoints, refine the AbstractDifferentiation.jl package and use it within DiffEqSensitivity.jl, add more docs and examples. If you have any further suggestions or comments, check out our slac/zulip channels #sciml-bridged and #diffeq-bridged or the Julia language discourse.\nAcknowledgement Many thanks to my mentors Chris Rackauckas, Moritz Schauer, Yingbo Ma, and Mohamed Tarek for their unique, continuous support. It was a great opportunity to be part of such an inspiring collaboration. I highly appreciate our quick and flexible meeting times. I would also like to thank Christoph Bruder, Julian Arnold, and Martin Koppenhöfer for helpful comments on my blog posts. Special thanks to Michael Poli and Stefano Massaroli for their suggestions on adjoints for hybrid differential equations. Finally, thanks to the very supportive julia community and to Google’s open source program for funding this experience!\n","date":1628883705,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628883705,"objectID":"295f158a34d7a2a8bb042950210377c3","permalink":"https://frankschae.github.io/post/gsoc-2021/","publishdate":"2021-08-13T21:41:45+02:00","relpermalink":"/post/gsoc-2021/","section":"post","summary":"Project summary In this project, we have implemented state-of-the-art sensitivity tools for chaotic dynamical systems, continuous adjoint sensitivity methods for hybrid differential equations, as well as a high level API for automatic differentiation.","tags":["GSoC 2021"],"title":"Neural Hybrid Differential Equations and Adjoint Sensitivity Analysis","type":"post"},{"authors":[],"categories":[],"content":"Differentiable programming (∂P), i.e., the ability to differentiate general computer program structures, has enabled the efficient combination of existing packages for scientific computation and machine learning1. The Julia2 language is well suited for ∂P, see also Chris’ article3 for a detailed examination. There is already a plethora of examples where ∂P has provided massive performance and accuracy advantages over black-box approaches to machine learning. This is because black-box machine learning approaches are flexible but require a large amount of data. Incorporating previously acquired knowledge about the structure of a problem reduces the amount of data and allows the learning task to be simplified4, for example, by focusing on learning only the parts of the model that are actually missing4 5. In the context of quantum control, we have demonstrated the power of this framework for closed6 and open quantum systems7.\n∂P is (commonly) realized by automatic differentiation (AD), which is a family of techniques to efficiently and accurately differentiate numeric functions expressed as computer programs. Generally, besides forward- and reverse-mode AD, the two main branches of AD, a large variety of software implementations with different pros and cons exists. The goal is to make the best choice in every part of the program without requiring users to significantly customize their code. Having a common ground by ChainRules.jl empowers this idea of a Glue AD where backend developers just define ChainRules overloads. However, switching from one backend to another on the user side can still be tedious because the user has to look up the syntax of the new AD package.\nMohamed Tarek has started to implement a high level API for differentiation that unifies the APIs of all the AD packages in the Julia ecosystem. Ultimately, the API of our new package, AbstractDifferentiation.jl, aims at enabling AD users to write AD backend-agnostic code. This will greatly facilitate the switching between different AD packages. Once the interface is completed and all tests are added, it is also planned that DiffEqSensitivity.jl within the SciML software suite adopts AbstractDifferentiation.jl as a better way of handling AD choices. In this part of my GSoC project, I’ve started to fix remaining errors of the initial PR.\nThe interested reader is encouraged to look at Mohamed’s first PR for a complete list of functions provided by AbstractDifferentiation.jl (and some great discussions about the package). In the rest of this blog post, I will focus on a concrete example to illustrate the main idea.\nOptimization of the Rosenbrock function The Rosenbrock function is defined by\n$$ g(x_1,x_2) = (a-x_1)^2 + b(x_2-x_1^2)^2. $$\nThe function $g$ has a global minimum at $(x_1^\\star, x_2^\\star)= (a, a^2)$ with $g(x_1^\\star, x_2^\\star)=0$. In the following, we fix $a = 1$ and $b = 100$. The global minimum is located inside a long, narrow, banana-shaped, flat valley, which makes the function a common test case for optimization algorithms.\nLet us now implement the Gauss–Newton algorithm to find the global minimum. The Gauss–Newton algorithm iteratively finds the value of the $N$ variables ${\\bf{x}}=(x_1,\\dots, x_N)$ that minimize the sum of squares of $M$ residuals $(f_1,\\dots, f_M)$\n$$ S({\\bf x}) = \\frac{1}{2} \\sum_{i=1}^M f_i({\\bf x})^2. $$\nStarting from an initial guess ${\\bf x_0}$ for the minimum, the method runs through the iterations\n$$ {\\bf x}^{k+1} = {\\bf x}^k - \\alpha_k \\left(J^T J \\right)^{-1} J^T f({\\bf x}^k), $$ where $J$ is the Jacobian matrix at ${\\bf{x}}^k$ and $\\alpha_k$ is the step length determined via a line search subroutine.\nThe following plot shows the Rosenbrock function in 3D as well as a 2D heatmap including the global minimum ${\\bf x^\\star}=(1,1)$ and our initial guess ${\\bf x_0}=(0,-0.1)$.\nusing Pkg path = @__DIR__ cd(path); Pkg.activate(\u0026#34;.\u0026#34;); Pkg.instantiate() ## AbstractDifferentiation is not released yet!! using AbstractDifferentiation using Test, LinearAlgebra using FiniteDifferences, ForwardDiff, Zygote using Enzyme, UnPack using Plots, LaTeXStrings # using Diffractor: ∂⃖¹ ## Diffractor needs \u0026gt;julia@1.6 ## Rosenbrock function # R: R^2 -\u0026gt; R: x -\u0026gt; (a-x₁)² + b(x₂-x₁²)² g(x,p) = (p[1]-x[1])^2 + p[2]*(x[2]-x[1]^2)^2 # visualization p = [1.0,100.0] x₀ = [0.0,-0.1] xopt = [1.0,1.0] do_plot = true if do_plot x₁, x₂ = -2.0:0.01:2.0, -0.6:0.01:3.5 z = Surface((x₁,x₂)-\u0026gt;g([x₁,x₂],p), x₁, x₂) pl1 = surface(x₁,x₂,z, linealpha = 0.3, c=cgrad(:thermal, scale = :exp), colorbar=true, labelfontsize=20,camera = (3,50), xlabel = L\u0026#34;x_1\u0026#34;, ylabel = L\u0026#34;x_2\u0026#34;) pl2 = heatmap(x₁,x₂,z, c=cgrad(:thermal, scale = :exp), labelfontsize=20, xlabel = L\u0026#34;x_1\u0026#34;, ylabel = L\u0026#34;x_2\u0026#34;) scatter!(pl2, [(x₀[1],x₀[2])], label=L\u0026#34;x_0\u0026#34;, legendfontsize=15, markershape = :circle, markersize = 10, markercolor = :green) scatter!(pl2, [(xopt[1],xopt[2])],label=L\u0026#34;x^\\star\u0026#34;, legendfontsize=15, markershape = :star, markersize = 10, markercolor = :red) pl = plot(pl1,pl2, …","date":1627812197,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627812197,"objectID":"d9ff4a599f5556fadd3c7cc978b481a3","permalink":"https://frankschae.github.io/post/abstract_differentiation/","publishdate":"2021-08-01T12:03:17+02:00","relpermalink":"/post/abstract_differentiation/","section":"post","summary":"Differentiable programming (∂P), i.e., the ability to differentiate general computer program structures, has enabled the efficient combination of existing packages for scientific computation and machine learning1. The Julia2 language is well suited for ∂P, see also Chris’ article3 for a detailed examination.","tags":["GSoC 2021","julia","Automatic Differentiation","AbstractDifferentiation.jl"],"title":"AbstractDifferentiation.jl for AD-backend agnostic code ","type":"post"},{"authors":["Frank Schäfer and Moritz Schauer"],"categories":[],"content":"In this post, we discuss sensitivity analysis of differential equations with state changes caused by events triggered at defined moments, for example reflections, bounces off a wall or other sudden forces. These are described by hybrid differential equations1. We highlight differences between explicit2 and implicit events3 4. As a paradigmatic example, we consider a bouncing ball described by the ODE\n$$ \\begin{aligned} \\text{d}z(t) \u0026amp;= v(t) \\text{d}t, \\\\ \\text{d}v(t) \u0026amp;= -\\mathrm g\\thinspace \\text{d}t \\end{aligned}\n$$\nwith initial condition\n$$ \\begin{aligned} z(t=0) \u0026amp;= z_0 = 5, \\\\ v(t=0) \u0026amp;= v_0 = -0.1. \\end{aligned}\n$$\nThe initial condition contains the initial height $z_0$ and initial velocity $v_0$ of the ball. We have two important parameters in this system. First, there is the gravitational constant $\\mathrm g=10$ modeling the acceleration of the ball due to an approximately constant gravitational field.\nSecond, we model the ground as barrier at $z = 0$ where the ball bounces off in opposite direction. We include a dissipation factor $\\gamma=0.8$ (coefficient of restitution) that accounts for a imperfect elastic bounce on the ground.\nWhen ignoring the bounces, we can straightforwardly integrate the ODE analytically\n$$ \\begin{aligned} z(t) \u0026amp;= z_0 + v_0 t - \\frac{\\mathrm g}{2} t^2, \\\\ v(t) \u0026amp;= v_0 - \\mathrm g\\thinspace t \\end{aligned}\n$$\nor numerically using the OrdinaryDiffEq package from the SciML ecosystem.\n### simulate forward using ForwardDiff, Zygote, OrdinaryDiffEq, DiffEqSensitivity using Plots, LaTeXStrings # dynamics function f(du,u,p,t) du[1] = u[2] du[2] = -p[1] end # parameters and solve z0 = 5.0 v0 = -0.1 t0 = 0.0 tend = 1.9 g = 10 γ = 0.8 u0 = [z0,v0] tspan = (t0,tend) p = [g, γ] prob = ODEProblem(f,u0,tspan,p) # plot forward trajectory sol = solve(prob,Tsit5(),saveat=0.1) pl = plot(sol, label = [\u0026#34;z(t)\u0026#34; \u0026#34;v(t)\u0026#34;], labelfontsize=20, legendfontsize=20, lw = 2, xlabel = \u0026#34;t\u0026#34;, legend=:bottomleft) hline!(pl, [0.0], label=false, color=\u0026#34;black\u0026#34;) savefig(pl,\u0026#34;BB_forward_no_bounce.png\u0026#34;) Of course, this way the ball continues to fall through the barrier at $z=0$.\nForward simulation with events At time $\\tau$ around $\\tau \\approx 1$, the ball hits the ground $z(\\tau) = 0$, and is inelastically reflected while dissipating a fraction of its energy. This can be modeled by re-initializing the ODE at time $\\tau$ with new initial conditions\n$$ \\begin{aligned}\nz({\\tau}) \u0026amp;= z(\\tau-) ,\\\\ v({\\tau})\u0026amp;= -\\gamma v(\\tau-) , \\end{aligned}\n$$\nso that there is a jump in the velocity at the event time: the velocity right before the bounce, the left limit $v(\\tau-)$, and the velocity with which the ball continues its movement after the bounce $v(\\tau)$, are different.\nGiven our analytical solution for the state as a function of time, we can easily compute the event time $\\tau$ in terms of the initial condition and parameters as\n$$ \\tau = \\frac{v_0 + \\sqrt{v_0^2 + 2 \\mathrm g z_0}}{\\mathrm g}. $$\nExplicit events We can define the bounce of the ball as an explicit event by inserting the values of the initial condition and the parameters into the formula for $\\tau$. We obtain\n$$ \\tau = 0.99005. $$\nThe full explicit trajectory $z_{\\rm exp}(t) = z(t)$ is determined by\n$$ z(t) = \\begin{cases} z_0 + v_0 t - \\dfrac{\\mathrm g}{2} t^2 ,\u0026amp; \\forall t \u0026lt; \\tau, \\\\ -0.4901 \\mathrm g - 0.5 \\mathrm g (-0.99005 + t)^2 + 0.99005 v_0 + z_0\\\\ \\quad - (-0.99005 + t) (-0.99005 \\mathrm g + v_0)\\gamma ,\u0026amp; \\forall t \\ge \\tau, \\end{cases} $$\nwhere we used\n$$ \\begin{aligned}\nz({\\tau})\u0026amp;= z_0 + 0.99005 v_0 -0.4901 \\mathrm g, \\\\ v({\\tau})\u0026amp;= -\\gamma v({\\tau-}) = -\\gamma(v_0 - 0.99005 \\mathrm g) . \\end{aligned}\n$$\nHere the change in state $(z,v)$ at the event time is defined with the help of an affect function\n$$ a(z,v) = (z, -\\gamma v). $$\nNumerically, we use a DiscreteCallback in this case to simulate the system.\n# solve with DiscreteCallback (explicit event) tstar = (v0 + sqrt(v0^2+2*z0*g))/g condition1(u,t,integrator) = (t == tstar) affect!(integrator) = integrator.u[2] = -integrator.p[2]*integrator.u[2] cb1 = DiscreteCallback(condition1,affect!,save_positions=(true,true)) sol1 = solve(prob,Tsit5(),callback=cb1, saveat=0.1, tstops=[tstar]) Evidently, by choosing an explicit definition of the event, the impact time is fixed. The reflection event is triggered at $\\tau = 0.99005$, a time where under different initial configurations the ball perhaps hasn’t reached the ground.\nImplicit events The physically more meaningful description of a bouncing ball is therefore given by an implicit description of the event in form of a condition (event function)\n$$ g(z,v,p,t), $$\nwhere an event occurs at time $\\tau$ if $g(z(\\tau),v(\\tau),p,\\tau) = 0$. We have already used this condition to define our impact time $\\tau$ when modeling the bounce explicitly. The implicit formulation also lends itself to take multiple bounces into account by triggering the event every time $g(z,v,p,t) = 0$.\nAs in the previous case, we can analytically compute the full trajectory of the ball. By …","date":1626434644,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1626434644,"objectID":"a60e1fb7808c483d902fff1d56e2a3a3","permalink":"https://frankschae.github.io/post/bouncing_ball/","publishdate":"2021-07-16T13:24:04+02:00","relpermalink":"/post/bouncing_ball/","section":"post","summary":"In this post, we discuss sensitivity analysis of differential equations with state changes caused by events triggered at defined moments, for example reflections, bounces off a wall or other sudden forces.","tags":["GSoC 2021","Hybrid differential equations","Adjoint sensitivity methods","Event handling"],"title":"Sensitivity Analysis of Hybrid Differential Equations","type":"post"},{"authors":[],"categories":[],"content":"In this post, we dig into sensitivity analysis of chaotic systems. Chaotic systems are dynamical, deterministic systems that are extremely sensitive to small changes in the initial state or the system parameters. Specifically, the dependence of a chaotic system on its initial conditions is well known as the “butterfly effect”. Chaotic models are encountered in various fields ranging from simple examples such as the double pendulum to highly complicated fluid or climate models.\nSensitivity analysis methods have proven to be very powerful for solving inverse problems such as parameter estimation or optimal control1 2 3. However, conventional sensitivity analysis methods may fail in chaotic systems due to the ill-conditioning of the initial value problem. Sophisticated methods, such as least squares shadowing4 (LSS) or non-intrusive least squares shadowing5 (NILSS) have been developed in the last decade. Essentially, these methods transform the initial value problem to a well conditioned optimization problem – the least squares shadowing problem. In this second part of my GSoC project, I implemented the LSS and the NILSS method within the DiffEqSensitivity.jl package.\nThe objective for LSS and NILSS is a long-time average quantity. More precisely, we define the instantaneous objective by $g(u,p)$, where $u$ is the state and $p$ is the parameter of the differential equation. Then, the objective is obtained by averaging $g$ over an infinitely long trajectory:\n$$ \\langle g \\rangle_∞ = \\lim_{T \\rightarrow ∞} \\langle g \\rangle_T, $$ where $$ \\langle g \\rangle_T = \\frac{1}{T} \\int_0^T g(u,s) \\text{d}t. $$ Under the assumption of ergodicity, $\\langle g \\rangle_∞$ only depends on $p$.\nThe Lorenz system One of the most important chaotic models is the Lorenz system which is a simplified model for atmospheric convection. The Lorenz system has three states $x$, $y$, and $z$, as well as three parameters $\\rho$, $\\sigma$, and $\\beta$. Its time evolution is given by the ODE:\n$$ \\begin{pmatrix} \\text{d}x \\\\ \\text{d}y \\\\ \\text{d}z \\\\ \\end{pmatrix} = \\begin{pmatrix} \\sigma (y-x)\\\\ x(\\rho-z) - y\\\\ x y - \\beta z \\\\ \\end{pmatrix}\\text{d}t $$\nFor simplicity, let us fix $\\sigma=10$ and $\\beta=8/3$ and focus only on the sensitivity with respect to $\\rho$. The classic Lorenz attractor is obtained when using $\\rho=28$:\nusing Random; Random.seed!(1234) using OrdinaryDiffEq using Statistics using QuadGK, ForwardDiff, Calculus using DiffEqSensitivity using SparseArrays, LinearAlgebra # simulate 1 trajectory of the Lorenz system forward function lorenz!(du,u,p,t) du[1] = 10*(u[2]-u[1]) du[2] = u[1]*(p[1]-u[3]) - u[2] du[3] = u[1]*u[2] - (8//3)*u[3] end p = [28.0] tspan_init = (0.0,30.0) tspan_attractor = (30.0,50.0) u0 = rand(3) prob_init = ODEProblem(lorenz!,u0,tspan_init,p) sol_init = solve(prob_init,Tsit5()) prob_attractor = ODEProblem(lorenz!,sol_init[end],tspan_attractor,p) sol_attractor = solve(prob_attractor,Vern9(),abstol=1e-14,reltol=1e-14) using Plots, LaTeXStrings pl1 = plot(sol_init,vars=(1,2,3), legend=true, label = \u0026#34;initial\u0026#34;, labelfontsize=20, lw = 2, xlabel = L\u0026#34;x\u0026#34;, ylabel = L\u0026#34;y\u0026#34;, zlabel = L\u0026#34;z\u0026#34;, xlims=(-25,30),ylims=(-30,30),zlims=(5,49) ) plot!(pl1, sol_attractor,vars=(1,2,3), label=\u0026#34;attractor\u0026#34;,xlims=(-25,30),ylims=(-30,30),zlims=(5,49) ) savefig(pl1, \u0026#34;Lorenz_forward.png\u0026#34;) Here, we separated the trajectory in two parts: We plot the initial transient dynamics starting from random initial conditions towards the attractor in blue and the subsequent time evolution lying entirely on the attractor in orange.\nFollowing Refs.4 and 5, we choose\n$$ \\langle z \\rangle_∞ = \\lim_{T \\rightarrow ∞} \\frac{1}{T} \\int_0^T z \\text{d}t $$\nas the objective, where we only use the trajectory that lies completely on the attractor (i.e., the orange trajectory in the plot on top). Let us first study the objective as a function of $\\rho$.\nfunction compute_objective(sol) quadgk(t-\u0026gt; sol(t)[end]/(tspan_attractor[2]-tspan_attractor[1]) ,tspan_attractor[1],tspan_attractor[2], atol=1e-14, rtol=1e-10)[1] end pl2 = plot(sol_attractor.t, getindex.(sol_attractor.u,3), ylabel=L\u0026#34;z(t)\u0026#34;, xlabel=L\u0026#34;t\u0026#34;, label=false, labelfontsize=20,lw = 2) mean_z = [mean(getindex.(sol_attractor.u,3))] int_z = compute_objective(sol_attractor) hline!(pl2, [int_z], label=L\u0026#34;\\langle z\\rangle\u0026#34;, lw = 2) savefig(pl2, \u0026#34;zsingle.png\u0026#34;) # for each value of the parameter, solve 20 times the initial value problem # wrap the procedure inside a function depending on p function Lorenz_solve(p) u0 = rand(3) prob_init = ODEProblem(lorenz!,u0,tspan_init,p) sol_init = solve(prob_init,Tsit5()) prob_attractor = ODEProblem(lorenz!,sol_init[end],tspan_attractor,p) sol_attractor = solve(prob_attractor,Vern9(),abstol=1e-14,reltol=1e-14) sol_attractor, prob_attractor end Niter = 10 ps = collect(0.0:1.0:50.0) probs = [] sols = [] zmean = [] zstd = [] for ρ in ps @show ρ ztmp = [] for i=1:Niter sol, prob = Lorenz_solve([ρ]) zbar = compute_objective(sol) push!(sols, sol) push!(probs, prob) push!(ztmp, zbar) end …","date":1625216902,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625216902,"objectID":"263091e46f2c8aead98407a523d8a2fe","permalink":"https://frankschae.github.io/post/shadowing/","publishdate":"2021-07-02T11:08:22+02:00","relpermalink":"/post/shadowing/","section":"post","summary":"In this post, we dig into sensitivity analysis of chaotic systems. Chaotic systems are dynamical, deterministic systems that are extremely sensitive to small changes in the initial state or the system parameters.","tags":["GSoC 2021","julia","Adjoint sensitivity methods","Forward sensitivity methods","Shadowing","Chaotic systems"],"title":"Shadowing Methods for Forward and Adjoint Sensitivity Analysis of Chaotic Systems","type":"post"},{"authors":[],"categories":[],"content":"I am delighted that I have been awarded my second GSoC stipend this year. I look forward to carrying out the ambitious project scope with my mentors Chris Rackauckas, Moritz Schauer, Yingbo Ma, and Mohamed Tarek. This year’s project is embedded within the NumFocus/SciML organization and comprises adjoint sensitivity methods for discontinuities, shadowing methods for chaotic dynamics, symbolically generated adjoint methods, and further AD tooling within the Julia Language.\nThis first post aims to illustrate our new (adjoint) sensitivity analysis tools with respect to event handling in (ordinary) differential equations (DEs).\nNote: Please check the SciMLSensitivity.jl docs for a maintained neural hybrid DE tutorial!\nHybrid Differential Equations DEs with additional explicit or implicit discontinuities are called hybrid DEs. Within the SciML software suite, such discontinuities may be incorporated into DE models by callbacks. Evidently, the incorporation of discontinuities allows a user to specify changes (events) in the system, i.e., changes of the state or the parameters of the DE, which cannot be modeled by a plain ordinary DE. While explicit events can be described by DiscreteCallbacks, implicit events have to be specified by ContinuousCallbacks. That is, explicit events possess explicit event times, while implicit events are triggered when a continuous function evaluates to 0. Thus, implicit events require some sort of rootfinding procedure.\nSome relevant examples for hybrid DEs with discrete or continuous callbacks are:\nquantum optics experiments, where photon-counting measurements lead to jumps in the quantum state that occur with a variable rate, see for instance Appendix A in Ref.1 (ContinuousCallback). a bouncing ball2 (ContinuousCallback). classical point process models, such as a Poisson process3. digital controllers4, where a continuous system dynamics is controlled by a discrete-time controller (DiscreteCallback). pharmacokinetic models5, where explicit dosing times change the drug concentration in the blood (DiscreteCallback). The simplest possible example being the one-compartment model. kicked oscillator dynamics, e.g., a harmonic oscillator that gets a kick at some time points (DiscreteCallback). The associated sensitivity methods that allow us to differentiate through the respective hybrid DE systems have been recently introduced in Refs. 2 and 3.\nKicked harmonic oscillator Let us consider the simple physical model of a damped harmonic oscillator, described by an ODE of the form\n$$ \\ddot{x}(t) + a\\cdot\\dot{x}(t) + b \\cdot x(t) = 0 , $$\nwhere $a=0.1$ and $b=1$ with initial conditions\n$$ \\begin{aligned} x(t=0) \u0026amp;= 1 \\\\ v(t=0) \u0026amp;= \\dot{x}(t=0) = 0. \\end{aligned}\n$$\nThis second-order ODE can be reduced to two first-order ODEs, such that we can straightforwardly simulate the resulting ODE with the DifferentialEquations.jl package. (Instead of doing this reduction manually, we could also use ModelingToolkit.jl to transform the ODE in an automatic manner. Alternatively, for second-order ODEs, there is also a SecondOrderODEProblem implemented.) The Julia code reads:\nusing DiffEqFlux, DifferentialEquations, Flux, Optim, Plots, DiffEqSensitivity using Zygote using Random u0 = Float32[1.; 0.] tspan = (0.0f0,50.0f0) dtsave = 0.5f0 t = tspan[1]:dtsave:tspan[2] function oscillator!(du,u,p,t) du[1] = u[2] du[2] = - u[1] - 1//10*u[2] return nothing end prob_data = ODEProblem(oscillator!,u0,tspan) # ODE without kicks pl = plot(solve(prob_data,Tsit5(),saveat=t), label=[\u0026#34;x(t)\u0026#34; \u0026#34;v(t)\u0026#34;]) We now include a kick to the velocity of the oscillator at regular time steps. Here, we choose both the time difference between the kicks and the increase in velocity as 1.\nkicktimes = tspan[1]:1:tspan[2] function kick!(integrator) integrator.u[end] += one(eltype(integrator.u)) end cb_ = PresetTimeCallback(kicktimes,kick!,save_positions=(false,false)) sol_data = solve(prob_data,Tsit5(),callback=cb_,saveat=t) t_data = sol_data.t ode_data = Array(sol_data) # visualize data pl1 = plot(t_data,ode_data[1,:],label=\u0026#34;data x(t)\u0026#34;) plot!(pl1,t_data,ode_data[2,:],label=\u0026#34;data v(t)\u0026#34;) pl2 = plot(t_data[1:20],ode_data[1,1:20],label=\u0026#34;data x(t)\u0026#34;) plot!(pl2,t_data[1:20],ode_data[2,1:20],label=\u0026#34;data v(t)\u0026#34;) pl = plot(pl2, pl1, layout=(1,2), xlabel=\u0026#34;t\u0026#34;) The left-hand side shows a zoom for short times to better resolve the kicks. Note that by setting save_positions=(true,true), the kicks would be saved before and after the event such that the kicks would appear completely vertically in the plot. The data on the right-hand will be used as training data below. In the spirit of universal differential equations6, we now aim at learning (potentially) missing parts of the model from these data traces.\nHigh domain knowledge For simplicity, we assume that we have almost perfect knowledge about our system. That is, we assume to know the basic structure of the ODE, including its parameters $a$ and $b$, and that the affect! function of the event only acts on the …","date":1623847817,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623847817,"objectID":"c5c641840c6146609c2e90c018c85a3f","permalink":"https://frankschae.github.io/post/hybridde/","publishdate":"2021-06-16T14:50:17+02:00","relpermalink":"/post/hybridde/","section":"post","summary":"I am delighted that I have been awarded my second GSoC stipend this year. I look forward to carrying out the ambitious project scope with my mentors Chris Rackauckas, Moritz Schauer, Yingbo Ma, and Mohamed Tarek.","tags":["GSoC 2021","julia","Hybrid differential equations","Adjoint sensitivity methods","Event handling"],"title":"Neural Hybrid Differential Equations","type":"post"},{"authors":[],"categories":[],"content":"","date":1615332097,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615332097,"objectID":"6b8484ee245fb6a73711cfc61c673627","permalink":"https://frankschae.github.io/software/sciml/","publishdate":"2021-03-10T00:21:37+01:00","relpermalink":"/software/sciml/","section":"software","summary":"Contributions to the SciML ecosystem in Julia, especially the DiffEqSensitivity.jl package for sensitivity analysis utilities, the StochasticDiffEq.jl package for stochastic differential equations solvers, and the DiffEqNoiseProcess package for tools to develop noise processes for differential equations.","tags":[],"title":"SciML Scientific Machine Learning Software","type":"software"},{"authors":[],"categories":[],"content":"","date":1615332037,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615332037,"objectID":"7d136c46f74da06acca4c2ac00a7b219","permalink":"https://frankschae.github.io/software/mitosisstochasticdiffeq/","publishdate":"2021-03-10T00:20:37+01:00","relpermalink":"/software/mitosisstochasticdiffeq/","section":"software","summary":"Implementation of the backward filter and the forward change of measure of the Automatic Backward Filtering Forward Guiding paradigm. Joint work with [Moritz Schauer](https://github.com/mschauer).","tags":[],"title":"MitosisStochasticDiffEq.jl","type":"software"},{"authors":["FS in collaboration with Pavel Sekatski","Martin Koppenhöfer","Niels Lörch","Christoph Bruder","and Michal Kloc"],"categories":[],"content":"Conceptually, it is straightforward to determine the time evolution of a quantum system for a fixed initial state given its (time-dependent) Hamiltonian or Lindbladian. Depending on the physical context, the dynamics is described by an ordinary or stochastic differential equation. In quantum state control, which is of paramount importance for quantum computation, we aim at solving the inverse problem. That is, starting from a distribution of initial states, we seek protocols that allow us to reach a desired target state by optimization of free parameters of the differential equation (control drives) in a certain time interval. To solve this control problem, we implement the system dynamics as part of a fully differentiable program and use a loss function that quantifies the distance from the target state. Specifically, we employ a neural network that maps an observation of the state of the qubit to a control drive defined via the differential equation for each time interval. To implement efficient training, we backpropagate the gradient information from the loss function through the SDE solver using adjoint sensitivity methods. Such a procedure should ultimately combine powerful tools from machine learning and scientific computation.\n","date":1615332029,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615332029,"objectID":"0dda26cfe2920348a8f4a2cf6ef7ac1d","permalink":"https://frankschae.github.io/project/dp_for_control/","publishdate":"2021-03-10T00:20:29+01:00","relpermalink":"/project/dp_for_control/","section":"project","summary":"Quantum control based on parametrized controllers trained with gradient information computed by (adjoint) sensitivity methods.","tags":["SciML","differentiable programming","NODE","NSDE","adjoint sensitivity methods","automatic differentiation","quantum control"],"title":"Control of (Stochastic) Quantum Dynamics with Differentiable Programming","type":"project"},{"authors":["FS in collaboration with Eliska Greplova","Tomoki Hirosawa","Jozef Bucko","František Herman","Rebekka Garreis","Chuyao Tong","Annika Kurzmann","Thomas Ihn","Hideaki Maebashi","Hiroyasu Matsuura","and Masao Ogata"],"categories":[],"content":"","date":1615330603,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615330603,"objectID":"94d4899d49aece16c0d03e7ab9c4963f","permalink":"https://frankschae.github.io/project/reconstruction/","publishdate":"2021-03-09T23:56:43+01:00","relpermalink":"/project/reconstruction/","section":"project","summary":"We address the challenges of connecting measurements of a physical system to an underlying theoretical description.","tags":[],"title":"Automated Data-driven Reconstruction of Physical Properties","type":"project"},{"authors":["FS in collaboration with Julian Arnold","Flemming Holtorf","Eliska Greplova","Agnes Valenti","Martin Zonda","Axel Lode","Gregor Boschung","Sebastian Huber","and Niels Lörch"],"categories":[],"content":"Artificial neural networks have successfully been used to identify phase transitions from data and classify data into distinct phases in an automated fashion. The power and success of these approaches (e.g., “learning by confusion” or the “prediction-based method”) can be attributed to the ability of deep neural networks to learn arbitrary functions. However, the larger a neural network, the more computational resources are needed to train it, and the more difficult it is to understand its decision making. In this project, we establish a solid theoretical foundation of popular machine-learning methods that rely on neural networks for detecting phase transitions and develop new efficient numerical routines to identify phase transitions directly from data. In the future, our methods could make it possible to detect as yet unknown phase transitions, for instance in quantum simulators or in novel materials.\n","date":1615330603,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615330603,"objectID":"96c9e3dc2a1485e968cc89f130ac8af0","permalink":"https://frankschae.github.io/project/ml_for_pt/","publishdate":"2021-03-09T23:56:43+01:00","relpermalink":"/project/ml_for_pt/","section":"project","summary":"Data-driven methods based on sample instances of the state of a physical system as a function of the system's parameters.","tags":["Machine learning","analytical predictors","neural networks","unsupervised learning"],"title":"Machine Learning for Phase Transitions","type":"project"},{"authors":["FS in collaboration with Laurent de Forges de Parny","Miguel Bastarrachea","Axel Lode","and Andreas Buchleitner"],"categories":[],"content":"We examine the spectral structure and many-body dynamics of two and three repulsively interacting bosons trapped in a one-dimensional double-well, for variable barrier height, inter-particle interaction strength, and initial conditions. By exact diagonalization of the many-particle Hamiltonian, we specifically explore the dynamical behavior of the particles launched either at the single-particle ground state or saddle-point energy, in a time-independent potential. We complement these results by a characterization of the cross-over from diabatic to quasi-adiabatic evolution under finite-time switching of the potential barrier, via the associated time evolution of a single particle’s von Neumann entropy. This is achieved with the help of the multiconfigurational time-dependent Hartree method for indistinguishable particles (MCTDH-X)—which also allows us to extrapolate our results for increasing particle numbers.\n","date":1615282751,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615282751,"objectID":"4b16c3ed4d0b9e975df9b36f75807256","permalink":"https://frankschae.github.io/project/mbdynamics/","publishdate":"2021-03-09T10:39:11+01:00","relpermalink":"/project/mbdynamics/","section":"project","summary":"Study of the spectral structure and the resulting dynamics of a few bosons under consideration of different initial conditions.","tags":["Many-body physics","exact diagonalization","Bose-Hubbard model","MCTDH-X"],"title":"Spectral Structure and Many-Body Dynamics of Ultracold Bosons in a Double Well ","type":"project"},{"authors":[],"categories":[],"content":"Project summary In this project, we have implemented new promising tools within the SciML organization which are relevant for tasks such as optimal control or parameter estimation for stochastic differential equations. The high weak order solvers will allow for massive performance advantages for fitting expectations of equations. Instead of automatic differentiation (AD) through the operations of an SDE solver, which scales poorly in memory, one can now use efficient stochastic adjoint sensitivity methods.\nBlog posts The following posts describe the work during the entire period in more detail:\nGSoC 2020: High weak order SDE solvers and their utility in neural SDEs High weak order SDE solvers Docs The documentation of the solvers is available here. Docs with respect to the adjoint sensitivity tools will be available here.\nAchievements Please find below a list of the PRs carried out during GSoC in the different repositories in chronological order within the SciML ecosystem.\nStochasticDiffEq.jl Merged:\nInplace version of DRI1 scheme RI1 method tstop fixes for reverse time propagation Fixes for EulerHeun scheme Speed up the tests for the DRI1 and RI1 schemes RI3, RI5, RI6, RDI2WM, RDI3WM, and RDI4WM schemes RDI1WM scheme Adaptive version of the stochastic Runge-Kutta schemes by embedding RS1 and RS2 schemes PL1WM scheme NON scheme Citations for weak methods Stochastic improved and modified Euler methods COM scheme Computationally more efficient NON variant (NON2) Open:\nStatic array tests Levy area for non-commutative noise processes DiffEqSensitivity.jl Merged:\nAdjoint sensitivities for steady states Concrete_solve dispatch for steady state problem BacksolveAdjoint for SDEs GPU savety for SDE BacksolveAdjoint Tests for concrete solve with respect to SDEs Alternative differentiation choices (vjps) for noise Jacobian Fixes and tests for inplace formulation of BacksolveAdjoint Efficient SDE BacksolveAdjoint for scalar noise Generalization of the SDE Adjoint for non-diagonal noise processes and diagonal noise processes with mixing terms InterpolatingAdjoint for SDEs Citations for backsolve, steadystate and interpolation adjoint Allow for more general noise processes: replace NoiseGrid by NoiseWrapper Checkpointing fix for BacksolveAdjoint in case of ODEs and SDEs Cheaper non-diagonal noise tests Open:\nSupport adjoints for SDEs written in the Ito sense DiffEqNoiseProcess.jl Merged:\nMulti-dimensional Brownian motion tests Bug fix for inplace form of NoiseGrid Reversible NoiseWrapper Relax the size constraints of the available noise processes Generalization of the real-valued white noise process function Fix of an extraction issue with NoiseGrid Allow NoiseWrapper to start at user-specified time points for interpolating parts of a trajectory Extraction and endpoint fixes on NoiseWrapper Reversal of SDEs written in the Ito sense DiffEqGPU.jl Merged:\nMemory efficient reduction function for ensemble problems ModelingToolkit.jl Merged:\nmodelingtoolkitize for SDESystem with conversion function between Ito and Stratonovich sense DiffEqDevTools.jl Merged:\nNoiseWrapper alternative for analyticless convergence tests of SDE solvers test_convergence() dispatch for ensemble simulations Work precision set for ensemble problems DiffEqBase.jl Merged:\nFix concrete_solve tests Future work There is still a lot that we’d like to do, e.g.,\nWriting up more docs and examples Implementing drift-implicit weak stochastic Runge-Kutta solvers Finishing the SDE adjoints for the Ito sense Implementing a virtual Brownian tree to store the noise processes in O(1) memory Setting up an OptimalControl library that allows for easy usage of the new tools within a symbolic interface Benchmarking of the new solvers and adjoints Contributions, suggestions \u0026amp; comments are always welcome! You might like to join our slac channels #diffeq-bridged and #neuralsde to get in touch.\nAcknowledgement I would like to thank my mentors Chris Rackauckas, Moritz Schauer, and Yingbo Ma for their amazing support during this project. It was a great opportunity to work in such an inspiring collaboration and I highly appreciate their detailed feedback. I would also like to thank Christoph Bruder, Niels Lörch, Martin Koppenhöfer, and Michal Kloc for helpful comments on my blog posts. Many thanks to the very supportive julia community and to Google’s open source program for funding this experience!\n","date":1598475589,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598475589,"objectID":"c74c1755693bb9cf28d7bf9019cfb1ee","permalink":"https://frankschae.github.io/post/gsoc-2020/","publishdate":"2020-08-26T22:59:49+02:00","relpermalink":"/post/gsoc-2020/","section":"post","summary":"Project summary In this project, we have implemented new promising tools within the SciML organization which are relevant for tasks such as optimal control or parameter estimation for stochastic differential equations.","tags":["GSoC 2020"],"title":"High weak order solvers and adjoint sensitivity analysis for stochastic differential equations","type":"post"},{"authors":[],"categories":[],"content":"This post summarizes our new high weak order methods for the SciML ecosystem, as implemented within the Google Summer of Code 2020 project.\nAfter an introductory part highlighting the differences between the strong and the weak approximation for stochastic differential equations, we look into the convergence and performance properties of a few representative new methods in case of a non-commutative noise process. Based on the stochastic version of the Brusselator equations, we demonstrate how adaptive step-size control for the weak solvers can result in a better approximation of the system dynamics. Finally, we discuss how to run simulations on GPU hardware.\nThroughout this post, we shall use the vector notation $X(t)$ to denote the solution of the d-dimensional Ito SDE system\n$$ dX(t) = a(t,X(t)) dt + b(t,X(t)) dW $$\nwith an m-dimensional driving Wiener process W(t) in the time span $\\mathbb{I}=[t_0, T]$, where $a: \\mathbb{I}\\times\\mathbb{R}^d \\rightarrow \\mathbb{R}^d$ and $b: \\mathbb{I}\\times \\mathbb{R}^{d} \\rightarrow \\mathbb{R}^{d \\times m}$ are continuous functions which fulfill a global Lipschitz condition.1 For simplicity, we write $X(t)$ for both time-discrete approximations and continuous-time random variables in the following.\nStrong convergence Suppose that we encounter the following problem: Given noisy observations $Z(t)$ (e.g., originating from measurement noise), what is the best estimate $\\hat{X}(t)$ of a stochastic system $X(t)$ satisfying the form above. Intuitively, we aim at filtering away the noise from the observations in an optimal way. Such tasks are well known as filtering problems.\nTo solve a filtering problem, we need a solver whose sample paths $Y(t)$ are close to the ones of the stochastic process $X(t)$, i.e., the solver should allow us to reconstruct correctly the numerical solution of each single trajectory of an SDE.\nIntroducing the absolute error at the final time $T$ as $$ \\rm{E}(|X(T) -Y(T)|) \\leq \\sqrt{\\rm{E}(|X(T)-Y(T)|^2)}, $$ we define convergence in the strong sense with order $p$ of a time discrete approximation $Y(T)$ with step size $h$ to the solution $X(T)$ of a SDE at time $T$ if there exists a constant $C$ (independent of $h$) and a constant $\\delta \u0026gt; 0$ such that $$ \\rm{E}(|X(T) -Y(T)|) \\leq C \\cdot h^p, $$ for each $h \\in [0, \\delta]$.\nThe StochasticDiffEq package contains various state-of-the-art solvers for the strong approximation of SDEs. In most cases, the strong solvers are however restricted to special noise forms. For example, the very powerful stability-optimized, adaptive strong order 3/2 stochastic Runge-Kutta method (SOSRI) can only handle diagonal and scalar noise Ito SDEs, i.e., noise processes where b has only entries on its diagonal or $m=1$. The main difficulty for the construction of strong methods with an order \u0026gt; 1/2 arises from the need of an accurate estimation of multiple stochastic integrals. While the iterated stochastic integrals can be expressed in terms of dW in the case of scalar, diagonal, and commutative noise processes, an approximation based on a Fourier expansion of a Brownian bridge must be employed in the case of non-commutative noise processes.2 Currently, we are also implementing those iterated integrals in the StochasticDiffEq library.\nWeak convergence Instead of an accurate pathwise approximation of a stochastic process, we only require an estimation for the expected value of the solution in many situations. In these cases, methods for the weak approximation are sufficient and – due to the less restrictive formulation of the objective – those solvers are computationally cheaper than their strong counterparts. For example, weak solvers are very efficient for simulations in quantum optics, if only mean values of many trajectories are required, e.g., when the expectation values of variables such as position and momentum operators are computed in the phase space framework (Wigner functions, positive P-functions, etc.) of quantum mechanics. Our new contributions are particularly appealing for many-body simulations, which are the computationally most demanding problems in quantum mechanics.\nWe define convergence in the weak sense with order $p$ of a time-discrete approximation $Y(T)$ with step size $h$ to the solution $X(T)$ of a SDE at time $T$ if there exists a constant $C$ (independent of $h$) and a constant $\\delta \u0026gt; 0$ such that $$ |\\rm{E}(g(X(T))) -\\rm{E}(g(Y(T)))| \\leq C \\cdot h^p, $$ $~$\nfor any polynomial $g$ for each $h \\in [0, \\delta]$.\nWe demonstrate below that high weak order solvers are specifically appealing, as they allow for using much larger time steps while attaining the same error in the mean, as compared with SDE solvers possessing a smaller weak-order convergence.\nNew high weak order methods A list of all new weak solvers is available in the SciML documentation. Note that we also implemented methods designed for the Stratonovich sense. For the subsequent examples regarding Ito SDEs, we use only a subset …","date":1597668395,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597777200,"objectID":"43477ca9b2445f4eddd037d09515db97","permalink":"https://frankschae.github.io/post/high-weak/","publishdate":"2020-08-17T14:46:35+02:00","relpermalink":"/post/high-weak/","section":"post","summary":"This post summarizes our new high weak order methods for the SciML ecosystem, as implemented within the Google Summer of Code 2020 project.\nAfter an introductory part highlighting the differences between the strong and the weak approximation for stochastic differential equations, we look into the convergence and performance properties of a few representative new methods in case of a non-commutative noise process.","tags":["GSoC 2020","julia","High weak order solver","SRK methods"],"title":"High weak order SDE solvers","type":"post"},{"authors":[],"categories":[],"content":"First and foremost, I would like to thank my mentors Chris Rackauckas, Moritz Schauer, and Yingbo Ma for their willingness to supervise me in this Google Summer of Code project. Although we are still at the very beginning of the project, we already had plenty of very inspiring discussion. I will spend the following months implementing both new high weak order solvers as well as adjoint sensitivity methods for stochastic differential equations (SDEs). The project is embedded within the SciML organization which, among others, unifies the latest toolsets from scientific machine learning and differential equation solver software. Ultimately, the planned contributions will allow researchers to simulate (or even control) stochastic dynamics. Also inverse problems, where SDE models are fit to data, fall into the scope. Therefore, relevant applications are found in many fields ranging from the simulation of (bio-)chemical processes over financial modeling to quantum mechanics.\nThis post is supposed to summarize what we have implemented in this first period and what we are going to do next. Future posts are going to dig into the individual subjects in more details.\nHigh Weak Order Solvers Currently, the StochasticDiffEq package contains state-of-the-art solvers for the strong approximation of SDEs, i.e., solvers that allow one to reconstruct correctly the numerical solution of an SDE in a pathwise sense. In general, an accurate estimation of multiple stochastic integrals is then required to produce a strong method of order greater than 1/2.\nHowever in many situations, we are only aiming for computing an estimation for the expected value of the solution. In such situations, methods for the weak approximation are sufficient. The less restrictive formulation of the objective for weak methods has the advantage that they are computationally cheaper than strong methods. High weak order solvers are particularly appealing, as they allow for using much larger time steps while attaining the same error in the mean, as compared with SDE solvers having a smaller weak order convergence. As an example, when Monte Carlo methods are used for SDE models, it is indeed often sufficient to be able to accurately sample random trajectories of the SDE, and it is not important to accurately approximate a particular trajectory. The former is exactly what a solver with high weak order provides.\nSecond order Runge-Kutta methods for Ito SDEs In the beginning of the community bonding period I finished the implementations of the DRI1()1 and RI1()2 methods. Both are representing second order Runge-Kutta schemes and were introduced by Rößler. Interestingly, these methods are designed to scale well with the number of Wiener processes m. Specifically, only 2m-1 random variables have to be drawn (in contrast to m(m+1)/2 from previous methods). Additionally, the number of function evaluations for the drift and the diffusion terms is independent of m.\nAs an example, we can check the second order convergence property on a multi-dimensional SDE with non-commuting noise1:\n$$ \\scriptstyle d \\begin{pmatrix} X_1 \\\\ X_2 \\end{pmatrix} = \\begin{pmatrix} -\\frac{273}{512} \u0026amp; \\phantom{X_2}0 \\\\ -\\frac{1}{160} \\phantom{X_2} \u0026amp; -\\frac{785}{512}+\\frac{\\sqrt{2}}{8} \\end{pmatrix} \\begin{pmatrix} X_1 \\\\ X_2 \\end{pmatrix} dt + \\begin{pmatrix} \\frac{1}{4} X_1 \u0026amp; \\frac{1}{16} X_1 \\\\ \\frac{1-2\\sqrt{2}}{4} X_2 \u0026amp; \\frac{1}{10}X_1 +\\frac{1}{16} X_2 \\end{pmatrix} d \\begin{pmatrix} W_1 \\\\ W_2 \\end{pmatrix} $$\nwith initial value $$ X(t=0)= \\begin{pmatrix} 1 \\\\ 1\\end{pmatrix}.$$\nFor the function $f(x)=(x_1)^2$, we can analytically compute the expected value of the solution\n$$ \\rm{E}\\left[ f(X(t)) \\right] = \\exp(-t),$$\nwhich we use to test the weak convergence order of the algorithms in the following.\nTo compute the expected value numerically, we sample an ensemble of numtraj = 1e7 trajectories for different step sizes dt. The code for a single dt reads:\nusing StochasticDiffEq numtraj = 1e7 u₀ = [1.0,1.0] function f!(du,u,p,t) du[1] = -273//512*u[1] du[2] = -1//160*u[1]-(-785//512+sqrt(2)/8)*u[2] end function g!(du,u,p,t) du[1,1] = 1//4*u[1] du[1,2] = 1//16*u[1] du[2,1] = (1-2*sqrt(2))/4*u[1] du[2,2] = 1//10*u[1]+1//16*u[2] end dt = 1//8 tspan = (0.0,10.0) prob = SDEProblem(f!,g!,u₀,tspan,noise_rate_prototype=zeros(2,2)) h(z) = z^2 ensemble_prob = EnsembleProblem(prob; output_func = (sol,i) -\u0026gt; (h(sol[end][1]),false) ) sol = solve(ensemble_prob, DRI1(); dt=dt, save_start=false, save_everystep=false, weak_timeseries_errors=false, weak_dense_errors=false, trajectories=numtraj) We then compute the error of the numerically obtained expected value of the ensemble simulation with respect to the analytical result:\nLinearAlgebra.norm(Statistics.mean(sol.u)-exp(-tspan[2])) Repeating this procedure for some more values of dt, the log-log plot of the error as a function of dt displays nicely the second order convergence (slope $\\approx 2.2$).\nIn the next couple of weeks, my focus will be on\nadding …","date":1590844233,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590844233,"objectID":"b18c7f652abe8e3ab1ef5f8324b079fc","permalink":"https://frankschae.github.io/post/gsoc2020-high-weak-order-solvers-sde-adjoints/","publishdate":"2020-05-30T15:10:33+02:00","relpermalink":"/post/gsoc2020-high-weak-order-solvers-sde-adjoints/","section":"post","summary":"First and foremost, I would like to thank my mentors Chris Rackauckas, Moritz Schauer, and Yingbo Ma for their willingness to supervise me in this Google Summer of Code project. Although we are still at the very beginning of the project, we already had plenty of very inspiring discussion.","tags":["GSoC 2020","julia","High weak order solver","SRK methods","Adjoint sensitivity methods"],"title":"GSoC 2020: High weak order SDE solvers and their utility in neural SDEs","type":"post"},{"authors":[],"categories":[],"content":"","date":1589109744,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589109744,"objectID":"79e44c0f8a0e36807f6c8ada19854586","permalink":"https://frankschae.github.io/publication/njp/","publishdate":"2020-05-10T13:22:24+02:00","relpermalink":"/publication/njp/","section":"publication","summary":"Machine-learning driven models have proven to be powerful tools for the identification of phases of matter. In particular, unsupervised methods hold the promise to help discover new phases of matter without the need for any prior theoretical knowledge. While for phases characterized by a broken symmetry, the use of unsupervised methods has proven to be successful, topological phases without a local order parameter seem to be much harder to identify without supervision. Here, we use an unsupervised approach to identify boundaries of the topological phases. We train artificial neural nets to relate configurational data or measurement outcomes to quantities like temperature or tuning parameters in the Hamiltonian. The accuracy of these predictive models can then serve as an indicator for phase transitions. We successfully illustrate this approach on both the classical Ising gauge theory as well as on the quantum ground state of a generalized toric code.","tags":[],"title":"E. Greplova, A. Valenti, G. Boschung, F. Schäfer, N. Lörch, and S. Huber, New J. Phys. 22, 045003 (2020)","type":"publication"},{"authors":[],"categories":[],"content":"","date":1589109737,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589109737,"objectID":"ce947d9c8d777c18560c094394319a35","permalink":"https://frankschae.github.io/publication/entropy/","publishdate":"2020-05-10T13:22:17+02:00","relpermalink":"/publication/entropy/","section":"publication","summary":"We examine the spectral structure and many-body dynamics of two and three repulsively interacting bosons trapped in a one-dimensional double-well, for variable barrier height, inter-particle interaction strength, and initial conditions. By exact diagonalization of the many-particle Hamiltonian, we specifically explore the dynamical behavior of the particles launched either at the single-particle ground state or saddle-point energy, in a time-independent potential. We complement these results by a characterization of the cross-over from diabatic to quasi-adiabatic evolution under finite-time switching of the potential barrier, via the associated time evolution of a single particle’s von Neumann entropy. This is achieved with the help of the multiconfigurational time-dependent Hartree method for indistinguishable particles (MCTDH-X)—which also allows us to extrapolate our results for increasing particle numbers.","tags":["Bosonic systems","Exact Diagonalization","MCTDH-X"],"title":"F. Schäfer, M. A. Bastarrachea-Magnani, A. U. J. Lode, L. de Forges de Parny, and A. Buchleitner, Entropy 22, 382 (2020)","type":"publication"},{"authors":[],"categories":[],"content":"","date":1589109731,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589109731,"objectID":"919eb72cd3c1e9e9150d95b768cf58a8","permalink":"https://frankschae.github.io/publication/jphysb/","publishdate":"2020-05-10T13:22:11+02:00","relpermalink":"/publication/jphysb/","section":"publication","summary":"We investigate multiple scattering of scalar waves by an ensemble of N resonant point scatterers in three dimensions. For up to N = 21 scatterers, we numerically optimize the positions of the individual scatterers, to maximize the total scattering cross section for an incoming plane wave, on the one hand, and to minimize the decay rate associated to a long-lived scattering resonance, on the other. In both cases, the optimum is achieved by configurations where all scatterers are placed on a line parallel to the direction of the incoming plane wave. The associated maximal scattering cross section increases quadratically with the number of scatterers for large N, whereas the minimal decay rate—which is realized by configurations that are not the same as those that maximize the scattering cross section—decreases exponentially as a function of N. Finally, we also analyze the stability of our optimized configurations with respect to small random displacements of the scatterers. These results demonstrate that optimized configurations of scatterers bear a considerable potential for applications such as quantum memories or mirrors consisting of only a few atoms.","tags":["multiple scattering","numerical optimization"],"title":"F. Schäfer, F. Eckert and T. Wellens, J. Phys. B 50, 235502 (2017)","type":"publication"},{"authors":[],"categories":[],"content":"","date":1589109296,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589109296,"objectID":"d90fc2504c29d3f2758c889682fc049f","permalink":"https://frankschae.github.io/publication/pre99/","publishdate":"2020-05-10T13:14:56+02:00","relpermalink":"/publication/pre99/","section":"publication","summary":"We introduce an alternative method to identify phase boundaries in physical systems. It is based on training a predictive model such as a neural network to infer a physical system's parameters from its state. The deviation of the inferred parameters from the underlying correct parameters will be most susceptible and diverge maximally in the vicinity of phase boundaries. Therefore, peaks in the vector field divergence of the model's predictions are used as indication of phase transitions. Our method is applicable for phase diagrams of arbitrary parameter dimension and without prior information about the phases. Application to both the two-dimensional Ising model and the dissipative Kuramoto-Hopf model show promising results.","tags":["Machine Learning","Phase Transitions"],"title":"F. Schäfer and N. Lörch, Phys. Rev. E 99, 062107 (2019)","type":"publication"},{"authors":["Frank Schäfer"],"categories":null,"content":" Create your slides in Markdown - click the Slides button to check out the example. Add the publication’s full text or supplementary notes here. You can use rich formatting such as including code, math, and images.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"https://frankschae.github.io/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Hugo Blox Builder Hugo Blox Builder | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://frankschae.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Hugo Blox Builder's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Frank Schäfer","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Add the publication’s full text or supplementary notes here. You can use rich formatting such as including code, math, and images.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"https://frankschae.github.io/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["Frank Schäfer","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Add the publication’s full text or supplementary notes here. You can use rich formatting such as including code, math, and images.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"https://frankschae.github.io/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"An example conference paper","type":"publication"},{"authors":["FS in collaboration with Felix Eckert and Thomas Wellens"],"categories":[],"content":"We investigate multiple scattering of scalar waves by an ensemble of N resonant point scatterers in three dimensions. For up to N = 21 scatterers, we numerically optimize the positions of the individual scatterers, to maximize the total scattering cross section for an incoming plane wave, on the one hand, and to minimize the decay rate associated to a long-lived scattering resonance, on the other. In both cases, the optimum is achieved by configurations where all scatterers are placed on a line parallel to the direction of the incoming plane wave. The associated maximal scattering cross section increases quadratically with the number of scatterers for large N, whereas the minimal decay rate—which is realized by configurations that are not the same as those that maximize the scattering cross section—decreases exponentially as a function of N. Finally, we also analyze the stability of our optimized configurations with respect to small random displacements of the scatterers. These results demonstrate that optimized configurations of scatterers bear a considerable potential for applications such as quantum memories or mirrors consisting of only a few atoms.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"00a3646bc080207c242cecd1daa16abd","permalink":"https://frankschae.github.io/project/scattering/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/scattering/","section":"project","summary":"Numerical optimization of the positions of point scatterers to maximize the total scattering cross section for an incoming plane wave.","tags":["multiple scattering theory"],"title":"Cooperative Scattering of Scalar Waves by Optimized Configurations of Point Scatterers","type":"project"}]
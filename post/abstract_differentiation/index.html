<!DOCTYPE html><html lang="en-us" >

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.8.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Frank Schäfer">

  
  
  
    
  
  <meta name="description" content="Differentiable programming (∂P), i.e., the ability to differentiate general computer program structures, has enabled the efficient combination of existing packages for scientific computation and machine learning1. The Julia2 language is well suited for ∂P, see also Chris&#39; article3 for a detailed examination.">

  
  <link rel="alternate" hreflang="en-us" href="https://frankschae.github.io/post/abstract_differentiation/">

  


  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  




  


  
  

  
  <link rel="alternate" href="/post/abstract_differentiation/index.xml" type="application/rss+xml" title="FS">
  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="https://frankschae.github.io/post/abstract_differentiation/">

  
  
  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="FS">
  <meta property="og:url" content="https://frankschae.github.io/post/abstract_differentiation/">
  <meta property="og:title" content="AbstractDifferentiation.jl for AD-backend agnostic code  | FS">
  <meta property="og:description" content="Differentiable programming (∂P), i.e., the ability to differentiate general computer program structures, has enabled the efficient combination of existing packages for scientific computation and machine learning1. The Julia2 language is well suited for ∂P, see also Chris&#39; article3 for a detailed examination."><meta property="og:image" content="https://frankschae.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png">
  <meta property="twitter:image" content="https://frankschae.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2021-08-01T12:03:17&#43;02:00">
    
    <meta property="article:modified_time" content="2021-08-01T12:03:17&#43;02:00">
  

  


    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://frankschae.github.io/post/abstract_differentiation/"
  },
  "headline": "AbstractDifferentiation.jl for AD-backend agnostic code ",
  
  "datePublished": "2021-08-01T12:03:17+02:00",
  "dateModified": "2021-08-01T12:03:17+02:00",
  
  "author": {
    "@type": "Person",
    "name": "Frank Schäfer"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "FS",
    "logo": {
      "@type": "ImageObject",
      "url": "https://frankschae.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_2.png"
    }
  },
  "description": "Differentiable programming (∂P), i.e., the ability to differentiate general computer program structures, has enabled the efficient combination of existing packages for scientific computation and machine learning1. The Julia2 language is well suited for ∂P, see also Chris' article3 for a detailed examination."
}
</script>

  

  


  


  





  <title>AbstractDifferentiation.jl for AD-backend agnostic code  | FS</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  







<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">FS</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">FS</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Research projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#software"><span>Open Source Software</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link js-theme-selector" data-toggle="dropdown" aria-haspopup="true">
          <i class="fas fa-palette" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      

    </ul>

  </div>
</nav>


  <article class="article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1>AbstractDifferentiation.jl for AD-backend agnostic code </h1>

  

  
    


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    Aug 1, 2021
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    11 min read
  </span>
  

  
  
  

  
  

</div>

    














  
</div>



  <div class="article-container">

    <div class="article-style">
      <p>
<a href="https://sinews.siam.org/Details-Page/scientific-machine-learning-how-julia-employs-differentiable-programming-to-do-it-best" target="_blank" rel="noopener">Differentiable programming (∂P)</a>, i.e., the ability to differentiate general computer program structures, has enabled the efficient combination of existing packages for scientific computation and machine learning<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. The Julia<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> language is 
<a href="https://github.com/tensorflow/swift/blob/main/docs/WhySwiftForTensorFlow.md" target="_blank" rel="noopener">well suited for ∂P</a>, see also Chris' article<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> for a detailed examination. There is already a plethora of examples where ∂P has provided massive performance <em>and</em> accuracy advantages over black-box approaches to machine learning. This is because black-box machine learning approaches are flexible but require a large amount of data. Incorporating previously acquired knowledge about the structure of a problem reduces the amount of data and allows the learning task to be simplified<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>, for example, by focusing on learning only the parts of the model that are actually missing<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>. In the context of quantum control, we have demonstrated the power of this framework for closed<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> and 
<a href="https://www.youtube.com/watch?v=uDUwdAqKzYM&amp;list=PLP8iPy9hna6TxktMt-IzdU2vQpGp3bwDn&amp;index=3&amp;t=12s" target="_blank" rel="noopener">open quantum systems</a><sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>.</p>
<p>∂P is (commonly) realized by automatic differentiation (AD), which is a family of techniques to efficiently and accurately differentiate numeric functions expressed as computer programs. Generally, besides forward- and reverse-mode AD, the two main branches of AD, 
<a href="https://juliadiff.org/" target="_blank" rel="noopener">a large variety of software implementations</a> with different 
<a href="https://discourse.julialang.org/t/state-of-automatic-differentiation-in-julia/43083" target="_blank" rel="noopener">pros and cons</a> exists. The goal is to make the best choice in every part of the program without requiring users to significantly customize their code. Having a common ground by 
<a href="https://github.com/JuliaDiff/ChainRules.jl" target="_blank" rel="noopener">ChainRules.jl</a> empowers this idea of a 
<a href="http://www.stochasticlifestyle.com/glue-ad-for-full-language-differentiable-programming/" target="_blank" rel="noopener">Glue AD</a> where backend developers just define ChainRules overloads. However, switching from one backend to another on the user side can still be tedious because the user has to look up the syntax of the new AD package.</p>
<p>
<a href="https://github.com/mohamed82008" target="_blank" rel="noopener">Mohamed Tarek</a> has started to 
<a href="https://github.com/JuliaDiff/AbstractDifferentiation.jl/pull/1" target="_blank" rel="noopener">implement a high level API for differentiation</a> that unifies the APIs of all the AD packages in the Julia ecosystem.  Ultimately, the API of our new package, 
<a href="https://github.com/JuliaDiff/AbstractDifferentiation.jl" target="_blank" rel="noopener">AbstractDifferentiation.jl</a>, aims at enabling AD users to write AD backend-agnostic code. This will greatly facilitate the switching between different AD packages. Once the interface is completed and all tests are added, it is also planned that 
<a href="https://github.com/SciML/DiffEqSensitivity.jl" target="_blank" rel="noopener">DiffEqSensitivity.jl</a> within the 
<a href="https://sciml.ai/" target="_blank" rel="noopener">SciML</a> software suite adopts AbstractDifferentiation.jl as a better way of handling AD choices. In this part of my GSoC project, I&rsquo;ve started to fix remaining errors of the 
<a href="https://github.com/JuliaDiff/AbstractDifferentiation.jl/pull/1" target="_blank" rel="noopener">initial PR</a>.</p>
<p>The interested reader is encouraged to look at Mohamed&rsquo;s 
<a href="https://github.com/JuliaDiff/AbstractDifferentiation.jl/pull/1" target="_blank" rel="noopener">first PR</a> for a complete list of functions provided by AbstractDifferentiation.jl (and some great discussions about the package). In the rest of this blog post, I will focus on a concrete example to illustrate the main idea.</p>
<h2 id="optimization-of-the-rosenbrock-function">Optimization of the Rosenbrock function</h2>
<p>The 
<a href="https://en.wikipedia.org/wiki/Rosenbrock_function" target="_blank" rel="noopener">Rosenbrock function</a> is defined by</p>
<p>$$
g(x_1,x_2) = (a-x_1)^2 + b(x_2-x_1^2)^2.
$$</p>
<p>The function $g$ has a global minimum at $(x_1^\star, x_2^\star)= (a, a^2)$ with $g(x_1^\star, x_2^\star)=0$. In the following, we fix $a = 1$ and $b = 100$. The global minimum is located inside a long, narrow, banana-shaped, flat valley, which makes the function a common test case for optimization algorithms.</p>
<p>Let us now implement the 
<a href="https://en.wikipedia.org/wiki/Gauss%E2%80%93Newton_algorithm" target="_blank" rel="noopener">Gauss–Newton algorithm</a> to find the global minimum. The Gauss–Newton algorithm iteratively finds the value of the $N$ variables ${\bf{x}}=(x_1,\dots, x_N)$ that minimize the sum of squares of $M$ residuals $(f_1,\dots, f_M)$</p>
<p>$$
S({\bf x}) = \frac{1}{2} \sum_{i=1}^M f_i({\bf x})^2.
$$</p>
<p>Starting from an initial guess ${\bf x_0}$  for the minimum, the method runs through the iterations</p>
<p>$$
{\bf x}^{k+1} = {\bf x}^k - \alpha_k \left(J^T J \right)^{-1} J^T f({\bf x}^k),
$$
where $J$ is the Jacobian matrix at ${\bf{x}}^k$ and $\alpha_k$ is the step length determined via a 
<a href="https://de.wikipedia.org/wiki/Gau%C3%9F-Newton-Verfahren#Beispiel" target="_blank" rel="noopener">line search subroutine</a>.</p>
<p>The following plot shows the Rosenbrock function in 3D as well as a 2D heatmap including the global minimum ${\bf x^\star}=(1,1)$ and our initial guess ${\bf x_0}=(0,-0.1)$.</p>
<pre><code class="language-julia">using Pkg
path = @__DIR__
cd(path); Pkg.activate(&quot;.&quot;); Pkg.instantiate()

## AbstractDifferentiation is not released yet!!

using AbstractDifferentiation
using Test, LinearAlgebra
using FiniteDifferences, ForwardDiff, Zygote
using Enzyme, UnPack
using Plots, LaTeXStrings
# using Diffractor: ∂⃖¹ ## Diffractor needs &gt;julia@1.6

## Rosenbrock function
# R: R^2 -&gt; R: x -&gt; (a-x₁)² + b(x₂-x₁²)²
g(x,p) = (p[1]-x[1])^2 + p[2]*(x[2]-x[1]^2)^2

# visualization
p = [1.0,100.0]
x₀ = [0.0,-0.1]
xopt = [1.0,1.0]

do_plot = true
if do_plot    
    x₁, x₂ = -2.0:0.01:2.0, -0.6:0.01:3.5
    z = Surface((x₁,x₂)-&gt;g([x₁,x₂],p), x₁, x₂)
    pl1 = surface(x₁,x₂,z, linealpha = 0.3, c=cgrad(:thermal, scale = :exp), colorbar=true,
                labelfontsize=20,camera = (3,50),
                xlabel = L&quot;x_1&quot;, ylabel = L&quot;x_2&quot;)

    pl2 = heatmap(x₁,x₂,z, c=cgrad(:thermal, scale = :exp),
                labelfontsize=20,
                xlabel = L&quot;x_1&quot;, ylabel = L&quot;x_2&quot;)
    scatter!(pl2, [(x₀[1],x₀[2])], label=L&quot;x_0&quot;, legendfontsize=15, markershape = :circle, markersize = 10, markercolor = :green)
    scatter!(pl2, [(xopt[1],xopt[2])],label=L&quot;x^\star&quot;, legendfontsize=15, markershape = :star, markersize = 10, markercolor = :red)

    pl = plot(pl1,pl2, layout=(2,1))
    savefig(pl, &quot;Rosenbrock.png&quot;)
end
</code></pre>





  











<figure >


  <a data-fancybox="" href="/img/Rosenbrock.png" >


  <img src="/img/Rosenbrock.png" alt=""  >
</a>



</figure>

<p>To apply the Gauss-Newton algorithm to the Rosenbrock function $g$, we first cast $g$ into an appropriate form fulfilling $S({\bf x})$, i.e., we use:</p>
<p>$$
f:\mathbb{R}^2\rightarrow\mathbb{R}^2:  {\bf x} \mapsto \begin{pmatrix}
f_1({\bf x}) \\<br>
f_2({\bf x}) \\<br>
\end{pmatrix} = \begin{pmatrix}
\sqrt{2}(a-x_1) \\<br>
\sqrt{2b}(x_2-x_1^2)\\<br>
\end{pmatrix},
$$</p>
<p>instead of $g$. We can easily compute the Jacobian of $f$ manually</p>
<p>$$
J =  \begin{pmatrix}
-\sqrt{2} &amp; 0 \\<br>
-2x_1\sqrt{2b} &amp; \sqrt{2b} \\<br>
\end{pmatrix}.
$$</p>
<p>We can then implement a (simple, non-optimized) version of the Gauss-Newton algorithm as follows.</p>
<pre><code class="language-julia"># bring Rosenbrock function into the form &quot;sum of squares of functions&quot;
f1(x,p) = convert(eltype(x),sqrt(2))*(p[1]-x[1])
f2(x,p) = convert(eltype(x),sqrt(2*p[2]))*(x[2]-x[1]^2)
f(x,p) = [f1(x,p),f2(x,p)]
function f(res,x,p) # Enzyme works with inplace functions
	res[1] = f1(x,p)
	res[2] = f2(x,p)
	return nothing
end

## manually pre-defined Jacobian
function Jacobian(x,p)
  [-convert(eltype(x),sqrt(2))   0
  -2*x[1]*convert(eltype(x),sqrt(2*p[2]))  convert(eltype(x),sqrt(2*p[2]))]
end

## Gauss-Newton scheme
function GaussNewton!(xs, x, p; maxiter=8, backend=nothing)
    for i=1:maxiter
        x = step(x, p, backend)
        @info i
        @show x
        push!(xs, x)
    end
    return xs, x
end
done(x,x2,p) = g(x2,p) &lt; g(x,p)
function step(x, p, backend::Nothing, α=1//1)
  x2 = deepcopy(x)
  while !done(x,x2,p)
    J = Jacobian(x,p)
    d = -inv(J'*J)*J'*f(x,p)
    copyto!(x2,x + α*d)
    α = α//2
  end
  return x2
end
</code></pre>
<p>When we run the algorithm, we find the global minimum after about the 7th iteration.</p>
<pre><code class="language-julia">xs = [x₀]
GaussNewton!(xs, x₀, p)
</code></pre>
<pre><code class="language-julia"># output:
[ Info: 1 ]
x = [0.125, -0.08750000000000001]
[ Info: 2 ]
x = [0.234375, -0.047265625000000006]
[ Info: 3 ]
x = [0.4257812499999995, 0.06800537109374968]
[ Info: 4 ]
x = [0.5693359374999986, 0.21857223510742047]
[ Info: 5 ]
x = [0.784667968749996, 0.5165503501892037]
[ Info: 6 ]
x = [0.9999999999999961, 0.9536321163177449]
[ Info: 7 ]
x = [0.9999999999999989, 0.9999999999999999]
[ Info: 8 ]
x = [1.0, 1.0]
</code></pre>
<p>If computing the Jacobian by hand is too cumbersome (or not possible for other reasons), we can compute it using finite differences. Within the AbstractDifferentiation API, we can directly define, for instance, the Jacobian of 
<a href="https://github.com/JuliaDiff/FiniteDifferences.jl" target="_blank" rel="noopener">FiniteDifferences.jl</a> as a new primitive operation.</p>
<pre><code class="language-julia">## FiniteDifferences
struct FDMBackend{A} &lt;: AD.AbstractFiniteDifference
    alg::A
end
FDMBackend() = FDMBackend(central_fdm(5, 1))
const fdm_backend = FDMBackend()
# Minimal interface
AD.@primitive function jacobian(ab::FDMBackend, f, xs...)
    return FiniteDifferences.jacobian(ab.alg, f, xs...)
end

# AD Jacobian returns tuple
# df_dx = AD.jacobian(fdm_backend, f(x,p), x₀, p)[1]
# df_dp = AD.jacobian(fdm_backend, f(x,p), x₀, p)[2]

@test AD.jacobian(fdm_backend, x-&gt;f(x,p), x₀)[1] ≈ Jacobian(x₀, p)
@test AD.jacobian(fdm_backend, f, x₀, p)[1] ≈ Jacobian(x₀, p)
</code></pre>
<p>After overloading the <code>step</code> function, we can run the Gauss-Newton algorithm as follows:</p>
<pre><code class="language-julia">function step(x, p, backend, α=1//1)
  x2 = deepcopy(x)
  while !done(x,x2,p)
    J = AD.jacobian(backend, f, x, p)[1]
    d = -inv(J'*J)*J'*f(x,p)
    copyto!(x2,x + α*d)
    α = α//2
  end
  return x2
end


xs = [x₀]
GaussNewton!(xs, x₀, p, backend=fdm_backend)
</code></pre>
<p>If we want to use reverse-mode AD instead, for example via 
<a href="https://github.com/FluxML/Zygote.jl" target="_blank" rel="noopener">Zygote.jl</a>, a natural choice for the primitive is to define the pullback function. AbstractDifferentiation then generates the associated code to compute the Jacobian for us.</p>
<pre><code class="language-julia">## Zygote
struct ZygoteBackend &lt;: AD.AbstractReverseMode end
const zygote_backend = ZygoteBackend()
AD.@primitive function pullback_function(ab::ZygoteBackend, f, xs...)
    return function (vs)
        # Supports only single output
        _, back = Zygote.pullback(f, xs...)
        if vs isa AbstractVector
            back(vs)
        else
            @assert length(vs) == 1
            back(vs[1])
        end
    end
end
##

@test minimum(AD.jacobian(fdm_backend, f, x₀, p) .≈ AD.jacobian(zygote_backend, f, x₀, p))
xs = [x₀]
GaussNewton!(xs, x₀, p, backend=zygote_backend)
</code></pre>
<p>Typically, reverse-mode AD is only beneficial for functions $f:\mathbb{R}^N\rightarrow\mathbb{R}^M$ where $M \ll N$, thus it is also a good idea to compare the performance with respect to forward-mode AD (
<a href="https://github.com/JuliaDiff/ForwardDiff.jl" target="_blank" rel="noopener">ForwardDiff.jl</a>)</p>
<pre><code class="language-julia">## ForwardDiff
struct ForwardDiffBackend &lt;: AD.AbstractForwardMode end
const forwarddiff_backend = ForwardDiffBackend()
AD.@primitive function pushforward_function(ab::ForwardDiffBackend, f, xs...)
    # jvp = f'(x)*v, i.e., differentiate f(x + h*v) wrt h at 0
    return function (vs)
        if xs isa Tuple
            @assert length(xs) &lt;= 2
            if length(xs) == 1
                (ForwardDiff.derivative(h-&gt;f(xs[1]+h*vs[1]),0),)
            else
                ForwardDiff.derivative(h-&gt;f(xs[1]+h*vs[1], xs[2]+h*vs[2]),0)
            end
        else
            ForwardDiff.derivative(h-&gt;f(xs+h*vs),0)
        end
    end
end
##

@test minimum(AD.jacobian(fdm_backend, f, x₀, p) .≈ AD.jacobian(forwarddiff_backend, f, x₀, p))
xs = [x₀]
GaussNewton!(xs, x₀, p, backend=forwarddiff_backend)
</code></pre>
<p>where we have used that the Jacobian-vector product $f'(x)v$, i.e., the primitives of forward-mode AD, can be computed by 
<a href="https://discourse.julialang.org/t/help-with-jacobian-vector-product-to-get-natural-gradient/51115/12" target="_blank" rel="noopener">differentiating $f(x + hv)$ with respect to $h$ at 0</a>.</p>
<p>Many AD packages, such as Zygote, have troubles with mutating functions. 
<a href="https://github.com/wsmoses/Enzyme.jl" target="_blank" rel="noopener">Enzyme.jl</a> is one of the exceptions. Additionally, it is very fast and has further improved the performance of the 
<a href="https://github.com/SciML/DiffEqSensitivity.jl/pull/427#issuecomment-866509944" target="_blank" rel="noopener">adjoints implemented within the DiffEqSensitivity package</a>.</p>
<pre><code class="language-julia">## Enzyme
struct EnzymeBackend{T1,T2,T3,T4} &lt;: AD.AbstractReverseMode
    out::T1
    λ::T2
    ∂f_∂x::T3
    ∂f_∂p::T4
end

out = zero(x₀)
λ = zero(x₀)
∂f_∂x = zero(x₀)
∂f_∂p = zero(p)

const enzyme_backend = EnzymeBackend(out,λ,∂f_∂x,∂f_∂p)
AD.@primitive function pullback_function(ab::EnzymeBackend, f, xs...)
    return function (vs)  
        # enzyme works only with inplace functions
        if !(vs isa AbstractVector)
            @assert length(vs) == 1 # Supports only single output
            vs = vs[1]
        end

        if xs isa Tuple
            @assert length(xs) == 2  # hard-coded for use case with two inputs
            x₀ = xs[1]
            p = xs[2]
        end

        @unpack out, λ, ∂f_∂x, ∂f_∂p = ab # cached in the struct, could also be created in here

        ∂f_∂x .*= false
        ∂f_∂p .*= false
        out .*= false

        copyto!(λ, vs)

        autodiff(Duplicated(out, λ), Duplicated(x₀, ∂f_∂x), Duplicated(p, ∂f_∂p)) do _out,_x, _p
            f(_out,_x,_p)
        end
        return (∂f_∂x,∂f_∂p)
    end
end
AD.isinplace(ab::EnzymeBackend) = true
AD.primalvalue(ab::EnzymeBackend, nothing, f, xs) = (f(ab.out,xs...);return ab.out)
##

@test minimum(AD.jacobian(fdm_backend, f, x₀, p) .≈ AD.jacobian(enzyme_backend, f, x₀, p))
xs = [x₀]
GaussNewton!(xs, x₀, p, backend=enzyme_backend)
</code></pre>
<p>Note that we have declared the Enzyme backend as <code>inplace</code> (which is important for internal control flow) and specified a <code>primalvalue</code> function returning the primal value of the forward pass.</p>
<h2 id="some-current-glitches">Some current glitches</h2>
<p>First, the push forward of a tuple of vectors, e.g., $(v_1, v_2)$, for a function with several input arguments is currently ambiguous. While <code>AD.jacobian</code> primitives and <code>AD.pullback_function</code> primitives interpret the push forward of our $f$ function as</p>
<p>$$
\left(\frac{\partial f(x_0,p)}{\partial x} v_1 , \frac{\partial f(x_0,p)}{\partial p} v_2 \right),
$$</p>
<p><code>AD.pushforward_function</code> primitives compute</p>
<p>$$
\frac{\partial f(x_0,p)}{\partial x} v_1 + \frac{\partial f(x_0,p)}{\partial p} v_2.
$$</p>
<pre><code class="language-julia"># pushforward_function wrt to multiple vectors is currently ambiguous
vs = (randn(2), randn(2))
res1 = AD.pushforward_function(fdm_backend, f, x₀, p)(vs)
res2 = AD.pushforward_function(forwarddiff_backend, f, x₀, p)(vs)

@test res2 ≈ res1[1] + res1[2]
</code></pre>
<p>Thus, we currently solve this issue by augmenting the input in the case of <code>AD.pushforward_function</code> primitives.</p>
<pre><code class="language-julia">res2a = AD.pushforward_function(forwarddiff_backend, f, x₀, p)((vs[1], zero(vs[2])))
res2b = AD.pushforward_function(forwarddiff_backend, f, x₀, p)((zero(vs[1]), vs[2]))

@test res2a ≈ res1[1]
@test res2b ≈ res1[2]
</code></pre>
<p>The plural &ldquo;primitives&rdquo; is used here because we may have different <code>pushforward_function</code> primitives for different backends. For instance, we can define an additional <code>pushforward_function</code> primitive for FiniteDifferences by:</p>
<pre><code class="language-julia">struct FDMBackend2{A} &lt;: AD.AbstractFiniteDifference
    alg::A
end
FDMBackend2() = FDMBackend2(central_fdm(5, 1))
const fdm_backend2 = FDMBackend2()
AD.@primitive function pushforward_function(ab::FDMBackend2, f, xs...)
    return function (vs)
        FDM.jvp(ab.alg, f, tuple.(xs, vs)...)
    end
end
</code></pre>
<p>Second, to avoid misunderstandings for the output of a Hessian of a function with several input arguments, we allow only single input arguments to the <code>Hessian</code> function.</p>
<pre><code class="language-julia"># Hessian only defined with respect to single input variable
@test_throws AssertionError H1 = AD.hessian(forwarddiff_backend, g, x₀, p)
H1 = AD.hessian(forwarddiff_backend, x-&gt;g(x,p), x₀)
H2 = AD.hessian(forwarddiff_backend, p-&gt;g(x₀,p), p)
</code></pre>
<p>Third, computing the Hessian requires to nest AD/backend calls. This can lead to failure if one tries to use Zygote over Zygote. To solve this problem, we have implemented a <code>HigherOrderBackend</code> that takes a tuple containing multiple backends (because, for example, using ForwardDiff over Zygote is perfectly fine).</p>
<pre><code class="language-julia"># Hessian might fail if AD system calls must not be nested (e.g. Zygote over Zygote)
backends = AD.HigherOrderBackend((forwarddiff_backend,zygote_backend))
H3 = AD.hessian(backends, x-&gt;g(x,p), x₀)
</code></pre>
<h2 id="outlook">Outlook</h2>
<p>There are many other use cases, e.g.,</p>
<ul>
<li>
<a href="https://diffeq.sciml.ai/stable/analysis/sensitivity/" target="_blank" rel="noopener">Sensitivity analysis of differential equations</a> requires vector-Jacobian products for adjoint methods and Jacobian-vector products for tangent methods.</li>
<li>The 
<a href="https://en.wikipedia.org/wiki/Newton%27s_method" target="_blank" rel="noopener">Newton–Raphson method</a> for rootfinding requires the gradient in the case of scalar function $f:\mathbb{R}\rightarrow\mathbb{R}$ and the Jacobian in case of $N$ (nonlinear) equations, i.e., finding the zeros of $f:\mathbb{R}^N\rightarrow\mathbb{R}^N$.</li>
<li>The 
<a href="https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization" target="_blank" rel="noopener">Newton method</a> in optimization requires the computation of the Hessian.</li>
</ul>
<p>AbstractDifferentiation.jl is by no means complete yet. We are still in the very early stages, but we hope to make significant progress in the coming weeks. Some of the next steps are:</p>
<ul>
<li>fixing remaining bugs, e.g., with respect to the computation of the Hessian and</li>
<li>adding AD/Finite Differentiation packages such as 
<a href="https://github.com/JuliaDiff/Diffractor.jl" target="_blank" rel="noopener">Diffractor</a>.</li>
</ul>
<p>If you have any questions or comments, please don’t hesitate to contact me!</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Mike Innes, Alan Edelman, et al., arXiv preprint arXiv:1907.07587 (2019). <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Jeff Bezanson, Stefan Karpinski, et al., arXiv preprint arXiv:1209.5145 (2012). <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Chris Rackauckas, The Winnower 8, DOI: 10.15200/winn.156631.13064 (2019). <a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>Chris Rackauckas, Yingbo Ma, et al., arXiv preprint arXiv:2001.04385 (2020). <a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p>Raj Dandekar, Chris Rackauckas, et al., Patterns <strong>1</strong>, 100145 (2020). <a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6" role="doc-endnote">
<p>Frank Schäfer, Michal Kloc, et al., Mach. Learn.: Sci. Technol. <strong>1</strong>, 035009 (2020). <a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7" role="doc-endnote">
<p>Frank Schäfer, Pavel Sekatski, et al., Mach. Learn.: Sci. Technol. <strong>2</strong>, 035004 (2021). <a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>

    </div>

    





<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/gsoc-2021/">GSoC 2021</a>
  
  <a class="badge badge-light" href="/tag/julia/">julia</a>
  
  <a class="badge badge-light" href="/tag/automatic-differentiation/">Automatic Differentiation</a>
  
  <a class="badge badge-light" href="/tag/abstractdifferentiation.jl/">AbstractDifferentiation.jl</a>
  
</div>



<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://frankschae.github.io/post/abstract_differentiation/&amp;text=AbstractDifferentiation.jl%20for%20AD-backend%20agnostic%20code%20" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://frankschae.github.io/post/abstract_differentiation/&amp;t=AbstractDifferentiation.jl%20for%20AD-backend%20agnostic%20code%20" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=AbstractDifferentiation.jl%20for%20AD-backend%20agnostic%20code%20&amp;body=https://frankschae.github.io/post/abstract_differentiation/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://frankschae.github.io/post/abstract_differentiation/&amp;title=AbstractDifferentiation.jl%20for%20AD-backend%20agnostic%20code%20" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://web.whatsapp.com/send?text=AbstractDifferentiation.jl%20for%20AD-backend%20agnostic%20code%20%20https://frankschae.github.io/post/abstract_differentiation/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https://frankschae.github.io/post/abstract_differentiation/&amp;title=AbstractDifferentiation.jl%20for%20AD-backend%20agnostic%20code%20" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>












  
  





  
    
    
    
      
    
    
    
    <div class="media author-card content-widget-hr">
      
        
        <img class="avatar mr-3 avatar-circle" src="/author/frank-schafer/avatar_hu9202cabaed592d2d4bbe51596d4206a2_80238_270x270_fill_lanczos_center_2.png" alt="Frank Schäfer">
      

      <div class="media-body">
        <h5 class="card-title"><a href="https://frankschae.github.io/">Frank Schäfer</a></h5>
        <h6 class="card-subtitle">Postdoctoral researcher</h6>
        <p class="card-text">My research interests include many-body physics, machine learning, and differentiable programming.</p>
        <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="/#contact" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.com/citations?user=goAokcEAAAAJ&amp;hl=de&amp;oi=sra#" target="_blank" rel="noopener">
        <i class="ai ai-google-scholar"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/frankschae" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://orcid.org/0000-0003-2684-4984" target="_blank" rel="noopener">
        <i class="ai ai-orcid"></i>
      </a>
    </li>
  
</ul>

      </div>
    </div>
  












  
  
  <div class="article-widget content-widget-hr">
    <h3>Related</h3>
    <ul>
      
      <li><a href="/post/shadowing/">Shadowing Methods for Forward and Adjoint Sensitivity Analysis of Chaotic Systems</a></li>
      
      <li><a href="/post/hybridde/">Neural Hybrid Differential Equations</a></li>
      
      <li><a href="/post/bouncing_ball/">Sensitivity Analysis of Hybrid Differential Equations</a></li>
      
      <li><a href="/post/high-weak/">High weak order SDE solvers</a></li>
      
      <li><a href="/post/gsoc2020-high-weak-order-solvers-sde-adjoints/">GSoC 2020: High weak order SDE solvers and their utility in neural SDEs</a></li>
      
    </ul>
  </div>
  



  </div>
</article>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.4.8/mermaid.min.js" integrity="sha256-lyWCDMnMeZiXRi7Zl54sZGKYmgQs4izcT7+tKc+KUBk=" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/julia.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = false;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.37431be2d92d7fb0160054761ab79602.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    © 2020 Frank Schäfer &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
